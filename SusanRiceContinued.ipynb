{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\#SusanRice, continued\n",
    "-----------------\n",
    "\n",
    "Today we are going to continue our work on the Susan Rice story. We have pulled all the tweets containing #SusanRice and packaged them up for you. There is so much to dig in here. \n",
    "\n",
    "[http://compute-cuj.org/tweets.csv](http://compute-cuj.org/tweets.csv)\n",
    "\n",
    "[http://compute-cuj.org/media.csv](http://compute-cuj.org/media.csv)\n",
    "\n",
    "[http://compute-cuj.org/hashtags.csv](http://compute-cuj.org/hashtags.csv)\n",
    "\n",
    "[http://compute-cuj.org/urls.csv](http://compute-cuj.org/urls.csv)\n",
    "\n",
    "[http://compute-cuj.org/mentions.csv](http://compute-cuj.org/mentions.csv)\n",
    "\n",
    "And here are the tweets.\n",
    "\n",
    "[http://compute-cuj.org/rice_tweets.tar.gz](http://compute-cuj.org/rice_tweets.tar.gz)\n",
    "\n",
    "\n",
    "There are two references we might want to consider. The first involves networking... how might we apply this here?\n",
    "[Pew report on mapping.](http://www.pewinternet.org/2014/02/20/mapping-twitter-topic-networks-from-polarized-crowds-to-community-clusters/) And the other has to do with ad trackers. It points to case studies and nice tools to see what kind of ad tracking are the different sites using.  [Tracker Tracker Tool.](https://wiki.digitalmethods.net/Dmi/WorkshopTrackingtheTrackers). Oh and another paper on tracking shared analytics tags (not just services but actual identifiers). [Some tips.](bellingcat.com/resources/how-tos/2015/07/23/unveiling-hidden-connections-with-google-analytics-ids/)\n",
    "\n",
    "\n",
    "OK down to work! Here is what we did to create the files you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from json import loads\n",
    "\n",
    "folder = \"json_tweets/\"\n",
    "tweet_folder = listdir(folder)\n",
    "len(tweet_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from csv import writer\n",
    "\n",
    "#tweets = writer(open(\"tweets.csv\",\"wb\"))\n",
    "#hashtags = writer(open(\"hashtags.csv\",\"wb\"))\n",
    "#urls = writer(open(\"urls.csv\",\"wb\"))\n",
    "#mentions = writer(open(\"mentions.csv\",\"wb\"))\n",
    "#media = writer(open(\"media.csv\",\"wb\"))\n",
    "\n",
    "#for tweet_file in tweet_folder:\n",
    "#    \n",
    "#    tweet = loads(open(folder+tweet_file).read())\n",
    "#    \n",
    "#    if tweet['source']:\n",
    "#        ts = tweet['source'].encode(\"utf-8\")\n",
    "#    else: ts = \"\"\n",
    "#        \n",
    "#    if tweet['in_reply_to_screen_name']:\n",
    "#        irt = tweet['in_reply_to_screen_name'].encode(\"utf-8\")\n",
    "#    else: irt = \"\"\n",
    "#        \n",
    "#    out = [tweet[\"id\"],tweet[\"text\"].encode(\"utf-8\"),tweet[\"created_at\"],tweet['retweeted'],\n",
    "#           irt, tweet['in_reply_to_status_id'],ts,\n",
    "#           tweet[\"retweet_count\"],tweet[\"user\"][\"screen_name\"].encode(\"utf-8\"),\n",
    "#           tweet[\"user\"][\"followers_count\"],tweet[\"user\"][\"friends_count\"]]\n",
    "#    \n",
    "#    tweets.writerow(out)\n",
    "#    \n",
    "#    if 'entities'in tweet and 'hashtags' in tweet['entities']:\n",
    "#        save = []\n",
    "#        for o in tweet['entities']['hashtags']:\n",
    "#        \n",
    "#            if not o['text'].encode('utf-8') in save:\n",
    "#                out = [tweet[\"id\"],tweet[\"created_at\"],tweet[\"user\"]['screen_name'].encode('utf-8'),o['text'].encode('utf-8')]\n",
    "#                hashtags.writerow(out)\n",
    "#                save.append(o['text'].encode('utf-8'))\n",
    "#    \n",
    "#    if 'entities'in tweet and 'urls' in tweet['entities']:\n",
    "#\n",
    "#        save = []\n",
    "#        for o in tweet['entities']['urls']:\n",
    "#        \n",
    "#            if not o['expanded_url'].encode('utf-8') in save:\n",
    "#                out = [tweet[\"id\"],tweet[\"created_at\"],tweet[\"user\"]['screen_name'].encode('utf-8'),o['expanded_url'].encode('utf-8')]\n",
    "#                urls.writerow(out)\n",
    "#                save.append(o['expanded_url'].encode('utf-8'))\n",
    "#                \n",
    "#    if 'entities'in tweet and 'user_mentions' in tweet['entities']:\n",
    "#        save = []        \n",
    "#        for o in tweet['entities']['user_mentions']:\n",
    "#            if not o['screen_name'].encode('utf-8') in save:\n",
    "#                out = [tweet[\"id\"],tweet[\"created_at\"],tweet[\"user\"]['screen_name'].encode('utf-8'),o['screen_name'].encode('utf-8')]\n",
    "#                mentions.writerow(out)\n",
    "#                save.append(o['screen_name'].encode('utf-8'))\n",
    "#\n",
    "#    if 'entities'in tweet and 'media' in tweet['entities']:\n",
    "#        save = []\n",
    "#        for o in tweet['entities']['media']:\n",
    "# \n",
    "#            if not o['expanded_url'].encode('utf-8') in save:\n",
    "#                out = [tweet[\"id\"],tweet[\"created_at\"],tweet[\"user\"]['screen_name'].encode('utf-8'),o['expanded_url'].encode('utf-8')]\n",
    "#                media.writerow(out)\n",
    "#                save.append(o['expanded_url'].encode('utf-8'))\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read in what we've got. It's a data frame so our lives will be easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"created_at\"][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These will make our displays a little easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import to_datetime, TimeGrouper, set_option\n",
    "set_option(\"display.max_rows\",100)\n",
    "set_option(\"display.max_colwidth\",140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that we need to transform date strings into date objects. Here we do it in the quickest way possible (it takes a long long time if you don't supply the date format and pandas has to guess instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"stamp\"] = to_datetime(df[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "df.set_index(\"stamp\",inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code we used last time to give us a sense of the time series. What other things can we do here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df.groupby(TimeGrouper(freq='30min')).agg({\"text\":{\"counts\":\"count\"}})\n",
    "counts.columns = counts.columns.droplevel()\n",
    "counts = counts.reset_index()\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sign_in(\"cocteautt\",\"9psj3t57ti\")\n",
    "\n",
    "mydata = [go.Scatter(x=counts[\"stamp\"],y=counts[\"counts\"],mode=\"line\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at screen names. Who tweeted the most using this hashtag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"screen_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the better computation tabulates users by time period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "usrcounts = df.groupby([TimeGrouper(freq='15min'),\"screen_name\"]).agg({\"screen_name\":{\"counts\":\"count\"}})\n",
    "usrcounts.columns = usrcounts.columns.droplevel()\n",
    "usrcounts = usrcounts.reset_index()\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "usrcounts.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usrcounts.sort_values(by=\"counts\",ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created special data frames for hashtags, media items, url's and mentions. Here are the hashtags..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = read_csv(\"hashtags.csv\")\n",
    "hashtags[\"stamp\"] = to_datetime(hashtags[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "hashtags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags[\"hashtag\"].str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and the URLs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = read_csv(\"urls.csv\")\n",
    "urls[\"stamp\"] = to_datetime(urls[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "urls.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One obvious alteration would be to pull out just the domains from the URLs. What sites are involved with the Susan Rice hashtag?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls[\"domain\"] =urls[\"url\"].str.replace(\".*//([^/]+).*\",\"\\\\1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls[\"domain\"].value_counts().head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One troubling observation is that bit.ly links didn't seem to get expanded. How can we fix that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls[urls[\"domain\"]==\"bit.ly\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls[urls[\"domain\"]==\"bit.ly\"][\"url\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the people mentioned in each tweet. What might we do with this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions = read_csv(\"mentions.csv\")\n",
    "mentions[\"stamp\"] = to_datetime(mentions[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "\n",
    "mentions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mentions[\"mention\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look at a time series of mentions of \"Cernovich\", the person who started the story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cer = mentions[mentions[\"mention\"]==\"Cernovich\"]\n",
    "\n",
    "cer.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "cercounts = cer.groupby(TimeGrouper(freq='30min')).agg({\"mention\":{\"counts\":\"count\"}})\n",
    "cercounts.columns = cercounts.columns.droplevel()\n",
    "cercounts = cercounts.reset_index()\n",
    "\n",
    "cer.reset_index(inplace=True)\n",
    "\n",
    "cercounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sign_in(\"cocteautt\",\"9psj3t57ti\")\n",
    "\n",
    "mydata = [go.Scatter(x=counts[\"stamp\"],y=counts[\"counts\"],mode=\"line\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we show you how to overlay two plots (or n plots) with separate axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cer = mentions[mentions[\"mention\"]==\"Cernovich\"]\n",
    "\n",
    "cer.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "cercounts = cer.groupby(TimeGrouper(freq='15min')).agg({\"mention\":{\"counts\":\"count\"}})\n",
    "cercounts.columns = cercounts.columns.droplevel()\n",
    "cercounts = cercounts.reset_index()\n",
    "\n",
    "cer.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "counts = df.groupby(TimeGrouper(freq='15min')).agg({\"text\":{\"counts\":\"count\"}})\n",
    "counts.columns = counts.columns.droplevel()\n",
    "counts = counts.reset_index()\n",
    "\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trace1 = go.Scatter(\n",
    "    x=counts[\"stamp\"],\n",
    "    y=counts[\"counts\"],\n",
    "    name='total tweets'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x=cercounts[\"stamp\"],\n",
    "    y=cercounts[\"counts\"],\n",
    "    name='cernovich mentions',\n",
    "    yaxis='y2'\n",
    ")\n",
    "mydata = [trace1, trace2]\n",
    "\n",
    "mylayout = go.Layout(\n",
    "    title='Comparing series',\n",
    "    yaxis=dict(\n",
    "        title='total tweets'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='cernovice mentions',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    autosize=False,width=1000,height=500\n",
    ")\n",
    "\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medium-sized API pulls\n",
    "-----------------\n",
    "Here's  some guidance about how you might use multiple credentials to make a big pull like we did for Susan Rice.\n",
    "First, load up your credetials!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# before we can make Twitter API calls, we need to initialize a few things...\n",
    "from tweepy import OAuthHandler, API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"8X0i7AWO7jbL11MZy926W6MArXYuJ2AqRY2sPfDA1pT6adqhjt\"\n",
    "ACCESS_TOKEN = \"851770460455014400-LBj7grHasYzTMjPyysaxTCLBMsnCYMm\"\n",
    "ACCESS_TOKEN_SECRET = \"G3ZThMZXaMsznNyQUPkVfN3l8IZB05bckxeTORSNjwrur\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api1 = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"KKiNtI8403O6R7MXUowWfM2mGB71eLJX2jeIMsgjGQ5SJrMaDl\"\n",
    "ACCESS_TOKEN = \"20743-PbvM6FZjT2LoDSKTfAUpWwSwLKwPrXj25VVyIe5s3mya\"\n",
    "ACCESS_TOKEN_SECRET = \"FdqcOey0FdwIhFhTyIuCJOFXwjFOX1EIDHG5vojPq3W51\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api2 = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"U7U9dyOrwyIEUZ8Gg6E3umDg2aYxE32Wxe68AmrYVoCpLdpHSE\"\n",
    "ACCESS_TOKEN = \"851777049371049984-ItoRu5hrw1c6Q0xfWNAHIm87VpylhBi\"\n",
    "ACCESS_TOKEN_SECRET = \"r11r1kkV9J6XhfbJabYdDSVmMfHr588QgiudTx0mGmt9A\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api3 = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"UnTNdH6L64vuZ7Am9yfOy6l9tUsJ3MAe9HPlikjzTPd7wb29m2\"\n",
    "ACCESS_TOKEN = \"851782771332837376-1oXxwDyBJ3ZNum6t2exwo5DwOtCMLwv\"\n",
    "ACCESS_TOKEN_SECRET = \"am9SmXn8jzH82Wkk2GpJ5GbF0CThQcilg5KU3rjy6DZab\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api4 = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"v0dqE3aZwZJtMTiHgmqj1OqdjT6VlscdKZR5CbcA68IVzoByu8\"\n",
    "ACCESS_TOKEN = \"851789776894210048-ANs4nyLcUSMxlkBeD0AdkpX4WVwufsb\"\n",
    "ACCESS_TOKEN_SECRET = \"g6l8V8pWTUGDVCubakBoNxo88guXBZJDd0EJcjzMXNlER\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api5 = API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"9tUnj3EdrusBXeHsziOf3UibwMViQUlEVW9epMnknbtgjeQ1BN\"\n",
    "ACCESS_TOKEN = \"851794545717149696-8Ml5QHfqwOyQgwiJBiZd5rjumTGwPbq\"\n",
    "ACCESS_TOKEN_SECRET = \"rmXCc8BZWqQp6ZJOJP7VG2pAerImIi76b60pYM6vmpfh0\"\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api6 = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use the cursor and try pulling from a  fixed date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy import Cursor\n",
    "\n",
    "query = '#SusanRice'\n",
    "\n",
    "ids = []\n",
    "texts = []\n",
    "times  = []\n",
    "retweets = []\n",
    "screen_names = []\n",
    "followers_counts = []\n",
    "friends_counts = []\n",
    "\n",
    "# Only iterate through the first 3 pages\n",
    "for page in Cursor(api1.search, q=query, result_type='recent', count=100, until=\"2017-04-04\").pages(170):\n",
    "    \n",
    "    for tweet in page:\n",
    "\n",
    "        ids.append(tweet.id)\n",
    "        texts.append(tweet.text)\n",
    "        times.append(tweet.created_at)\n",
    "        retweets.append(tweet.retweet_count)\n",
    "        screen_names.append(tweet.user.screen_name)\n",
    "        friends_counts.append(tweet.user.friends_count)\n",
    "        followers_counts.append(tweet.user.followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>id</th>\n",
       "      <th>retweet</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16985</th>\n",
       "      <td>288</td>\n",
       "      <td>143</td>\n",
       "      <td>849038793621590017</td>\n",
       "      <td>483</td>\n",
       "      <td>Robo_Elk</td>\n",
       "      <td>RT @Cernovich: Hey @EliLake, check the time st...</td>\n",
       "      <td>2017-04-03 23:19:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16986</th>\n",
       "      <td>515</td>\n",
       "      <td>197</td>\n",
       "      <td>849038792761769985</td>\n",
       "      <td>2</td>\n",
       "      <td>TroyLynch8</td>\n",
       "      <td>RT @VonWally: https://t.co/p7mjqjm91k #susanri...</td>\n",
       "      <td>2017-04-03 23:19:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16987</th>\n",
       "      <td>1234</td>\n",
       "      <td>2502</td>\n",
       "      <td>849038791893549056</td>\n",
       "      <td>37</td>\n",
       "      <td>carenharkins</td>\n",
       "      <td>RT @BinsackSb: #POWWW!! #Confirmed: #SusanRice...</td>\n",
       "      <td>2017-04-03 23:19:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16988</th>\n",
       "      <td>1678</td>\n",
       "      <td>1693</td>\n",
       "      <td>849038790471692289</td>\n",
       "      <td>2906</td>\n",
       "      <td>crawfishaka</td>\n",
       "      <td>RT @comermd: Will #SusanRice bring down #obama...</td>\n",
       "      <td>2017-04-03 23:19:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16989</th>\n",
       "      <td>1729</td>\n",
       "      <td>2721</td>\n",
       "      <td>849038790337363968</td>\n",
       "      <td>18</td>\n",
       "      <td>attackteam1</td>\n",
       "      <td>RT @FrogBallerina: Look Dems this is your lega...</td>\n",
       "      <td>2017-04-03 23:19:56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       followers_count  friends_count                  id  retweet  \\\n",
       "16985              288            143  849038793621590017      483   \n",
       "16986              515            197  849038792761769985        2   \n",
       "16987             1234           2502  849038791893549056       37   \n",
       "16988             1678           1693  849038790471692289     2906   \n",
       "16989             1729           2721  849038790337363968       18   \n",
       "\n",
       "        screen_name                                               text  \\\n",
       "16985      Robo_Elk  RT @Cernovich: Hey @EliLake, check the time st...   \n",
       "16986    TroyLynch8  RT @VonWally: https://t.co/p7mjqjm91k #susanri...   \n",
       "16987  carenharkins  RT @BinsackSb: #POWWW!! #Confirmed: #SusanRice...   \n",
       "16988   crawfishaka  RT @comermd: Will #SusanRice bring down #obama...   \n",
       "16989   attackteam1  RT @FrogBallerina: Look Dems this is your lega...   \n",
       "\n",
       "                     time  \n",
       "16985 2017-04-03 23:19:57  \n",
       "16986 2017-04-03 23:19:57  \n",
       "16987 2017-04-03 23:19:57  \n",
       "16988 2017-04-03 23:19:56  \n",
       "16989 2017-04-03 23:19:56  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame({\"id\":ids,\"text\":texts,\"time\":times,\"retweet\":retweets,\"screen_name\":screen_names,\"friends_count\":friends_counts,\"followers_count\":followers_counts})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we work our way backward, taking the oldest tweet in the group we pulled and saying to get another set of pages, organized so that this index is the upper bound for our search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for page in Cursor(api2.search, q=query, result_type='recent', count=100, max_id=\"849038790337363968\").pages(170):\n",
    "    \n",
    "    for tweet in page:\n",
    "\n",
    "        ids.append(tweet.id)\n",
    "        texts.append(tweet.text)\n",
    "        times.append(tweet.created_at)\n",
    "        retweets.append(tweet.retweet_count)\n",
    "        screen_names.append(tweet.user.screen_name)\n",
    "        friends_counts.append(tweet.user.friends_count)\n",
    "        followers_counts.append(tweet.user.followers_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>id</th>\n",
       "      <th>retweet</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33980</th>\n",
       "      <td>2527</td>\n",
       "      <td>2986</td>\n",
       "      <td>849029060999213056</td>\n",
       "      <td>2084</td>\n",
       "      <td>HearUsNowUSA1</td>\n",
       "      <td>RT @_Makada_: The left-wing propaganda media i...</td>\n",
       "      <td>2017-04-03 22:41:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33981</th>\n",
       "      <td>440</td>\n",
       "      <td>404</td>\n",
       "      <td>849029060885983232</td>\n",
       "      <td>390</td>\n",
       "      <td>MsFleurs87</td>\n",
       "      <td>RT @TheRickyDavila: Let's be clear, the WH usi...</td>\n",
       "      <td>2017-04-03 22:41:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33982</th>\n",
       "      <td>1252</td>\n",
       "      <td>2490</td>\n",
       "      <td>849029060302974978</td>\n",
       "      <td>20</td>\n",
       "      <td>Elizabe05716450</td>\n",
       "      <td>RT @ispyradio: It's all fun and games… until s...</td>\n",
       "      <td>2017-04-03 22:41:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33983</th>\n",
       "      <td>791</td>\n",
       "      <td>1057</td>\n",
       "      <td>849029059761909760</td>\n",
       "      <td>149</td>\n",
       "      <td>Steve4721076</td>\n",
       "      <td>RT @trump2016fan: #SUSANRICE  Who are Muslim a...</td>\n",
       "      <td>2017-04-03 22:41:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33984</th>\n",
       "      <td>826</td>\n",
       "      <td>1420</td>\n",
       "      <td>849029059170492416</td>\n",
       "      <td>390</td>\n",
       "      <td>DarkLab10</td>\n",
       "      <td>RT @TheRickyDavila: Let's be clear, the WH usi...</td>\n",
       "      <td>2017-04-03 22:41:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       followers_count  friends_count                  id  retweet  \\\n",
       "33980             2527           2986  849029060999213056     2084   \n",
       "33981              440            404  849029060885983232      390   \n",
       "33982             1252           2490  849029060302974978       20   \n",
       "33983              791           1057  849029059761909760      149   \n",
       "33984              826           1420  849029059170492416      390   \n",
       "\n",
       "           screen_name                                               text  \\\n",
       "33980    HearUsNowUSA1  RT @_Makada_: The left-wing propaganda media i...   \n",
       "33981       MsFleurs87  RT @TheRickyDavila: Let's be clear, the WH usi...   \n",
       "33982  Elizabe05716450  RT @ispyradio: It's all fun and games… until s...   \n",
       "33983     Steve4721076  RT @trump2016fan: #SUSANRICE  Who are Muslim a...   \n",
       "33984        DarkLab10  RT @TheRickyDavila: Let's be clear, the WH usi...   \n",
       "\n",
       "                     time  \n",
       "33980 2017-04-03 22:41:16  \n",
       "33981 2017-04-03 22:41:16  \n",
       "33982 2017-04-03 22:41:16  \n",
       "33983 2017-04-03 22:41:16  \n",
       "33984 2017-04-03 22:41:16  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame({\"id\":ids,\"text\":texts,\"time\":times,\"retweet\":retweets,\"screen_name\":screen_names,\"friends_count\":friends_counts,\"followers_count\":followers_counts})\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we just keep doing this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for page in Cursor(api3.search, q=query, result_type='recent', count=100, max_id=\"849029059170492416\").pages(170):\n",
    "    \n",
    "    for tweet in page:\n",
    "\n",
    "        ids.append(tweet.id)\n",
    "        texts.append(tweet.text)\n",
    "        times.append(tweet.created_at)\n",
    "        retweets.append(tweet.retweet_count)\n",
    "        screen_names.append(tweet.user.screen_name)\n",
    "        friends_counts.append(tweet.user.friends_count)\n",
    "        followers_counts.append(tweet.user.followers_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually this gets old and weput things in a loop. We'd ideally build an outer loop as well to skip back more than 6 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2017-04-02 03:05:22\n",
      "1 2017-04-02 03:05:22\n",
      "2 2017-04-02 03:05:22\n",
      "3 2017-04-02 03:05:22\n",
      "4 2017-04-02 03:05:22\n",
      "5 2017-04-02 03:05:22\n"
     ]
    }
   ],
   "source": [
    "apis = [api1,api2,api3,api4,api5,api6]\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    mid = min(ids)\n",
    "    api = apis[i]\n",
    "    \n",
    "    print i, min(times)\n",
    "    \n",
    "    for page in Cursor(api.search, q=query, result_type='recent', count=100, max_id=str(mid)).pages(170):\n",
    "    \n",
    "        for tweet in page:\n",
    "\n",
    "            ids.append(tweet.id)\n",
    "            texts.append(tweet.text)\n",
    "            times.append(tweet.created_at)\n",
    "            retweets.append(tweet.retweet_count)\n",
    "            screen_names.append(tweet.user.screen_name)\n",
    "            friends_counts.append(tweet.user.friends_count)\n",
    "            followers_counts.append(tweet.user.followers_count)\n",
    "    \n",
    "            out = open(\"tweets/\"+str(tweet.id)+\".json\",\"wb\")\n",
    "            out.write(dumps(tweet._json))\n",
    "            out.close()\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
