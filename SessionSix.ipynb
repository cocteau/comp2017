{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our minions - Powerful? Engaging? Or an isolated horde?\n",
    "------\n",
    "Today we are going to probe the network of our bots a little. First, we will talk about your observtions about the bots and how hard it was to tell them from actual users. You've read a little, but you've also had some experience looking at their profiles. To make discussion easier, here is a simple table. Feel free to add anything you want to help anchor our discussion.\n",
    "\n",
    "![Bot](https://regmedia.co.uk/2015/06/04/terminator.jpg?x=648&y=348&crop=1)\n",
    "\n",
    "The code below simply slurps up all the data from all the followers Rosie acquired. We are going to use a new set of data that you can [download here.](http://compute-cuj.org/rosie2.tar.gz) Uncompress it and put it in the same folder as this notebook. \n",
    "\n",
    "The code simply creates a data frame one row at a time -- each .json file representing a follower becominga new row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "from pandas import DataFrame\n",
    "\n",
    "# load in the list of followers and then reverse the order so now\n",
    "# oldest followers are first and newest are last (we should have been\n",
    "# doing that all along -- although it's good to know about negative indices)\n",
    "\n",
    "followers = loads(open(\"rosie2/newfollowers.json\").read())\n",
    "followers.reverse()\n",
    "\n",
    "# write the header for the csv\n",
    "column_names = [\"id\",\"screen_name\",\"name\",\"location\",\"lang\",\"time_zone\",\"url\",\n",
    "                \"statuses_count\",\"followers_count\",\"friends_count\",\"favourites_count\",\"listed_count\",\"created_at\"]\n",
    "rows = []\n",
    "\n",
    "# loop over our follower ids\n",
    "for id in followers:\n",
    "    \n",
    "    filename = \"rosie2/users/\"+str(id)+\".json\"\n",
    "    rawuser = loads(open(filename).read())\n",
    "\n",
    "    rows.append([rawuser[\"id\"],rawuser[\"screen_name\"].encode('utf-8'),rawuser[\"name\"].encode('utf-8'),\n",
    "                       rawuser[\"location\"].encode('utf-8'),rawuser[\"lang\"],rawuser[\"time_zone\"],rawuser[\"url\"],\n",
    "                       rawuser[\"statuses_count\"],rawuser[\"followers_count\"],\n",
    "                       rawuser[\"friends_count\"],rawuser[\"favourites_count\"],rawuser[\"listed_count\"],\n",
    "                       rawuser[\"created_at\"]]) \n",
    "\n",
    "# turn the list of lists into a dataframe\n",
    "df = DataFrame(rows,columns=column_names)\n",
    "\n",
    "# and write it out!\n",
    "df.to_csv(\"savefollowers.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look of various kinds. They are now sorted in acquisition order (oldest bots at the top, newest at the bottom). But there are other ways to sort this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=\"followers_count\",ascending=False)[0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to build a network of our bots' followers. Recall the following API calls that we can use to first get the id's of the followers and then their user information. This relies on Tweepy and so we have to fire up the old OAuth keys..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before we can make Twitter API calls, we need to initialize a few things...\n",
    "from tweepy import OAuthHandler, API\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)\n",
    "type(api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be an interesting user..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = api.followers_ids(screen_name=\"JoveinElyclaL\",count=5000)\n",
    "type(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users = api.lookup_users(user_ids=ids)\n",
    "type(users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to wrap this in a function. The function takes a list of user ids, our column of bots' id's and then an API object from Tweepy that represents \"twitter\". Here's the function, we can go over it later. In the next cell we use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, concat\n",
    "\n",
    "def grab_users(idlist,botlist,twitter):\n",
    "\n",
    "    # These are the data frames we will output, one for nodes and one for edges\n",
    "    big_edges = DataFrame()\n",
    "    big_nodes = DataFrame()\n",
    "    \n",
    "    # These are the columns each will have\n",
    "    node_names = [\"Type\",\"Name\",\"Description\",\"id\",\"location\",\"lang\",\"time_zone\",\"url\",\n",
    "                  \"statuses_count\",\"followers_count\",\"friends_count\",\"favourites_count\",\n",
    "                  \"listed_count\",\"created_at\"]\n",
    "    \n",
    "    edge_names = [\"From Type\",\"From Name\",\"Edge\",\"To Type\",\"To Name\",\"Weight\"]\n",
    "\n",
    "    # iterate over each id in the idlist...\n",
    "    for id in idlist:\n",
    "        \n",
    "        # looking up the id's followers on twitter \n",
    "        ids = twitter.followers_ids(user_id=id,count=5000)\n",
    "        ids.append(id)\n",
    "    \n",
    "        # and then getting information about each one (a little funny business for users\n",
    "        # with more than 100 followers -- not many)\n",
    "        number_of_followers = len(ids)\n",
    "        \n",
    "        users = []\n",
    "        for i in range(0, number_of_followers, 100):\n",
    "    \n",
    "            subset_ids = ids[i:i + 100]\n",
    "            users = users+twitter.lookup_users(user_ids=subset_ids)\n",
    "        \n",
    "        # isolate the screen name, because we didn't pass that (we just gave id's)\n",
    "        screen_name = [u.screen_name for u in users if u.id==id][0]\n",
    "    \n",
    "        # initialize a list of nodes and edges that will hold the rows for the data frames\n",
    "        nodes = []\n",
    "        edges = []\n",
    "    \n",
    "        # now iterate over the users and build up the nodes data frame for this id\n",
    "        for u in users:\n",
    "                \n",
    "            if u.id in botlist:\n",
    "                \n",
    "                node_type = \"bot\"\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                node_type = \"follower\"\n",
    "            \n",
    "            nodes.append([node_type,u.screen_name.encode('utf-8'),u.name.encode('utf-8'),u.id,\n",
    "                          u.location.encode('utf-8'),u.lang,u.time_zone,u.url,\n",
    "                          u.statuses_count,u.followers_count,\n",
    "                          u.friends_count,u.favourites_count,u.listed_count,\n",
    "                          u.created_at]) \n",
    "\n",
    "            if not u.id== id:\n",
    "            \n",
    "                edges.append([node_type,u.screen_name,\"follows\",\"bot\",screen_name,1])\n",
    "        \n",
    "        # combine the new edges and nodes into the big output\n",
    "        if big_nodes.empty:\n",
    "            big_nodes = DataFrame(nodes,columns=node_names)\n",
    "        else:\n",
    "            big_nodes = concat([big_nodes,DataFrame(nodes,columns=node_names)]).drop_duplicates()\n",
    "\n",
    "        if big_edges.empty:\n",
    "            big_edges = DataFrame(edges,columns=edge_names)\n",
    "        else:\n",
    "            big_edges = concat([big_edges,DataFrame(edges,columns=edge_names)])\n",
    "    \n",
    "    # and return both, wrapping them in a dictionary\n",
    "    return({\"nodes\":big_nodes,\"edges\":big_edges})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = grab_users([270315089,406926562],df[\"id\"],api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output stores an edges and a nodes data frame in a dictionary. We can output both and load them into Graph Commons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[\"edges\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[\"edges\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[\"nodes\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b[\"edges\"].to_csv(\"edges.csv\",index=False)\n",
    "b[\"nodes\"].to_csv(\"nodes.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to look at the activity of the bots. One idea would be to see what each bot is retweeting to get a sense of what kind of overlap you have. Here is one bot user (\"i\" becomes \"l\") -- [jennlferrothman](https://twitter.com/jennlferrothman). One of her retweets is to Chris Voss. Here is the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Its all right letting yourself go, as long as you can get yourself back.  Mick Jagger</p>&mdash; CHRIS VOSS (@CHRISVOSS) <a href=\"https://twitter.com/CHRISVOSS/status/829470715317465088\">February 8, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the other retweeters. Many have the patterns we look for, but none of them are in our collection of followers. This might be a way to expand the network we know about.\n",
    "\n",
    "In the next cells, we use the API to give us information about \"CHRISVOSS\" and to pull his timeline. This was code Mike gave you last Tuesday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(df[\"screen_name\"].str.contains(\"IloveLadyGaga92|Shawnie__ovoxo|Miss__Candass|TheHlllHaveEyes|AlexisApparell\",case=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get a user's profile ('CHRISVOSS' in this case)\n",
    "user = api.get_user(screen_name='CHRISVOSS')\n",
    "\n",
    "# print out some of the user's information\n",
    "print user.screen_name\n",
    "print user.id\n",
    "print user.statuses_count\n",
    "print user.friends_count\n",
    "print user.followers_count\n",
    "print user.description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pull all of CHRISVOSS' tweets, then if the retweet count is betwee 5 and 20, we pull the retweets of the tweet and for each we record the id of the retweeter, their screen name, their real name and the id of the tweet they retweeted. This will be written row by row and stored in a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vosslist = []\n",
    "\n",
    "for tweet in api.user_timeline(screen_name=\"CHRISVOSS\",count=50):\n",
    "    \n",
    "    if tweet.retweet_count > 5 and tweet.retweet_count <= 20:\n",
    "        retweets = api.retweets(tweet.id)\n",
    "    \n",
    "        for retweet in retweets:\n",
    "            vosslist.append([retweet.user.id,retweet.user.screen_name,retweet.user.name,tweet.id])\n",
    "\n",
    "voss = DataFrame(vosslist,columns=[\"id\",\"screen_name\",\"name\",\"retweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voss.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can see certain bots retweet this account more than others. Actually, are they all our bots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voss['screen_name'].value_counts().head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we pull our followers that retweeted CHRISVOSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[df[\"screen_name\"].isin(voss[\"screen_name\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below makes a large table of connections between Rosie's followers and their friends. It gives you a sense of how overlapping things are.\n",
    "\n",
    "**DON'T EXECUTE THIS CODE** It takes a while. I gave you what you need in the file you downloaded. You can read_csv it in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ONLY DO THIS ONCE!! After this you can just read_csv(\"savefollowers.csv\")!!!\n",
    "\n",
    "# from os.path import isfile\n",
    "# from json import loads\n",
    "# from pandas import DataFrame\n",
    "\n",
    "# load in the list of followers and then reverse the order so now\n",
    "# oldest followers are first and newest are last (we should have been\n",
    "# doing that all along -- although it's good to know about negative indices)\n",
    "\n",
    "followers = loads(open(\"rosie2/newfollowers.json\").read())\n",
    "followers.reverse()\n",
    "\n",
    "# initialize our two empty columns\n",
    "rosie_followers = []\n",
    "their_friends = []\n",
    "\n",
    "# loop over our follower ids for the first 2500 followers\n",
    "for id in followers[:2500]:\n",
    "    \n",
    "    filename = \"rosie2/friends/\"+str(id)+\".json\"\n",
    "    \n",
    "    if not isfile(filename):\n",
    "        continue\n",
    "    \n",
    "    friends_for_one_follower = loads(open(filename).read())\n",
    "\n",
    "    their_friends = their_friends + friends_for_one_follower\n",
    "    rosie_followers = rosie_followers + [id]*len(friends_for_one_follower)\n",
    "    \n",
    "# turn the two lists into a dataframe, each list is a column\n",
    "network = DataFrame({\"rosie follower\":rosie_followers,\"their friend\":their_friends})\n",
    "\n",
    "# and write it out!\n",
    "network.to_csv(\"rosie2/network_2500.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "network = read_csv(\"rosie2/network_2500.csv\")\n",
    "network.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network[\"rosie follower\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network[\"their friend\"].value_counts().head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
