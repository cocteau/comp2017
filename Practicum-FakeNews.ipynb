{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Announcement**\n",
    "\n",
    ">Monday 12:30-1:30, The Brown Institute\n",
    "<br><br>\n",
    "Our last Video Visionary is kind of terrifying. Heâ€™s Zohar Dayan, Co-founder and CEO of Wibbitz. You may know that Wibbitz is one of several   automated video platforms that create videos from text in a matter of seconds. Among their clients: Reuters and, most recently, the New York Daily News. \n",
    "<br><br>\n",
    "An existential threat to video journalists, or, as Zohar suggests, an exciting opportunity?  Decide for yourself as watch what this disruptive technology can do when Zohar feeds a text story into the Wibbitz platform and, seconds later, out pops a fully formed video. \n",
    "<br><br>\n",
    "\n",
    "Network stories\n",
    "----------------\n",
    "\n",
    "**Some \"Fake News\" News**\n",
    "\n",
    "We are expecting Google ClaimReview to debut tomorrow(ish). In the meantime, Facebook has annonced it is rolling out new tools against misinformation. In [a blog post](https://newsroom.fb.com/news/2017/04/a-new-educational-tool-against-misinformation/), they outline a new addition to your news feed. Here's a blurb and a screen shot.\n",
    "\n",
    "> As part of our ongoing efforts, weâ€™ve worked in consultation with First Draft, a non-profit dedicated to improving skills and standards in the reporting and sharing of information online, to roll out an educational tool to help people spot false news. Weâ€™re featuring this tool at the top of News Feed for a few days to people on Facebook in 14 countries.\n",
    "\n",
    "<img src=https://fbnewsroomus.files.wordpress.com/2017/04/in-feed-unit.png?w=600&h=1120 width=200>\n",
    "\n",
    "You can read about [the other steps Facebook is taking to combat \"false news\" here.](https://newsroom.fb.com/news/2017/04/working-to-stop-misinformation-and-false-news/)\n",
    "\n",
    "**Background on Today's Jamboree of Surprises**\n",
    "\n",
    "Today we are going to give you time to come up with a strategy for probing the evolution of #ricegate. The ways different news sites mobilize their readers (both real and robo) and link to other sites, creates a kind of communication drum beat that moves a story along. We are in the midst of the Susan Rice story, and it seems like an good time track what has been happening. Whether outright fake or just aggressively spun, the stories of Rice and \"unmasking\" Trump associates are dramatically different depending on the partisan leaning of the news organization. That said, the clearest recounting of the story I could find comes from a left-leaning publication. Here is a [Media Matters report on the \"Pro-Trump Propaganda Ecosystem.\"](https://www.mediamatters.org/blog/2017/04/05/susan-rice-unmasking-story-perfect-case-study-new-pro-trump-propaganda-ecosystem/215914) Here's how they see the evolution of a story from the right.\n",
    ">Often, a claim will start on a fringe outlet or forum, and other such sites will amplify the misinformation, then fake news purveyors will push it, and then the claim will jump into more traditional right-wing media before sometimes spreading into mainstream media. Trump aides and other people connected to Trump have even promoted some of those stories, crucially helping them break through at times.\n",
    "\n",
    "Let's focus for the moment less on the politics and more on the mechanics. For the Rice story, was there a \"fringe outlet\" involved? How did the story progress? If we were to track how it has evolved what would we do? Let me say, it has gone in a lot of directions and does start to strain the imagination..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">BREAKING NEWS! Obama administration spied on Sean Hannity and Erik Prince, per Chuck Johnson.</p>&mdash; Mike Cernovich ðŸ‡ºðŸ‡¸ (@Cernovich) <a href=\"https://twitter.com/Cernovich/status/849307209133678593\">April 4, 2017</a></blockquote>\n",
       "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Thank u all for heads up. I have zero knowledge of any surveillance vs me or unmasking of me by The Obama administration. Nothing shocks me!</p>&mdash; Sean Hannity (@seanhannity) <a href=\"https://twitter.com/seanhannity/status/849333293493489665\">April 4, 2017</a></blockquote>\n",
       "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">BREAKING NEWS! Obama administration spied on Sean Hannity and Erik Prince, per Chuck Johnson.</p>&mdash; Mike Cernovich ðŸ‡ºðŸ‡¸ (@Cernovich) <a href=\"https://twitter.com/Cernovich/status/849307209133678593\">April 4, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Thank u all for heads up. I have zero knowledge of any surveillance vs me or unmasking of me by The Obama administration. Nothing shocks me!</p>&mdash; Sean Hannity (@seanhannity) <a href=\"https://twitter.com/seanhannity/status/849333293493489665\">April 4, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task**\n",
    "\n",
    "Today we would like you to divide into groups and map out what you might look for to tell the story of this story. Where did it start? How was it spread? What signals do you find either on Twitter or some other source? Are there interesting voices? Is there any indication of robo help? How are \"memes\" conveyed? Are there images or video that are important? Links to news sites? Hashtags? Terms? How are they used?\n",
    "\n",
    "To help you, we have assembled a few sources. These either provide an explicit methodology or give you a kind reporting example, a template. Looking these over you can start to see how people take a network and turn it into data, and then into narrative. What kinds of things are interesting to know and how do you know them? Yes? OK!\n",
    "\n",
    "1. [Melissa Zimdars at Merrimack College](http://www.merrimack.edu/live/profiles/586-melissa-mish-zimdars) is a professor of communication and media and has assembled a set of strategies for identifying misinformation. [The long-ish document is here.](https://docs.google.com/document/d/10eA5-mCZLSS4MQY5QGb5ewC3VAL6pLkT53V_81ZyitM/preview) As part of her process, she compiled a list of news sites, categorizing them as \"fake\" or \"click-bait\" or legitimate. She wrote up her experiences in a Washington Post piece, [\"My â€˜fake news listâ€™ went viral. But made-up stories are only part of the problem.\"](https://www.washingtonpost.com/posteverything/wp/2016/11/18/my-fake-news-list-went-viral-but-made-up-stories-are-only-part-of-the-problem/?utm_term=.555c32b7e52b) And yes, her list is not without [its critics](http://www.washingtonexaminer.com/harvard-library-circulating-fake-news-list-which-of-course-includes-just-about-every-conservative-news-site/article/2617103).\n",
    "\n",
    "2. Less as a recipe and more as an existence proof, have a look at the ways in which people report on networks and the spread of misleading content. Here is a [news report on research from the Oxford Internet Institute](http://www.thedailybeast.com/articles/2016/11/17/how-pro-trump-twitter-bots-spread-fake-news.html). And here is [an original report from the institute.](http://politicalbots.org/?p=1096) How do they draw narrative out of Twitter? What do they say about the people and organizations involved? There is also an article from LSE on [mapping the \"news\" web sites themselves](http://blogs.lse.ac.uk/impactofsocialsciences/2017/02/06/three-ways-in-which-digital-researchers-can-shed-light-on-the-information-politics-of-the-post-truth-era/), which we will do more of next week.\n",
    "\n",
    "3. The International Journal of Communication had [a special issue devoted to computational propaganda.](http://ijoc.org/index.php/ijoc/issue/view/12#more4) The articles that might prove inspirational are [the introduction](http://ijoc.org/index.php/ijoc/article/view/6298), and a piece [analyzing bot code on GitHub](http://ijoc.org/index.php/ijoc/article/view/6136). \n",
    "\n",
    "4. And a piece in BuzzFeed about [fake news and ads](https://www.buzzfeed.com/craigsilverman/fake-news-real-ads?utm_term=.tsxX4d3dkX#.cxeEma8aKE) and another about [a master bot conductor.](https://www.buzzfeed.com/josephbernstein/from-utah-with-love?utm_term=.kaOZglyleZ#.orOX4emeMX)\n",
    "\n",
    "Here are some resources you might find helpful. \n",
    "\n",
    "1. [Media Bias/Fact Check](https://mediabiasfactcheck.com) maintains an extensive list of news sites and evaluates them based on their political leaning and their fact-worthiness. \n",
    "2. The list from Prof. Zimdars is also available in a more usable form (CSV or JSON) through [this web site.](http://www.opensources.co/)\n",
    "3. [Another list is curated by BuzzFeed](https://docs.google.com/spreadsheets/d/1sVFSHM7aITXE4QMNA7NIyPI8uYR1NHFiHHAMj5q3vKU/edit#gid=0) and was referenced in this article [on fake news and ads](https://www.buzzfeed.com/craigsilverman/fake-news-real-ads).\n",
    "3. A paper on [bot detection](http://arxiv.org/abs/1703.03107) by the group that brought you [BotOrNot](https://truthy.indiana.edu/botornot).\n",
    "\n",
    "To warm you up a little, one way in to a story might be using the fact-check details if one has been published. Perhaps there is a link to an originating web site, or perhaps there is a quote that can be tracked, or a statistic. Here we look at the one Rice fact-check we could find and try it out. (Your analysis should probably be a mix of hand searches and automated pulls.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_claim_info(url):\n",
    "    # make the request and run the page through BeautifulSoup\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "\n",
    "    claims = []\n",
    "    for claim_tag in soup.find_all(attrs={'itemtype': 'http://schema.org/ClaimReview'}):\n",
    "    \n",
    "        claim_reviewed = ''\n",
    "        claim_url = ''\n",
    "    \n",
    "        claim_reviewed_tag = claim_tag.find(attrs={'itemprop':'claimReviewed'})\n",
    "        if claim_reviewed_tag:\n",
    "            claim_reviewed = claim_reviewed_tag.get_text().strip()\n",
    "\n",
    "        # look for the itemReviwed\n",
    "        item_reviewed_tag = claim_tag.find(attrs={'itemprop':'itemReviewed'})\n",
    "        if item_reviewed_tag:\n",
    "\n",
    "            # look for the sameAs property\n",
    "            same_as_tag = item_reviewed_tag.find(attrs={'itemprop':'sameAs'})\n",
    "            if same_as_tag:\n",
    "                claim_url = same_as_tag['content']\n",
    "\n",
    "        claims.append((claim_reviewed, claim_url))\n",
    "\n",
    "    return claims\n",
    "\n",
    "\n",
    "url = 'http://www.snopes.com/bumble-bee-tuna-recall-human/'\n",
    "url = 'https://www.washingtonpost.com/news/fact-checker/wp/2017/04/05/epa-administrator-scott-pruitts-claim-that-clean-coal-helped-reduce-carbon-emissions/'\n",
    "url = 'https://www.washingtonpost.com/news/fact-checker/wp/2017/04/04/please-can-someone-brief-the-president-on-the-unemployment-rate/?utm_term=.20dfb0e12a5d'\n",
    "url = 'http://www.snopes.com/nancy-pelosi-arrested-coup-attempt/'\n",
    "url = 'http://www.snopes.com/crayola-retire-dandelion-crayon/'\n",
    "url = 'http://www.politifact.com/florida/statements/2017/apr/05/volusia-county-republican-party/did-us-department-education-introduce-islamic-indo/'\n",
    "url = 'http://www.snopes.com/arizona-drug-welfare-recipients/'\n",
    "url = 'http://www.politifact.com/california/statements/2017/apr/02/blog-posting/websites-spread-fake-news-nancy-pelosi-was-arreste/'\n",
    "url = 'http://www.snopes.com/hillary-clinton-uranium-russia-deal/'\n",
    "#url = 'https://www.washingtonpost.com/news/fact-checker/wp/2017/04/06/president-trumps-claim-without-evidence-that-susan-rice-may-have-committed-a-crime/?utm_term=.b62f92e4023d'\n",
    "\n",
    "claims = get_claim_info(url)\n",
    "print claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(claim_summary, same_as_url) = claims[0]\n",
    "#if same_as_url:\n",
    "    # e.g. http://thelastlineofdefense.org/breaking-nancy-pelosi-was-just-taken-from-her-office-in-handcuffs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before we can make Twitter API calls, we need to initialize a few things...\n",
    "from tweepy import OAuthHandler, API\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)\n",
    "type(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "same_as_url = 'http://thelastlineofdefense.org/breaking-nancy-pelosi-was-just-taken-from-her-office-in-handcuffs'\n",
    "\n",
    "slug = 'breaking-nancy-pelosi-was-just-taken-from-her-office-in-handcuffs'\n",
    "domain = 'thelastlineofdefense.org'\n",
    "\n",
    "terms = slug.split('-')\n",
    "\n",
    "query = ' '.join(terms)\n",
    "#query = same_as_url\n",
    "#query = domain+' pelosi'\n",
    "#query = 'breaking-nancy-pelosi-just-taken-office-handcuffs'\n",
    "#query = 'BREAKING: Nancy Pelosi Was Just Taken From Her Office In Handcuffs Responding To The Direct Order Of The President'\n",
    "#query = 'BREAKING: Nancy Pelosi Was Just Taken From Her Office In Handcuffs'\n",
    "#query = 'thelastlineofdefense.org pelosi'\n",
    "\n",
    "urls = []\n",
    "for tweet in api.search(query, result_type='recent', count=100):\n",
    "    print \"TWEET\", tweet.created_at, tweet.id_str, tweet.text, tweet.entities, '\\n'\n",
    "    for url_info in tweet.entities['urls']:\n",
    "        urls.append(url_info['expanded_url'])\n",
    "\n",
    "for url in urls:\n",
    "    print url\n",
    "    \n",
    "print 'done'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finish our warmup, we thought we'd remind you how to make simple time series plots using pandas and Plotly. Here we are looking for the hashtag #obamacabal. Not the most popular in the series, but one of the few circulating. Here we cycle through the search results and keep the text of the tweet and the time it was created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = \"#obamacabal\"\n",
    "\n",
    "times = []\n",
    "tweets = []\n",
    "\n",
    "for tweet in api.search(query, result_type='recent', count=200):\n",
    "    times.append(tweet.created_at)\n",
    "    tweets.append(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then turn it into a DataFrame, using the `tweets` list as a column called `text`. To be sly, we assign the index to be the times. This will let us use something called `TimeGrouper` to make counts by 15 minutes, hours, days, whatever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series,TimeGrouper, DataFrame\n",
    "\n",
    "df = DataFrame({\"text\":tweets},index=times)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `groupby()` and `agg()` as we did in the third trending lecture. We create counts in 15 minute intervals. The `agg()` function creates a multilevel index that we drop and then we move the times into a column, restoring  usual 0, 1, 2... index.\n",
    "\n",
    "And then we plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counts = df.groupby(TimeGrouper(freq='15min')).agg({\"text\":{\"counts\":\"count\"}})\n",
    "counts.columns = counts.columns.droplevel()\n",
    "counts = counts.reset_index()\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sign_in(\"cocteautt\",\"9psj3t57ti\")\n",
    "\n",
    "mydata = [go.Scatter(x=counts[\"index\"],y=counts[\"counts\"],mode=\"line\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
