{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">The Future is Highly Recommended </h1>\n",
    "<hr>\n",
    "<img src=\"https://gigaom.com/wp-content/uploads/sites/1/2011/02/3047760160_f869b55dda_z.png\" style=\"width: 55%;\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We live in a world where information production has multiplied exponentially. Ninety percent of the world's digital data was created in the last two years! What happens now? \n",
    "\n",
    "**Endless choice**. Never have we have we ever had so much choice in terms of news, information, music and entertainment. The \"democratisation\" of production means its easier than ever for people to create content. Sadly, this also means we are receiving more than we can consume -- it's even hard to know the full extent of the information being produced daily, its size and shape and inflection.\n",
    "\n",
    "In media circles, people refer to this moment of over-production as \"Peak Content,\" [the point at which this glut of things to read, watch and listen to becomes completely unsustainable](https://www.themediabriefing.com/article/peak-content-the-collapse-of-the-attention-economy). As a data person, I like the fact that this means more data... but our brains only have limited processing abilities.  \n",
    "\n",
    "**Attention**. In that sense, everything is competing for your attention, starting from museums to social networks to TV shows to your gaming console. The power of a connected world is obvious - we disseminate information, not just from consolidated systems but from the edges of the network. \n",
    "\n",
    "To prevent information overload, traditional curation has been the solution for a long time. But at some point, someone figured out that even curation can't keep up with this information age. People are different not in their fondness for the common or popular information, but in their affinity for very specific sections of the \"long tail.\" (\"The theory of the Long Tail is that our culture and economy is increasingly shifting away from a focus on a relatively small number of 'hits' -- mainstream products and markets -- at the head of the demand curve and toward a huge number of niches in the tail. [See Chris Anderson on the topic.](http://www.longtail.com/the_long_tail/faq/)) In other words, specific sections of the long tail can attract your attention more than the usual boring mainstream information.\n",
    "\n",
    "And thus began the age of internet information systems with the mission to give you **exactly** what you want. Yahoo! tried to do this using a directory structure that was larger selection of topics than newspaper beats. \n",
    ">\"In April 1994 David Filo and Jerry Yang created the Yahoo! Directory as a collection of their favorite web pages. As their number of links grew they had to reorganize and become a searchable directory.\" [From Search Engine History.](http://www.searchenginehistory.com/)\n",
    "\n",
    "And eventually, Google figured out technology to rank web sites satisfying your \"query\", a keyword or sentence. [See Brin and Page's \"In this paper we present Google...\"](http://infolab.stanford.edu/~backrub/google.html)\n",
    "\n",
    "**Can I make a recommendation?**. Search engines rose to prominence in the mid1990s promising to help users find almost anything on the Web. But there was one problem - *you still had to know what to search for.* This is what recommendation tries to solve. Given an existing data trail, the system is supposed to tell you how you might interact with the system next. For Google, this is recommending you a similar phrase to search. For Amazon, its recommending you a similar product to buy. For [Facebook, making sensible recommendations is their ultimate challenge](https://code.facebook.com/posts/861999383875667/recommending-items-to-more-than-a-billion-people). \n",
    "\n",
    "> There is a growing convergence of search and recommendations. In fact, recommender algorithms tie together three key themes that form a kind of technical oligopoly that dominates the market for your attention: (1) search engines, (2) recommendation systems and (3) smart push notifications. \n",
    "\n",
    "As you can see, it seems like humans have become comfortable offloading as much of their decision making to software as possible, in many cases (like shopping, travel) at least. So recommendation systems became the norm of internet websites. Thus arose an entire field of computing around recommender systems, and there is an [entire ACM conference dedicated](https://recsys.acm.org/) to it. I always find it fascinating how much Computer Science as an academic field is driven by what the industry needs.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Ok - so in this session, we will consider some key aspects of recommender systems, play around with data and explore the features that an optimal news recommendation system should possess! We will cover the following things:\n",
    "\n",
    "1. Examples/Impact of recommendations \n",
    "2. Ways to recommend\n",
    "3. Is news recommendation is unique problem\n",
    "4. Make your own recommendation engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Why this item isn't the most important - it's the next one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most imporant article on your website is the second article that someone reads. If that next article is also as good as the current one, then you’ve established something meaningful. Thats how the user will start trusting you. \n",
    "\n",
    "\n",
    "- **Site Walk**. For many original content sites, only 10% of visits are organically to the homepage of content sites. (This is certainly not the way it used to be when the web was young and shiny! Why is it true now?) The vast majority of people spend time on the content pages (which may or may not be linked on homepage). The journey from one article to another is important. This means the power of internal suggestion tools in a website is more critical than anything else. \n",
    "\n",
    "\n",
    "- **High Engagement**. The ability to make relevant suggestions is at the core of any content business. Looking at Netflix, their recommender system is used on most screens of the product beyond the homepage, and on average influences about 80% of the hours of content they stream.  (Curious where the other 20% comes from?) \n",
    "\n",
    "\n",
    "- **\\$\\$ utility**. The combined effect of personalization and recommendations is to increase engagement levels and reduce churn significantly. Is the effect of recommendations measurable? Yes - this saves Netflix more than \\$1B per year. You can read more here: [The Netflix Recommender System: Algorithms, Business Value, and Innovation](http://dl.acm.org/citation.cfm?id=2843948)\n",
    "\n",
    "\n",
    "- **Mix with curation**. In many of the world's most beloved services, recommendations play an invisible yet unrelenting role that is not only critical in keeping consumers happy, but also necessary in scaling the underlying information systems. Here's [how Spotify chooses what makes it onto your Discover Weekly playlist](http://www.wired.co.uk/article/tastemakers-spotify-edward-newett)\n",
    "\n",
    "\n",
    "- **Personal/Privacy**. Also, recall that recommendations are customized to YOU and so use a lot of they collect about you -- including, but not limited to, your usage history of the service -- and thus, can be deeply personal.\n",
    "<br><br>\n",
    "<img src = \"https://imgs.xkcd.com/comics/pandora.png\">\n",
    "<br><br>\n",
    "Want to know *everything* that you've done in Google lately. [Here you go](https://myactivity.google.com/myactivity). \n",
    "\n",
    "\n",
    "- One <font color='red'>warning</font>: Recommendations re-order the set of all possible answers to a question by relevance (creating a list of books or web sites or movies or songs). If you interact with that list by picking the TOP answer - then you have created a kind of algorithmic personal assistant. \n",
    "<br><br>\n",
    "This is how Siri or Alexa or Google Home decides on the ONE answer it gives you - it searches the world, aggregates all candidate (relevant) stories, orders them by RECOMMENDED STORIES and then picks the first one! Of course, other signals might be involved (like the device you are using) but that core process needs to be run. And [when this recommendation list goes wrong, ONE true answers turn nasty](http://searchengineland.com/googles-one-true-answer-problem-featured-snippets-270549)\n",
    "\n",
    "\n",
    "- Ok one more <font color='red'>warning</font>: What happens when we recommend \"similar\" things? We end up in a bubble. Trusting recommendations blindly is what people do, without knowing how its made or the internal biases it has. That in turn leads to [rating bubbles.](http://sloanreview.mit.edu/article/the-problem-with-online-ratings-2/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How to recommend the next one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Your data format/content item structure matters.** Almost every company uses some kind of machine learning with whatever format of data their product generates to recommend items from their inventory. Here are some links on how these individual products \"do\" recommendation. Let's each pick one and skim the techniques and then talk about it.\n",
    "\n",
    " 1.  Pins - [PInterest](https://medium.com/@Pinterest_Engineering/pinnability-machine-learning-in-the-home-feed-64be2074bf60#.6906fsamn)\n",
    " 2. Videos -  [YouTube](https://pdfs.semanticscholar.org/e7d5/3f538f5239739d1f943c81d17e4a167c65c6.pdf)\n",
    " 3. Communities - [Reddit](http://jaybaxter.net/redditrecommender.pdf)\n",
    " 4. Music - [Pandora](https://arstechnica.com/tech-policy/2011/01/digging-into-pandoras-music-genome-with-musicologist-nolan-gasser/)\n",
    " 5. Rentals - [AirBnb](https://www.forbes.com/sites/ellenhuet/2015/06/05/how-airbnb-uses-big-data-and-machine-learning-to-guide-hosts-to-the-perfect-price/#30975ecf6d49)\n",
    " 6. Job profiles - [LinkedIn](https://blog.linkedin.com/2011/03/02/linkedin-products-you-may-like)\n",
    " 7. Search - [Google Now](http://dl.acm.org/citation.cfm?id=2959192)\n",
    " 8. Social NewsFeeds - [Facebook](http://science.sciencemag.org/content/348/6239/1130)\n",
    " 9. Travel/Flights - [Expedia](https://techblog.expedia.com/2016/03/07/how-expedia-finds-flights-a-detailed-view/)\n",
    " 10. Your shopping cart - [Amazon](http://www.cs.umd.edu/~samir/498/Amazon-Recommendations.pdf)\n",
    "\n",
    "\n",
    "- **Data generating products:** The beauty of designing a system is that you can nudge the users to CREATE data that assists future recommendations. Everything from \"Like\" buttons to how long they spend on a particular article can be used to model their affinity and predispositions. Designers spend a lot of time doing this, so interactions become feedback.\n",
    "\n",
    "\n",
    "- **Filtering:** Filtering the right items can make your recommendations much more useful and improve user experience.\n",
    " 1. Something that's not an item: Don't recommend videos in a articles feed, maybe make a new landing page. \n",
    " 2. Something that is stale/not applicable anymore: Don't recirculate old relevance.  \n",
    " 3. Something the user has already seen: Been there, done that. \n",
    " 4. Something that can offend an user: Careful. \n",
    " 5. Something that miscalculates user-topic granularity: Don't recommend Android news to Apple fans, although both are in tech.\n",
    "\n",
    " 6. *....  your recommendations for filtering here*\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Notable Algorithms and Mechanisms:\n",
    "\n",
    "There are two widely used ideas for recommendation. The limiting factor, as you've guessed already, is the data that you are capturing. Here's why:\n",
    "\n",
    "- **Topic level modeling.** The first way is super simple: observe the **semantics** of content that the user is reading, and recommend her something similar. In other words, recommend an user reading about Messi more stories about Messi or Soccer or Sports etc. \n",
    "\n",
    "- **User co-interaction modeling**. The second method models users by their similar actions in a content space. For example, imagine users P1,P2 and P3 reads articles X,Y,Z,P,Q. Now assume a new user P4 reads article X,Y,Z and P. There is a high chance that user P4 can be recommended article Q because other users with the same pattern have read it. *If you eyebrows are raised thats totally valid*\n",
    "\n",
    "So what are techniques formally called: \n",
    "\n",
    "| Technique | Basic Idea | Limitations |\n",
    "| ------ | ----------- |\n",
    "|[Collaborative Filtering](https://en.wikipedia.org/wiki/Collaborative_filtering)   |  If a person L has the same opinion as person S on an issue (or issues), L is more likely to have S's opinion on a different issue than that of a randomly chosen person. | [Cold Start](https://en.wikipedia.org/wiki/Cold_start)|\n",
    "|[Semantic Analysis](https://en.wikipedia.org/wiki/Semantic_similarity) | If we can find the category of content a person likes, we can suggest him similar items from related categories.  | Learning new topics. | \n",
    "|[Hybrid](http://techblog.netflix.com/2012/04/netflix-recommendations-beyond-5-stars.html)   | Combine previous two approaches | Balance is tough. |\n",
    "|[A/B Testing ](http://blog.yhat.com/posts/the-beer-bandit.html)   | Start with random choice, improve probability of recommending with click rate | Initial votes matter more.\n",
    "\n",
    "Both topic and user co-interaction modeling have a common drawback: The **Rich get Richer** Effect. \n",
    "Two great related reads: \n",
    "1. [How recommenders (among other things) lead to the downfall of Blockbuster](http://pubsonline.informs.org/doi/abs/10.1287/mnsc.1080.0974), \n",
    "2. [Analyzing the Youtube video recommendation and how it affects video views](https://www.cl.cam.ac.uk/~jac22/camhor/mia_imc07_sumitted.pdf) \n",
    "\n",
    "\n",
    "Hybrids are incredibly powerful when tuned properly, and sometimes can [transform products](https://www.nytimes.com/2014/03/07/business/media/the-sweet-streaming-sound-of-data.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. A word on Metrics\n",
    "    \n",
    "Clearly none of these models will work unless we can assign a score to each and every item (whether its a news article or song or a movie). How you design these metrics or scores plays a huge role in what gets recommended. \n",
    "\n",
    "<img src = \"https://imgs.xkcd.com/comics/star_ratings.png\">\n",
    "\n",
    "*<u>How <font color= red> NOT </font>to score a Rating!! </u>* But what should we do? Here are some examples. Suggest more!\n",
    "\n",
    "- Score = (total_positive_ratings - total_negative_ratings)\n",
    "\n",
    "- Score = (total_positive_ratings / all_ratings)\n",
    "\n",
    "- *Your exercise: Find our the optimal metric by which ratings should be score*\n",
    "\n",
    "\n",
    "\n",
    "Make sure in an attempt to do things like [reverse engineering Hollywood](https://www.theatlantic.com/technology/archive/2014/01/how-netflix-reverse-engineered-hollywood/282679/), we don't imbue a ratings system with bias. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Issues in News Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Surprise: You only want to scroll to find the next interesting thing. \n",
    "\n",
    "\n",
    "- The Long Tail: Enjoyment of a product is much less dictated by the median experience, but instead by the outliers. The barrier to this long tail market is contextual knowledge, specific to you and your interests at this moment in time.\n",
    "\n",
    "\n",
    "- Editors vs. Algorithms: Battle of the Ages. \n",
    "\n",
    "\n",
    "- Segment Recommendation vs. Personalization: is your cohort size =1 ? \n",
    "\n",
    "\n",
    "- Filter Bubble vs. Engagement: The reality is [people REALIZE the consequences with personalized recommendations, but they still want them](http://digitalnewsreport.org/essays/2016/people-want-personalised-recommendations/)\n",
    "\n",
    "\n",
    "- Diversity vs. Irrelevance: Surprise vs. why are you showing me this? \n",
    "\n",
    "\n",
    "- Cold start: I don't know enough about the user to recommend anything \n",
    "\n",
    "\n",
    "- Serendipity: or giving the appearance of serendipitious information discovery. \n",
    "\n",
    "\n",
    "- Robustness: Gaming a recommender system or resistence to [media hacking](https://render.betaworks.com/media-hacking-3b1e350d619c#.njy9cij35). \n",
    "\n",
    "\n",
    "- Trust: A recommender explaining itself! (*Because you watched the matrix*)\n",
    "\n",
    "\n",
    "- Privacy: *[you might also like.. privacy risks in collaborative filtering](https://www.cs.utexas.edu/~shmat/shmat_oak11ymal.pdf)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Building your own news recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some data from digg's channels -- these are URLs in the movies, music, politics and TV verticals of digg. We collect this links through our Facebook API, by polling certain entities that we track, e.g., Bernie Sanders etc. We also get some meta data with these links, like the likes, shares, comments etc. \n",
    "\n",
    "This is how the data looks -- it's 225K urls. [Download the file from here](http://sumandebroy.com/columbia/page_2_topics_dump.json.zip) and move it to the folder where this notebook resides. Or use urlretrieve() from the urllib module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Below we load up all the  modules we need.\n",
    "\n",
    "import pandas\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by reading in the JSON data from Suman -- we are using `load()` rather than `loads()` because we are passing an open file, `page_2_topics_dump.json`. We could read the contents of a file into a string and use `loads()` too. All roads..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.load(open('page_2_topics_dump.json'))\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we get a list. Here's the first element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as a list, the important question to ask is \"How many such items do you contain, oh list?\". Here we find nearly 260K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the 101st entry. Compare it to the first (above). What do you notice? Anything in common? What is each entry in the list `data`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give that each entry in the list is a dictionary with the same keys, we can use `DataFrame()` to create a DataFrame out of it. Each element in `data`, each list element, becomes a row in the DataFrame. So we've made DataFrames out of dictionaries of lists (each list is a column, keys in the dictionary are column names), and now we are making a DataFrame from a list of dictionaries (each list element is a row, the keys are again referencing columns). See [Mr. Data Converter](https://shancarter.github.io/mr-data-converter/) for more examples!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tables tables...\n",
    "topics = pandas.DataFrame(data)\n",
    "topics.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh the joy! Now that we have a DataFrame again, we can make simple counts of the categorical variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what vertical/channel are all these articles in? \n",
    "topics['vertical'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 57K articles about movies, 106K articles about music, 65K about poltiics and 29K about TV. What about the popular \"domains\" (the lead part of a URL)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what are the most popular domains..\n",
    "print topics['domain'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a LOT of \"URL shortner\" domains here (t.co, bit.ly, trib.al, etc.), so let's get around that by extracting the real URL. Here's a handy library. We will work instead with the `url` column now and pull offjust the domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urlparse import urlparse\n",
    "test_url = \"http://thehill.com/blogs/blog-briefing-room/news/283330-former-gop-senator-endorses-clinton-after-orlando-shooting\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass it through the parser. It gives you access to the domain (net location), the path inside the domain and any queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print urlparse(test_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do you get the domain? (That was the goal.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print urlparse(test_url).netloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK with that in hand, we can run down the `url` column of the `topics` DataFrame and convert each entry. We will use the `apply()` method that essentially applies the indicated function to each element in the column. We then assign the result to a new column in `topics` called `cleanDomain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def justdomain(test_url):\n",
    "    # a function to pull out just the domain\n",
    "    return urlparse(test_url).netloc\n",
    "\n",
    "topics[\"cleanDomain\"] = topics[\"url\"].apply(justdomain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the shiny new column at the end of the table! Here we look at the first five rows that have to do with politics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[topics[\"vertical\"]==\"politics\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the top domains in all topics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topics[\"cleanDomain\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and just hte top in politics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[ topics['vertical']=='politics' ][\"cleanDomain\"].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domains havechanged a fair bit. Now they refer to news outlets, primarily. Alright, let's look at the other columns. Here we look at the topic -- how many unique topics are we tracking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[\"topic\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[\"topic\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or how many unique URLs (links) doe we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics[\"url\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Ranking \n",
    "\n",
    "At the core of most information systems you encounter on the Web, from search engines to social network newsfeeds to shopping recommendations, is the concept of *Ranking*. We saw that a recommendation engine is producing a ranking as well. This is a common need, and the idea is simple. You could give the user all the content in the world, but clearly he/she does not have time or capacity to consume that. So you have to select what to show *first*. And thus, you have to rank all the content by some parameter, depending on what sort of data features your products have. \n",
    "\n",
    "Try searching something on Google:\n",
    "\n",
    "<img src = \"http://i.imgur.com/thQGPdj.gif\">\n",
    "\n",
    "Notice the footer mentioning the incredibly large number of results the query retrived. Clearly, if Google showed you 10 of those links at random on the front page, it wouldn't be the product it is today. So it has to somehow figure which 10 stories are most relevant or which 10 stories *you are most likely to click* on the front page.\n",
    "\n",
    "As an aside, search results were not always lists. Early on, Altavista had \"live topics\" that allowed for a graph based display of content, a \"dynamic categorisation of results\". [Read more here](http://www.ariadne.ac.uk/issue9/search-engines).\n",
    "\n",
    "![live](http://www.ariadne.ac.uk/images/issue9-search-engines/lt2.gif)\n",
    "\n",
    "Anyway...\n",
    "\n",
    "- The enormous power of these ranking systems come from the intelligence of their algorithms. Think about the Facebook newsfeed: What if it always showed you photos of friends you don't care about? Think of Netflix: What if it recommended movies you didn't care about? Think about Amazon: What if its recommended \"next buy\" is completely different than what you are browsing, and not in a compelling way? Information systems are powerful because there is a core technology that is ranking. \n",
    "\n",
    "- And if that algorithm works, it can [topple empires](http://infolab.stanford.edu/pub/papers/google.pdf) \n",
    "\n",
    "\n",
    "- Research indicates that [91% of searchers do not go past page 1 of the Google search results](https://www.utwente.nl/nl/bms/cw/bestanden/Using%20the%20Internet-%20Skill%20related%20problems.pdf), and  50% do not go past the first 3 results on page 1. Imagine [the competiton to get in that top-3](https://en.wikipedia.org/wiki/Search_engine_optimization). \n",
    "\n",
    "\n",
    "- Google did a lot of research on this. They found people will actually *rewrite* a search query phrase rather than go into the second page. \n",
    "\n",
    "\n",
    "- And as you have seen in 2016, stories that appears on newsfeeds can reshape realities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to build a recommendation engine using the digg links. Once the user enters a link, your goal is to build a recommendation engine that suggests the next link and prioritizes some feature in doing so. For example, the next recommended link can be ranked based on: \n",
    "\n",
    " 1. The top publishers\n",
    " 2. The comment score of articles\n",
    " 3. Similar words in the content\n",
    " 4. Similar topics\n",
    " 5. The number of likes the article got\n",
    " 6. Is it fresh (timestamp)?\n",
    " 7. The number of times the article was shared \n",
    " 8. *You decide*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 4.2 A very simple topic link recommender \n",
    "\n",
    "Let's map out a simple strategy for making recommendations. Fun!\n",
    "- Ask user for a topic. \n",
    "- Recommend 3 links, relevant to topic and \"recent\" \n",
    "- *you can keep stacking rules here*\n",
    "\n",
    "We are going to take a query and remove \"stop words\" -- if someone is looking for \"donald or hillary\" we will look for \"donald\" or \"hillary\" and leave out the word \"or\" from our query. You can add to this list or take from it as you like. [I picked it up from here.](http://www.ranks.nl/stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stoplist = [\"I\", \"a\", \"about\", \"an\", \"are\", \"as\", \"at\", \"be\", \"by\", \"for\", \"from\", \"how\", \"in\", \"is\", \"it\", \"of\", \"on\", \"or\", \"that\", \"the\", \"this\", \"to\", \"was\", \"what\", \"when\", \"where\", \"who\", \"will\", \"with\", \"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a function that takes in a query (a string of words) and the `topics` DataFrame and then the stoplist. If you leave it out, it will just take the empty list and drop no words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_links_by_topic(query,data,stop=[]):\n",
    "   \n",
    "    # split the query string into separate words (textblob could be used too)\n",
    "    # and make them lowercase. love list comprehensions!\n",
    "    queryterms = query.split(\" \")\n",
    "    queryterms = [q.lower() for q in queryterms if not q in stop]\n",
    "\n",
    "    regex = \"|\".join(queryterms)\n",
    "    print regex\n",
    "    \n",
    "    # find topics matching the query, case-insensitive match -- uses .contains()\n",
    "    matches = data[data[\"topic\"].str.contains(regex,case=False)]\n",
    "    \n",
    "    print 'Found ', matches.shape[0],' candidate links about ', query\n",
    "        \n",
    "    # sort by time -- newest first \n",
    "    matches = matches.sort_values(by=\"timestamp\",ascending=False)\n",
    "    \n",
    "    #recommendation 1:  top 3 most recent\n",
    "    return matches[[\"title\",\"topic\",\"url\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try the recommendation\n",
    "pandas.set_option(\"display.max_colwidth\",300)\n",
    "           \n",
    "recommend_links_by_topic('donald trump',topics,stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_links_by_topic(query,data,stop=[]):\n",
    "   \n",
    "    # split the query string into separate words (textblob could be used too)\n",
    "    # and make them lowercase. love list comprehensions!\n",
    "    queryterms = query.split(\" \")\n",
    "    queryterms = [q.lower() for q in queryterms if not q in stop]\n",
    "\n",
    "    regex = \"|\".join(queryterms)\n",
    "    print regex\n",
    "    \n",
    "    # find topics matching the query, case-insensitive match -- uses .contains()\n",
    "    matches = data[data[\"topic\"].str.contains(regex,case=False)]\n",
    "    \n",
    "    # limit it to video sites\n",
    "    matches = matches[matches[\"cleanDomain\"].isin(['youtube.com', 'vimeo.com'])]\n",
    "    \n",
    "    print 'Found ', matches.shape[0],' candidate links from video sites about ', query\n",
    "        \n",
    "    # sort by time -- newest first -- \n",
    "    matches = matches.sort_values(by=\"timestamp\",ascending=False)\n",
    "    \n",
    "    # recommendation 3: most recent but only videos\n",
    "    return matches[[\"title\",\"topic\",\"url\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_links_by_topic('donald trump',topics,stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommend_links_by_topic(query,data,stop=[]):\n",
    "   \n",
    "    # split the query string into separate words (textblob could be used too)\n",
    "    # and make them lowercase. love list comprehensions!\n",
    "    queryterms = query.split(\" \")\n",
    "    queryterms = [q.lower() for q in queryterms if not q in stop]\n",
    "\n",
    "    regex = \"|\".join(queryterms)\n",
    "    print regex\n",
    "    \n",
    "    # find topics matching the query, case-insensitive match -- uses .contains()\n",
    "    matches = data[data[\"topic\"].str.contains(regex,case=False)]\n",
    "    \n",
    "    # limit it to the top 20 popular domains\n",
    "    popsites = data[\"cleanDomain\"].value_counts()[:20].index\n",
    "    matches = matches[matches[\"cleanDomain\"].isin(popsites)]\n",
    "    \n",
    "    print 'Found ', matches.shape[0],' candidate links from popular sites about ', query\n",
    "        \n",
    "    # sort by time -- newest first -- \n",
    "    matches = matches.sort_values(by=\"timestamp\",ascending=False)\n",
    "    \n",
    "    # recommendation 3: most recent and only from top-20 most popular sites\n",
    "    return matches[[\"title\",\"topic\",\"url\"]][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recommend_links_by_topic('donald trump',topics,stoplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how to get an url without the parameters ??\n",
    "url = 'http://www.nbcnews.com/video/dear-mr-president-letters-from-the-american-people-856106563921/?cid=sm_fb_msnbc'\n",
    "urlparse(url).netloc+urlparse(url).path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Case Studies - When Recommendation becomes News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [The Hollywood Reporter](https://medium.com/@wfhorn/keep-reading-the-story-of-a-nascent-recommendation-engine-fe84a81248c9#.vzs3rtn8w)\n",
    "2. [The NY Times](https://open.blogs.nytimes.com/2015/08/11/building-the-next-new-york-times-recommendation-engine/)\n",
    "3. [Clavis - WashingtonPost](http://knightlab.northwestern.edu/2015/06/03/how-the-washington-posts-clavis-tool-helps-to-make-news-personal/)\n",
    "4. [Apple News](https://www.theguardian.com/technology/2015/jun/16/apple-news-app-editors-curation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Collaborative Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we will take up a very different approach to making recommendations -- rather than judge things based on qualities of the items we have to served up (movies, books, links) we will look to other users of the system for help. When someone read a particular news article, what other articles did they read? Users with similar preferences will be grouped together and their selections used to make recommendations. This is called collaborative filtering, although the collaboration is not exactly genuine. The first example of collaborative filtering was in an email context in 1992! [You can read it here.](http://dl.acm.org/citation.cfm?id=138867)\n",
    "\n",
    "It's worth trying to think what kinds of interactions might we base this kind of user clustering on. What data would Pinterest or Spotify or The New York Times have on you?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
