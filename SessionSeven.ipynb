{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All about (or a lot about... or some about) bots!\n",
    "\n",
    "Today we wanted to give you a little overview of the kinds of bots that are circulating in the world, providing a taxonomy, if you will, of all the innovative work being done. But first, what is a bot? \n",
    "\n",
    "We'll draw mostly from [botnerds.com](http://botnerds.com) and the [article by Mark Sample](https://medium.com/@samplereality/a-protest-bot-is-a-bot-so-specific-you-cant-mistake-it-for-bullshit-90fe10b7fbaa#.ikymcdf6q). The former reference offers a practical definition...\n",
    ">Bots are software programs that perform automated, repetitive, pre-defined tasks.  These tasks can include almost any interaction with software that has an API.\n",
    "\n",
    "...while Mark Sample is more aspirational.\n",
    ">A computer program that reveals the injustice and inequality of the world and imagines alternatives. A computer program that says who’s to praise and who’s to blame. A computer program that questions how, when, who and why. A computer program whose indictments are so specific you can’t mistake them for bullshit. A computer program that does all this automatically.\n",
    "\n",
    "![Bot](http://21clradio.com/wp-content/uploads/2016/02/Kiddle-Logo.png)\n",
    "\n",
    "First, the practical. Our first reference divides bots into \"Good\" and \"Bad\" categories (sorry Kasiana), which are interpreted largely in terms of their effect on our information ecosystem -- functionally, adding or detracting.\n",
    "\n",
    "1. Good Bots\n",
    "    * **Chatbots** \"are designed to carry on conversations with humans, usually just for fun, and to test the limits of the technology.\"\n",
    "    * **Crawlers** \"run continuously in the background, primarily fetch data from other APIs or websites, and are *well-behaved* in that they respect directives you give them\"\n",
    "    * **Transactional bots** act as agents on behalf of humans, and interact with external systems to accomplish a specific transaction, moving data from one platform to another.\"\n",
    "    * **Informational bots** \"surface helpful information, often as push notifications, and are also called *news bots*.\"\n",
    "    * **Art bots** \"are designed to be appreciated aesthetically.\"\n",
    "    * **Game bots** \"game bots function as characters, often for humans to play against or to practice and develop skills...\"\n",
    "2. Bad Bots\n",
    "    * **Hackers** \"distribute malware of all kinds\"\n",
    "    * **Spammers** \"steal content (email addresses, images, text, etc)from other website\", often to republish it\n",
    "    * **Scrapers** post \"promotional content around the web, and ultimately drive traffic to the spammer’s website\"\n",
    "    * **Impersonators** \"mimic natural user characteristics, making them hard to identify\" (they cite [political propadanda bots](http://www.businessinsider.com/political-bots-by-governments-around-the-world-2015-12/#mexico-1))\n",
    "    \n",
    "In terms of Bot Agency or Bot Intelligence, this framing presents examples along a spectrum -- Script Bots, Smart Bots and Intelligent Agents. An interaction with a Script Bots, they write, is\n",
    "\n",
    ">based off of a pre-determined model (the “script”) that determines what the bot can and cannot do.  The “script” is a decision tree where responding to one question takes you down a specific path, which opens up a new, pre-determined set of possibilities. \n",
    "\n",
    "Upping the autonomy a little, Smart Bots have access to other APIs that expand the universe of responses.\n",
    "\n",
    ">Many bots have a heavy server-side processing component, which allows them access to massive computing power in understanding and responding to queries.  Couple that with the open-sourcing of AI software libraries like Theano and TensorFlow, and you have the ingredients for some amazing human-bot interactions.\n",
    "\n",
    "This category also allows for human-assisted interactions. The bot need not act alone, but can invoke human intelligence or even direct consultation, redirecting the interaction to a responsible human. Finally, the Intelligent Agent is meant to act autonomously.\n",
    "\n",
    "> If operating correctly, they should require no human intervention in order to perform their tasks correctly.  Google’s self-driving cars are designed without steering wheels for humans, because they shouldn’t be necessary.  x.ai has a bot that schedules meetings for you, Amy Ingram, and she manages all the back-and-forth with zero oversight.\n",
    "\n",
    "Mark Sample provides a different, less practical characterization of bots, one drawn more from literary studies (where bots have been an object of fascination for some time). He focuses on one particular kind of bot (primarily active on Twitter) that he terms \"Protest Bots\" or \"Bots of Conviction\". Sample says they share at least five characteristics: \n",
    "\n",
    "* **Topical** - \"They are about the morning news — and the daily horrors that fail to make it into the news.\"\n",
    "* **Data-based** - \"[They don’t make this [stuff] up. They draw from research, statistics, spreadsheets, databases.\" \n",
    "* **Cumulative** - [It is the nature of bots to do the same thing over and over again, with only slight variation...  The repetition builds on itself, the bot relentlessly riffing on its theme, unyielding and overwhelming, a pile-up of wreckage on our screens.\"\n",
    "* **Oppositional** - \"[B]ots of conviction challenge us to consider our own complicity in the wrongs of the world.\"\n",
    "* **Uncanny.** - \"Protests bots often reveal something that was hidden; or conversely, they might purposefully obscure something that had been in plain sight.\"\n",
    "\n",
    "The examples of Protest Bots that Sample introduces are often journalistic, but often more in the realm of advocacy. Still, the examples open up the potential to the kinds of projects or actions that can be taken outside the more functional description of our first reference. \n",
    "\n",
    "This weekend, you will be imaginging and making your own bots and we hope this outline has helped prime the pump. We will be on this topic for another week or so and will, with Suman, venture into the area of converational bots.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Our Bot Account & App\n",
    "\n",
    "**1) Create a New Twitter User for Your Bot**\n",
    "\n",
    "Before we get started, you'll want to create a new Twitter account for your bot! It's best to not create a bot out of your personal Twitter account, but I will leave that up to you!\n",
    "\n",
    "Go to [https://twitter.com/signup](https://twitter.com/signup) (you'll have to log out of your normal account or go incognito) and create a new account. **You will need to use your phone number when siging up** or you wont be able to create a new Twitter app in next step.\n",
    "\n",
    "\n",
    "**2) Create a New Twitter App for Your Bot**\n",
    "\n",
    "You are a pro at this! Once you have created your new Twitter account, create a new Twitter app for your bot.\n",
    "\n",
    "1. Go to [https://apps.twitter.com](https://apps.twitter.com/) and log in with your *personal* Twitter user account. 2. Click “Create New App”\n",
    "3. Fill out the form, agree to the terms, and click “Create your Twitter application”\n",
    "4. Click on “Keys and Access Tokens” tab, and copy your “API key” and “API secret”. Scroll down and click “Create my access token”, and copy your “Access token” and “Access token secret”.\n",
    "\n",
    "Once you have your tokens, copy them below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# insert your own keys and secrets here...or just use Mark's! he won't mind\n",
    "CONSUMER_KEY = \"\"\n",
    "CONSUMER_SECRET = \"\"\n",
    "ACCESS_TOKEN = \"\"\n",
    "ACCESS_TOKEN_SECRET = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# before we can make Twitter API calls, we need to initialize a few things...\n",
    "from tweepy import OAuthHandler, API\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)\n",
    "\n",
    "# call the \"me\" api to make sure you using the Twitter api as your bot\n",
    "print 'Ok, we are ready to tweet as ' + api.me().screen_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Send a Tweet From Our Bot!\n",
    "\n",
    "We will be using the `statuses/update` api to send the tweet: https://dev.twitter.com/rest/reference/post/statuses/update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# your bot's first tweet\n",
    "api.update_status(status='hello world!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Great! Now let's take a quick detour....\n",
    "\n",
    "In a few minutes, we are going to create a simple \"news\" bot: a bot that tweets out the latest stories from The New York Times. But, how are we going to get the NYTimes latest stories? Let's turn to [RSS](https://en.wikipedia.org/wiki/RSS).\n",
    "\n",
    "Most news sites on the internet publish an RSS feed. Here are a few:\n",
    "\n",
    "[New York Times \"HomePage\"](http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml)\n",
    "\n",
    "[Wired](https://www.wired.com/feed/)\n",
    "\n",
    "[WNYC Radio Lab Podcast](http://feeds.wnyc.org/radiolab)\n",
    "\n",
    "To use RSS feeds in our code, we're going to use the python module called [Feedparser](https://pypi.python.org/pypi/feedparser). `Feedparser` does the hard work of fetching and parsing the feeds for us. RSS feeds can be very messy and this module does an amazing job of dealing with the mess and handing us a nice python object (`dictionary`) to work with! \n",
    "\n",
    "Let's install the module and start working with some RSS feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following to install the `feedparser` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install feedparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at a short example of how we can fetch the RSS feed for The New York Times \"HomePage\" stories.\n",
    "\n",
    "The \"HomePage\" RSS feed can be found here: [http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml](http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml)\n",
    "\n",
    "The code below uses the `feedparser` module to fetch the RSS feed (remember HTTP requests?), parse it and return it as a python dictionary. This module does the hard work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's fetch the New York Times Homepage RSS Feed\n",
    "import feedparser\n",
    "\n",
    "# the URL of the homepage stories RSS feed\n",
    "nytimes_rss_url = 'http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml'\n",
    "\n",
    "# fetch the RSS feed and parse it\n",
    "feed = feedparser.parse(nytimes_rss_url)\n",
    "\n",
    "# what type of object are we dealing with?\n",
    "print type(feed)\n",
    "print feed.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `feed` information..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print feed['feed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets look at the `entities`, which is a list of the stories found in the feed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now, let's print out the stories (titles and urls) in the RSS feed\n",
    "for entry in feed['entries']:\n",
    "    print entry['title']\n",
    "    print entry['link']\n",
    "    print '--'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a break from \"news\" and look at the RSS feed for [Atlas Obscura](http://www.atlasobscura.com/) (a lovely site about travel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "rss_url = 'http://www.atlasobscura.com/feeds/latest'\n",
    "feed = feedparser.parse(rss_url)\n",
    "\n",
    "for entry in feed['entries']:\n",
    "    print entry['title']\n",
    "    print entry['link']\n",
    "    print '---'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OK, Let's Get Back to Our Bot!\n",
    "\n",
    "If we wanted to tweet out the latest story from Atlas Obscura, we combine our Twitter and our RSS/feedparser examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler, API\n",
    "import feedparser\n",
    "\n",
    "# setup the authentication\n",
    "auth = OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "\n",
    "# create an object we will use to communicate with the Twitter API\n",
    "api = API(auth)\n",
    "\n",
    "# now, get the Atlas Obscura feed\n",
    "rss_url = 'http://www.atlasobscura.com/feeds/latest'\n",
    "feed = feedparser.parse(rss_url)\n",
    "\n",
    "# let's take only the 1st story in our list\n",
    "first_story = feed['entries'][0]\n",
    "\n",
    "# now, create the text of the tweet using the story title and link/url\n",
    "tweet_text = 'This is really interesting! ' + first_story['title'] + ' ' + first_story['link']\n",
    "print tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# and now, tweet it!\n",
    "api.update_status(status=tweet_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Up: Let's Clone the @twoheadlines Bot\n",
    "\n",
    "[Darius Kazemi](https://twitter.com/tinysubversions) created a clever bot called [@twoheadlines](https://twitter.com/twoheadlines) where he combines two different headlines in to a single tweet:\n",
    "\n",
    "> Comedy is when you take two headlines about different things and then confuse them\n",
    "\n",
    "Let's do a simple clone of the `@twoheadlines` bot by combining the first half of a New York Times headline with the second half of a Breitbart headline :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import feedparser\n",
    "\n",
    "# fetch the nytimes and breitbart RSS feeds\n",
    "nytimes_rss_url = 'http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml'\n",
    "breitbart_rss_url = 'http://feeds.feedburner.com/breitbart'\n",
    "\n",
    "nytimes_feed = feedparser.parse(nytimes_rss_url)\n",
    "breitbart_feed = feedparser.parse(breitbart_rss_url)\n",
    "\n",
    "# get the first story from each of the two feeds\n",
    "nytimes_first_story = nytimes_feed['entries'][0]\n",
    "breitbart_first_story = breitbart_feed['entries'][0]\n",
    "\n",
    "print 'nyt: '+ nytimes_first_story['title']\n",
    "print 'b: ' + breitbart_first_story['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine the two headlines into a single headline\n",
    "nytimes_words = nytimes_first_story['title'].split(' ')\n",
    "breitbart_words = breitbart_first_story['title'].split(' ')\n",
    "\n",
    "# take the 1st half of the nytimes \"words\" plus the second half of the breitbart \"words\n",
    "new_words = nytimes_words[:len(nytimes_words)/2] + breitbart_words[len(breitbart_words)/2:]\n",
    "\n",
    "# this is python weirdness to take a list of words\n",
    "# and join them together with a space between each word\n",
    "new_headline = ' '.join(new_words)\n",
    "print new_headline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now, your bot can tweet the combined headline! **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.update_status(status=new_headline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, that's cute but how can we create a long-running bot?\n",
    "\n",
    "Everything we've done up to now just runs once and then exits/stops. Let's look at how we can have something run forever - our bot doesn't need to sleep much!\n",
    "\n",
    "Python has a great [`time`](https://docs.python.org/2/library/time.html), which handles various time-related functions (duh!). The `time` module also has a very helpful method called `sleep()`, which tells our program to sleep, or \"pause\", for a number of seconds. Let's take a look at it:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the time module allows us to \"sleep\" or pause for a given number of seconds\n",
    "import time\n",
    "\n",
    "# loop 10 times, pausing for 1 second during each iteration\n",
    "for number in range(0, 10):\n",
    "    print number\n",
    "    \n",
    "    # sleep for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "print 'done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add a simple \"forever\" loop to get our script to run until we stop it. The code below will loop forever, pausing for 1 second, until you hit the stop button in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the time module allows us to \"sleep\" or pause for a given number of seconds\n",
    "import time\n",
    "\n",
    "# loop forever!\n",
    "while True:\n",
    "    print 'hello'\n",
    "    \n",
    "    # sleep for one second\n",
    "    time.sleep(1)\n",
    "    \n",
    "# to get this to stop, hit the Stop button in your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Let's put it all together and build our news bot\n",
    "\n",
    "This is a very simple \"news\" bot, which will tweet out new top stories from The New York Times. The bot will check the NYTimes HomePage RSS feed every 10 seconds - if it sees a new story, it will tweet it.\n",
    "\n",
    "I'm also adding some super complicated AI, to add some color-commentary to each story that our bot tweets.\n",
    "\n",
    "This code uses a new module called [`random`](https://docs.python.org/2/library/random.html), which makes it easy to randomly select an item from a `list`.\n",
    "\n",
    "*So you don't put extra stress on The New York Times servers, you should sleep every 60 seconds (at least). We are only sleeping for 10 seconds here for demo purposes.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this \"bot\" will tweet out any new stories published in the nytimes homepage\n",
    "import time    \n",
    "import feedparser\n",
    "import random\n",
    "\n",
    "insightful_things_to_say = [\n",
    "    'this is really interesting',\n",
    "    'great read -->',\n",
    "    'hmmm....',\n",
    "    'amazing',\n",
    "    'how does this happen?',\n",
    "]\n",
    "\n",
    "nytimes_rss_url = 'http://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml'\n",
    "\n",
    "# keep track of the previous nytimes link/url that we tweeted\n",
    "prev_tweeted_link = ''\n",
    "\n",
    "# loop forever!\n",
    "while True:\n",
    "    \n",
    "    # fetch and parse the NYTimes RSS feed\n",
    "    nytimes_feed = feedparser.parse(nytimes_rss_url)\n",
    "\n",
    "    # get the first story\n",
    "    first_story = nytimes_feed['entries'][0]\n",
    "\n",
    "    # take the link of the first story and see if we've tweeted it before\n",
    "    link = first_story['link']\n",
    "    if link != prev_tweeted_link:\n",
    "        # it's new, lets tweet it out!\n",
    "        print 'new story - lets tweet it: ' + link\n",
    "  \n",
    "        # build the text of our tweet\n",
    "        tweet_text = random.choice(insightful_things_to_say) + ' ' + first_story['title'] + ' ' + first_story['link']\n",
    "        \n",
    "        # fire it off to twitter\n",
    "        api.update_status(status=tweet_text)\n",
    "        \n",
    "        # keep track of the this link that we just tweeted\n",
    "        prev_tweeted_link = link\n",
    "    else:\n",
    "        # we've already tweeted this...no new stories\n",
    "        # nothing to do\n",
    "        print 'no new story...lets wait a little while'\n",
    "\n",
    "    # sleep for a little while\n",
    "    time.sleep(10)\n",
    "\n",
    "    \n",
    "# if you want to stop this script, hit the Stop button in your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some computing tools for programming with \"language\"\n",
    "\n",
    "The Twitter bot Mike prepared relies on mashing up two headlines. Some of that might get better if we knew a little about what the headline described. What is the subject? What action is described? Some of these questions are addressed by a field of computer science (well, computational linguistics) called Natural Language Processing. There are plenty of tools in Python for making use of the fruits of this research. \n",
    "\n",
    "We will be using a package called [TextBlob](https://textblob.readthedocs.io/en/dev/) that is a simplified version of the Natural Language Toolkit in Python. (Sometimes tools become really powerful for practitioners and leave non-experts behind. That's what has happened, to some extent, with the NLTK. It's a little hard to just \"jump in\". And so TextBlob is like computational training wheels.) [Allison Parrish's Natural Language Basics with TextBlob](http://rwet.decontextualize.com/book/textblob/) is a great place to read about what TextBlob is good for. \n",
    "\n",
    "First, we need to install the package. Off to PIP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import download\n",
    "download('brown')\n",
    "download('punkt')\n",
    "download('maxent_ne_chunker')\n",
    "download('words')\n",
    "download('conll2000')\n",
    "download('maxent_treebank_pos_tagger')\n",
    "download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the package for this session and bring in a headline from todays New York Times. We read it in as a string but preface the quotes with a \"u\". That tells Python the string is in Unicode -- publishers use fancy quotation marks, for example, that are not the simple \" or '. \n",
    "\n",
    "The TextBlob() function takes text and turns it into a \"TextBlob\" object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "headline = u\"After Election, Trump’s Professed Love for Leaks Quickly Faded\"\n",
    "tb = TextBlob(headline)\n",
    "\n",
    "type(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TextBlob object has a number of attribures that have processed the text. The simplest are lists of words and sentences. Here we pull just the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is obviously a better approach than the one we took when we just split a string on spaces -- a technique that didn't handle punctuation like commas and periods well. OK that's a good trick but there are better ones! For example, TextBlob's language processing let's it estimate which words are part of noun phrases. \n",
    "\n",
    "There are various techniques for doing this and none of them are perfect. To be fair, using a headline means using a text fragment and not a sentence. The language processing tools are usually trained on full sentences of text. Still, it's not bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noun phrases are obtained by extracting information from a \"tagged\" version of the text. Here the tags represent parts of speech. You can see [a complete list of the tags here.](https://cs.nyu.edu/grishman/jet/guide/PennPOS.html) The parts of speech are stored as a list of word-tag pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(tb.tags[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .tags attribute is a list. (See the square brackets?) The list elements are a new data type called a \"tuple\" which is like a list, for our purposes. So you can take, say the first element of the tags list and look at the first and second elements of the tuple (the word and its estimates part of speech)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.tags[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.tags[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I'm not wild about it, TextBlob also provides an estimate of the sentiment of the statement. That is, is the text expressing a positive or negative sentiment. I'll leave you to consult the Parrish blog post or the TextBlob documentation of this lovely feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the same thing to a different headline. Mashing them up might mean replacing one noun phrase with another. How might you do that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headline2 = u\"Trump Vows to Catch ‘Low Life Leakers’ in Washington D.C.\"\n",
    "tb2 = TextBlob(headline2)\n",
    "tb2.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb2.noun_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing. There are various methods to \"parse\" text -- different algorithms for tagging words in a sentence, for extracting noun phrases and for estimating sentiment. You can replace the default when you call TextBlob. The documentation describes other noun phrase extractors. Here's how you would use the ConllExtractor, based on a data set compiled for the Conference on Computational Natural Language Learning (CoNLL-2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob.np_extractors import ConllExtractor\n",
    "extractor = ConllExtractor()\n",
    "\n",
    "tb = TextBlob(headline,np_extractor=extractor)\n",
    "tb.noun_phrases"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
