{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=http://static.politifact.com.s3.amazonaws.com/politifact/photos/fake.png width=300>\n",
    "\n",
    "\n",
    "# \"Fake news\"\n",
    "\n",
    "In this last phase of the semester, we will take our skills in analyzing text, in web scraping, in network tracing, in bot mobilizing, and even in machine learning, and apply them to two case studies. The first will be so-called \"fake news.\" Yes, the term has been so over-used as to become meaningless, but there is a circle of ideas around the term that are reasonably well-defined.\n",
    "\n",
    "Our good friends at FirstDraft have tried to provide some [structure to the term](https://firstdraftnews.com/fake-news-complicated/), laying groundwork for research and for investigations like ours. Robyn Caplan already discussed their breakdown of mis- or disinformation, their matrix of \"problematic content.\"<br><br>\n",
    "<img src=https://firstdraftnews.com/wp-content/uploads/2017/02/FDN_7Types_Misinfo-01-1024x576.jpg width=500>\n",
    "<br><br>\n",
    "(Seems like red is the dominant accent color for fake news critiques.) The horizontal scale describes the intent of the author, their \"intent to deceive.\" FirstDraft breaks this intention down further, categorizing the motivation for creating and circulating content into the eight P's -- \"Poor Journalism, Parody, to Provoke or ‘Punk’, Passion, Partisanship, Profit, Political Influence or Power, and Propaganda.\"\n",
    "\n",
    "When it comes to identifying fake news or misinformation, FirstDraft advocates a personal practice of skeptical reading. Given the bubbles and echo chambers we live in (remember how recommender systems work, and then there's the fact that we read a lot of news that is shared by our like-minded friends), be on guard for information that might sound too good to you. And independently verify what you are reading. \n",
    "\n",
    "In light of all this fakery, fact checking has taken on new importance since the election (heck, in the last 24 hours!). April 2 was the first [International Fact-Checking Day](http://factcheckingday.com/). It was initiated by Poynter and included events like a \"fact-check-a-thon,\" tutorials on how to spot fake news, and a [Hoax-Off](http://factcheckingday.com/hoax-off). Politifact's contribution to the day was [the analysis of a recent fake news story](http://www.politifact.com/california/statements/2017/apr/02/blog-posting/websites-spread-fake-news-nancy-pelosi-was-arreste/) about [Nansy Pelosi being arrested.](http://thelastlineofdefense.org/breaking-nancy-pelosi-was-just-taken-from-her-office-in-handcuffs/).\n",
    "\n",
    "Fact checking can be a laborious process and there have been attempts to automate it. Here is a nice summary of [the state of fact checking.](https://fullfact.org/media/uploads/full_fact-the_state_of_automated_factchecking_aug_2016.pdf) But it is not clear whether fact-checking alone is able to stop the spread of disinformation. Brooke Borel for FiveThirtyEight writes about [all the forces that counteract simple fact-checking.](https://fivethirtyeight.com/features/fact-checking-wont-save-us-from-fake-news/) And ultimately, as danah boyd points out, [we are at war.](http://www.zephoria.org/thoughts/archives/2017/01/27/the-information-war-has-begun.html)\n",
    "\n",
    "Borel cites algorithmic recommender systems and other dissemination strategies that make fake news particularly hard to stop. We have seen misinformation spread by networks of bots, [through advertising](https://www.wired.com/2016/12/fake-news-will-go-away-tech-behind-ads-wont-pay/) and through [promotion by the influential (or infamous)](http://web.archive.org/web/20161107234222/https:/twitter.com/GenFlynn/status/794000841518776320). In the second part of our investigation, we will look at how fake news spreads, dusting off our network graphing skills. We have already seen, for example, how [YouTube's recommender system deals in fake news.](https://medium.com/the-graph/youtubes-ai-is-neutral-towards-clicks-but-is-biased-towards-people-and-ideas-3a2f643dea9a)\n",
    "\n",
    "As a preview, consider a site like [Hoaxy](http://hoaxy.iuni.iu.edu/) that uses lists of fake news content and tracks the spread of URLs on social media (um, Twitter). This is a platform that you could easily make (and make better, I'm sure). There is also a machine learning (AI) [Fake News Challenge](http://www.fakenewschallenge.org/). \n",
    "\n",
    "<img src=http://www.fakenewschallenge.org/assets/img/wordcloud_lg.png width=300>\n",
    "\n",
    ">The goal of the Fake News Challenge is to explore how artificial intelligence technologies, particularly machine learning and natural language processing, might be leveraged to combat the fake news problem. We believe that these AI technologies hold promise for significantly automating parts of the procedure human fact checkers use today to determine if a story is real or a hoax.\n",
    "\n",
    "Of course this is an incredibly hard problem, one with deep epistemologial roots, and so the challenge has softened slightly to instead automate components that can be used to identify fake news. \"Stance detection,\" testing whether the headline of a story and its contents agree.\n",
    "\n",
    "We will also look at how large companies like Facebook and Google are addressing the problem. Today, we'll see Google's ClaimReview markup, a technique for spreading fact-checking that introduces new UI into GoogleNews -- to be released Friday! (In a recent post, danah boyd argues that [this kind of effort won't \"solve\" the problem.](https://backchannel.com/google-and-facebook-cant-just-make-fake-news-disappear-48f4b4e5fbe8) Eli Pariser, of The Filter Bubble fame, has created [an open GoogleDoc to focus attention on possible design solutions.](https://docs.google.com/document/d/1OPghC4ra6QLhaHhW8QvPJRMKGEXT7KaZtG_7s5-UQrw/edit#heading=h.1suoz8sco476) There are great ideas here and its structure is extremely helpful. \n",
    "\n",
    "Finally, as a flip to automated detection, we will see how AI or machine learning might start to play a role in how fake news is generated. We are probably well-aware of companies like [Narrative Science](https://www.narrativescience.com/) that turn data into stories. \n",
    "\n",
    ">Narrative Science is humanizing data like never before, with technology that interprets your data, then transforms it into Intelligent Narratives at unprecedented speed and scale. With Narrative Science, your data becomes actionable—a powerful asset you can use to make better decisions, improve interactions with customers and empower your employees.\n",
    "\n",
    "Their work is largely rule-based (think Eliza) but is rapidly incorporating learned elements. More recently, companies like [Wibbitz](http://www.wibbitz.com/) have gone farther, creating more elaborate media elements from data. Or in this case, video from text.\n",
    "\n",
    ">Video is essential to survive in the digital media landscape. Consumers want engaging video content accessible on every device and advertising budgets are rapidly shifting to video. Wibbitz automatically creates videos from text articles in seconds, allowing our partners to scalably increase premium video inventory.\n",
    "\n",
    "Is this the future? Mounds of misinformation created automatically, spread automatically? \n",
    "\n",
    "## Short fact-checking case study\n",
    "\n",
    "In honor of the first Fact-Checking Day, Politifact had a look at a fake news story about Nancy Pelosi. Before we consult Google News for the story, let's dust off our skills with AutoComplete and see what comes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "params = {\n",
    "    'client': 'firefox',\n",
    "    'ds':'n',\n",
    "    'q': \"Nancy Pelosi\"\n",
    "}\n",
    "\n",
    "url_params = urllib.urlencode(params)\n",
    "url = 'http://suggestqueries.google.com/complete/search?%s' % urllib.urlencode(params)\n",
    "\n",
    "r = requests.get(url)\n",
    "data = r.json()\n",
    "    \n",
    "search_term = data[0] \n",
    "results = data[1]\n",
    "\n",
    "for result in results:\n",
    "    print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, that's too bad. \n",
    "\n",
    "If you go to Google News and [conduct a search for 'Nancy Pelosi arrested'](https://www.google.com/search?hl=en&gl=us&tbm=nws&authuser=0&q=nancy+pelosi&oq=nancy+pelosi&gs_l=news-cc.3..43j0l9j43i53.1528.5256.0.6498.18.9.2.7.4.0.147.716.7j2.9.0...0.0...1ac.1.DMePDr5D3RM#hl=en&gl=us&authuser=0&tbm=nws&q=nancy+pelosi+arrested&*) you will find a Politifact blog post (the one we are basing this little detour on). Interestingly, the headlines from places like Snopes don't indicate strongly that the story is fake (although Politifact's rather large \"FAKE\" PNG for this story does the trick nicely). When it comes to surfacing fact-checks on articles, Google is not \"expressive\" enough -- it's user interface groups articles and fact-checking articles together in a flat way. I believe this is the motivation for their new markup offering that will help identify fact-checks in an article. \n",
    "\n",
    "Today's lesson is on so-called microformats that search engines have popularized to help them better categorize the kind of data they are indexing. [Here is a great Search Engine Land story on them.](http://searchengineland.com/schema-markup-structured-data-seo-opportunities-site-type-231077) Mike will walk you through the history of this effort, but for the moment, trust us that there is an extension to HTML that let's you encode extra information about the text on a web page. They offer a tool to explore the structure of these additions. [Here is a view of the Politifact story](https://search.google.com/structured-data/testing-tool/u/0/#url=http%3A%2F%2Fwww.politifact.com%2Fcalifornia%2Fstatements%2F2017%2Fapr%2F02%2Fblog-posting%2Fwebsites-spread-fake-news-nancy-pelosi-was-arreste%2F)\n",
    "\n",
    "On the left is the source of the story and on the right is an example of structured data found in the HTML page. The categories on the right indicate that the kind (type) of data is a ClaimReview (Google's idea of a fact-check), and there is an indication of what claim is being checked and by whom. Have a read over the categories. Oh and notice that there's even an error -- big, professional publishers also make mistakes! It is with this extra information that Google will be unveiling a new display mechanism for fact-checks -- we are told, Friday(ish). [Richard Gingras comments:](https://blog.google/topics/journalism-news/labeling-fact-check-articles-google-news/)\n",
    "\n",
    ">In the seven years since we started labeling types of articles in Google News (e.g., In-Depth, Opinion, Wikipedia), we’ve heard that many readers enjoy having easy access to a diverse range of content types. Earlier this year, we added a “Local Source” Tag to highlight local coverage of major stories. Today, we’re adding another new tag, “Fact check,” to help readers find fact checking in large news stories. You’ll see the tagged articles in the expanded story box on news.google.com and in the Google News & Weather iOS and Android apps, starting with the U.S. and the U.K.\n",
    "\n",
    "Because microdata, and metadata before it, are important for web scraping, we will go over these now. They are also going to be useful for fact-checking. Our friends at Google suggested that it might be useful to see how an organization indicates in the markup what claim is being checked and compare that to the body text. It might also be useful to see what kinds of facts are being checked. We are told that the following web sites are using Google's ClaimReview microdata markup.\n",
    "\n",
    "1. Snopes\n",
    "2. NYT fact-check\n",
    "3. WaPo fact-check\n",
    "4. FullFact.org\n",
    "5. GossipCop\n",
    "6. Politifact (maybe 80% ish)\n",
    "7. Factcheck.org (more hit or miss)\n",
    "\n",
    "With this in mind, how would you find fact-checking articles? What strategy would you follow? The text added to a web page is exactly what you saw on the righthand side of the Google \"Structured Data\" tool. In particular, you'll find a reference to \"ClaimReview\" in the source of the HTML page. So with that hint, how would you find fact-checking articles? Give it a try!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Metadata on the Web\n",
    "\n",
    "Before we look at the ```ClaimReview``` markup that publishers are starting to put in their pages, we're going to take a quick historical view of metadata on the web. As Mark mentioned, data within web pages (the \"metadata\") can be a rich source of information. Most of this is used by search engines, Facebook, Twitter, etc - but it's also available for you! Let's take a quick spin through the past ~15 years and look at how metadata on the web has changed. And, we're going to write a little HTML on the way :-0\n",
    "\n",
    "**Let's travel back in time... to the year 2000...**\n",
    "\n",
    "Imaging that we are going to start a technology news web site and put it on the world-wide-web, information super-highway thing. We start off by creating a web page that links to some of the big technology stories of the day, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "        <title>My Technology News Site</title>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "        <div>\n",
    "            <div><strong>Steve Jobs introduces the public beta of Mac OS X</strong></div>\n",
    "            <div>Sept 13, 2000 - Steve Jobs <a href=\"https://www.apple.com/pr/library/2000/09/13Apple-Releases-Mac-OS-X-Public-Beta.html\" target=\"_blank\">introduces</a> the public beta of Mac OS X for US$29.95.</div>\n",
    "            <div>Author: Michael Young</div>\n",
    "        </div>\n",
    "    </body\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "We send the link to our new site to our family and friends, and we have a handful of people reading it (well, two people really: our mom and the dog).\n",
    "\n",
    "**So, now we want more people to read it!**\n",
    "\n",
    "What's the best way to have more people discover this site in 2000? **Search.** And, by that I mean Google (which had launched a few years earlier in 1998). Let's ignore ~~Yahoo!~~ Oath for now, but it was a real player in search in the early days of the web.\n",
    "\n",
    "Our good friend, the SEO Guru, told us we needed to do some work on our site so that we could move up in the rankings. After talking to the \"guru\", we learned to help Google by telling them a little about our humble news site using the **```meta```** ```keywords``` and ```description``` tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "        <title>My Technology News Site</title>\n",
    "        <meta name=\"description\" content=\"My Technology News Site has the most interesting technology stories every day.\">\n",
    "        <meta name=\"keywords\" content=\"tech, news, super important tech news, technology, technology news\">\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "        <div>\n",
    "            <div><strong>Steve Jobs introduces the public beta of Mac OS X</strong></div>\n",
    "            <div>Sept 13, 2000 - Steve Jobs <a href=\"https://www.apple.com/pr/library/2000/09/13Apple-Releases-Mac-OS-X-Public-Beta.html\" target=\"_blank\">introduces</a> the public beta of Mac OS X for US$29.95.</div>\n",
    "            <div>Author: Michael Young</div>\n",
    "        </div>\n",
    "    </body\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "To review (in case of web technology circa 2000 is feeling slightly remote):\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The **```keywords```** metadata is used to tell search engines about the topic of the page.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The **```description```** metadata is used to describe the site and this is what search engines use in their search results.\n",
    "\n",
    "A **key point** to remember: none of this data is viewable by users. It's for machines.\n",
    "\n",
    "Here is example of the ```description``` tag in use: \n",
    "\n",
    "![description](https://qph.ec.quoracdn.net/main-qimg-2c6dddd356b26ca0763241db501f52f8)\n",
    "\n",
    "**Great!**\n",
    "\n",
    "Google now knows a little about us and is ranking our site a bit higher in the search results for \"technology news.\" Because of that, we have a few more people showing up at our site.\n",
    "\n",
    "Over the next few years, we expand our little tech news site in to listing events as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "        <title>My Technology News Site - Events in San Francisco</title>\n",
    "        <meta name=\"description\" content=\"My Technology News Site has the most interesting technology stories and events.\">\n",
    "        <meta name=\"keywords\" content=\"tech, news, super important tech news, technology, technology news, technology events, events, San Francico, Silicon Valley\">\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "        <div>\n",
    "            <div><strong>Macworld Expo San Francisco</strong></div>\n",
    "            <div>January 5-9, 2004</div>\n",
    "            <div>Moscone Convention Center, San Francisco, CA</div>\n",
    "        </div>\n",
    "    </body\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Questions**: how does a search engine know that this site/page is really about technology? How does it know it's an event listing? Does anyone see how this metadata approach could be abused?\n",
    "\n",
    "\n",
    "### 2. Microformats\n",
    "\n",
    "Around 2005, a group of people came up with the notion of a \"Microformat.\" The idea was to use additional markup in HTML to allow machines to easily discover data inside HTML (like our calendar event or news story). Simply put, _Microformats are a way to use html pages as both a human readable document and machine readable data, without repetition._\n",
    "\n",
    "The idea was originally a grassroots movement from developers but it was soon supported by some search engines and browers. It was never part of a standards body though - just an \"informal\" specification. [Microformats](http://microformats.org/wiki/Main_Page) are still used and supported but as we'll see, new metadata formats came along...\n",
    "\n",
    "Microformats allowed developers to highlight specific elements/types of content within a page, such as:\n",
    "\n",
    "```\n",
    "hAtom - blog posts and other date-stamped content\n",
    "hCalendar - events\n",
    "hCard - people, organizations, contacts\n",
    "hListing - listings for products or services\n",
    "hMedia - media info about images, video, audio\n",
    "hProduct - products\n",
    "hRecipe - cooking+baking recipes\n",
    "hResume - individual resumes and CVs\n",
    "hReview - individual reviews and ratings\n",
    "hReview-aggregate - aggregate reviews and ratings\n",
    "adr - address location information\n",
    "geo - latitude & longitude location (WGS84 geographic coordinates)\n",
    "```\n",
    "\n",
    "**What good does this do? What can we do with Micoformats?**\n",
    "\n",
    "A few things:\n",
    "1. Search engines now have help in knowing what a page, or data within a page, is about.\n",
    "2. Search engines can use this markup to know what to show in something like a \"rich snippet.\"\n",
    "3. Browsers started adding the ability to do things like detect an event in a page and allow a user to add it to their calendar (or a person's information to their Address book).\n",
    "\n",
    "Make sense? Let's revisit our event listing by using the `hCalendar` microformat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "        <title>My Technology News Site - Events in San Francisco</title>\n",
    "        <meta name=\"description\" content=\"My Technology News Site has the most interesting technology stories and events.\">\n",
    "        <meta name=\"keywords\" content=\"tech, news, super important tech news, technology, technology news, technology events, events, San Francico, Silicon Valley\">\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "        <div class=\"vevent\">\n",
    "            <div class=\"summary\"><strong>Macworld Expo San Francisco</strong></div>\n",
    "            <div>\n",
    "                 <span class=\"dtstart\" title=\"2004-01-05\">January 5</span>-\n",
    "                 <span class=\"dtend\" title=\"2005-01-09\">9, 2004</span>\n",
    "            </div>\n",
    "            <div class=\"location\">Moscone Convention Center, San Francisco, CA</div>\n",
    "        </div>\n",
    "    </body>\n",
    "\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Enter Microdata (and others)\n",
    "\n",
    "Over the coming years, other metadata approaches emerged such as [Microdata](http://schema.org/) (Google and other search engines), [OpenGraph](http://ogp.me/) (Facebook), [TwitterCards](https://dev.twitter.com/cards/overview) (Twitter) and others (RDF, [RDFa](https://rdfa.info/)). These were created and driven by various standard bodies, commercial interests (publishers, social networks, search engines, browsers) and developers. Again, the goal of these were to make it easier for machines to make sense of the data published inside web pages and to use that data to help display, rank and make publisher's content easier to interact with.\n",
    "\n",
    "We're going to focus on [Microdata](https://www.w3.org/TR/microdata/) for the rest of the class, but it's worth looking in to the others as well.\n",
    "\n",
    "Similar to Microformats, Microdata is defined as: _This specification defines the HTML microdata mechanism. This mechanism allows machine-readable data to be embedded in HTML documents in an easy-to-write manner, with an unambiguous parsing model. It is compatible with numerous other data formats including RDF and JSON._\n",
    "\n",
    "Though `Microdata` is not an official spec of *The W3C* (_The W3C HTML Working Group failed to find an editor for the specification and terminated its development with a 'Note'._) it is supported by Google, Microsoft, Yahoo and Yandex. In fact, these companies came together to create a vocabulary (specification, essentially) around microdata that is published at http://schema.org/. These companies have tried to establish and open forum and community-based process for updating the vocabulary/specification.\n",
    "\n",
    "Let's look at an example of how microdata works. We'll start by looking at a **Movie**. Here is some simple HTML that display's information about the movie Avatar. Go ahead and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<div>\n",
    "    <h1>Avatar</h1>\n",
    "    <div>Director: James Cameron (born August 16, 1954)</div>\n",
    "    <div>Science Fiction</div>\n",
    "    <div><a href=\"../movies/avatar-theatrical-trailer.html\">Trailer</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adding Microdata to our HTML\n",
    "\n",
    "We want to let Google and the search engines know what this is information about a movie.\n",
    "\n",
    "**Step 1**: Identify which section is about the Movie 🎥\n",
    "\n",
    "Add the **`itemscope`** attribute to the HTML element which encloses the information about the movie.\n",
    "\n",
    "```html\n",
    "<div itemscope>\n",
    "    ...Movie info here...\n",
    "</div>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<div itemscope>\n",
    "    <h1>Avatar</h1>\n",
    "    <div>Director: James Cameron (born August 16, 1954)</div>\n",
    "    <div>Science fiction</div>\n",
    "    <div><a href=\"../movies/avatar-theatrical-trailer.html\">Trailer</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Step 2**: Specify the type (i.e. this thing is a Movie)\n",
    "\n",
    "Now, add the **`itemtype`** attribute right after the **`itemscope`** and specify the type. When specifying the type, you can use any of the types listed on [schema.org](http://schema.org/docs/full.html)\n",
    "\n",
    "```html\n",
    "<div itemscope itemtype=\"http://schema.org/Movie\">\n",
    "    ...Movie info here...\n",
    "</div>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<div itemscope itemtype=\"http://schema.org/Movie\">\n",
    "    <h1>Avatar</h1>\n",
    "    <div>Director: James Cameron (born August 16, 1954)</div>\n",
    "    <div>Science fiction</div>\n",
    "    <div><a href=\"../movies/avatar-theatrical-trailer.html\">Trailer</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Step 3**: Use the **`itemprop`** attribute to specify properties about the Movie.\n",
    "\n",
    "Nothing has changed visually on the page, but we've told search engines that this section of the page is about a Movie. Google thanks you! Can we go further with the [Movie type](http://schema.org/Movie)? How would we tell Google which of these fields is the movie name, directory and genre? We can do this using the **`itemprop`** attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<div itemscope itemtype=\"http://schema.org/Movie\">\n",
    "    <h1 itemprop=\"name\">Avatar</h1>\n",
    "    <div>Director: James Cameron (born August 16, 1954)</div>\n",
    "    <div>Science fiction</div>\n",
    "    <div><a href=\"../movies/avatar-theatrical-trailer.html\">Trailer</a></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You Try It\n",
    "\n",
    "Edit the HTML above and specify which fields are the directory, genre and trailor. Reference the [Movie documenation on schema.org.](http://schema.org/Movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HOLD THE PHONE!\n",
    "\n",
    "So, this is one of three flavors of microdata. The others being [RDFa](https://rdfa.info/) and [JSON-LD](http://json-ld.org/spec/latest/json-ld/) (where \"LD\" is \"linked data\"). \n",
    "\n",
    "The search engines support all three formats but Google [recently said](https://developers.google.com/search/docs/guides/intro-structured-data) JSON-LD is their recommended format.\n",
    "\n",
    "Some publishers use the Microdata HTML markup, some use JSON-LD. It's a bit of the wild west out there. For the examples in this notebook, we'll stick with the HTML markup. However, if you were to take our Movie example from above and express it as JSON-LD, it would look something like this:\n",
    "\n",
    "```json\n",
    "<script type=\"application/ld+json\">\n",
    "{\n",
    "  \"@context\": \"http://schema.org\",\n",
    "  \"@type\": \"Movie\",\n",
    "  \"name\": \"Avatar\",\n",
    "  \"genre\": \"Science Fiction\",\n",
    "  \"director\": {\n",
    "    \"@type\": \"Person\",\n",
    "    \"name\": \"James Camerom\",\n",
    "  },\n",
    "}\n",
    "</script>\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at a different type: LocalBusiness 🏢\n",
    "\n",
    "Schema.org specifies a variety of different types: movies, restaurants, animal shelters, news articles, aiports, vehicles...you name it. Let's look at the **```LocalBusiness```** and **```Restaurant```** types:\n",
    "\n",
    "Here is the FourSquare page for a restaurant called Olmstead: https://foursquare.com/v/olmsted/5744efc0498e8b9ffbd0682a\n",
    "\n",
    "Let's see if FourSquare is using microdata to highlight the restaurant information. Open the page in your browser and \"View the Source.\" Do you see the ```itemscope``` attribute anywhere? What type did they specify?\n",
    "\n",
    "Looking through HTML can be very messy! Let's use Google's testing tool to see what it finds in the HTML. Give this a try:\n",
    "\n",
    "https://search.google.com/structured-data/testing-tool/u/0/#url=https%3A%2F%2Ffoursquare.com%2Fv%2Folmsted%2F5744efc0498e8b9ffbd0682a\n",
    "\n",
    "Ahh....much better!\n",
    "\n",
    "Now, try it for the Zagat page for the same restaurant: https://search.google.com/structured-data/testing-tool/u/0/#url=https%3A%2F%2Fwww.zagat.com%2Fr%2Folmsted-brooklyn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that you see how it works, let's do it ourselves!\n",
    "\n",
    "**A little refresh here**...remember how we scrape a page? Using the requests module to do an `HTTP GET` request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# grab the FourSquare page for Olmsted\n",
    "url = 'https://foursquare.com/v/olmsted/5744efc0498e8b9ffbd0682a'\n",
    "\n",
    "r = requests.get(url)\n",
    "print r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the HTML of that page, let's use our old friend `BeautifulSoup` to help parse out the **`itemscope`** attributes to see what microdata is represented in this HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "for tag in soup.find_all(attrs={\"itemscope\":True}):\n",
    "    print \"Name:\", tag.name\n",
    "    print \"Type:\", tag['itemtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about if we wrap this up in a handy function where we pass in a URL and get back the list of schema types (if any) are found on the given page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def get_schemas(url):\n",
    "\n",
    "    # make the request and run the page through BeautifulSoup\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    \n",
    "    schemas = []\n",
    "    for tag in soup.find_all(attrs={\"itemscope\":True}):\n",
    "        schemas.append(tag['itemtype'])\n",
    "\n",
    "    return schemas\n",
    "\n",
    "# call our method with any URL\n",
    "# news article?\n",
    "#url = 'https://www.nytimes.com/2017/04/02/us/politics/trump-china-jared-kushner.html'\n",
    "#url = 'http://digg.com/2017/amazon-alexa-is-not-your-friend'\n",
    "\n",
    "# restaurant? local business?\n",
    "#url = 'https://foursquare.com/v/olmsted/5744efc0498e8b9ffbd0682a'\n",
    "#url = 'https://www.yelp.com/biz/olmsted-brooklyn'\n",
    "\n",
    "# recipe?\n",
    "#url = 'http://www.bonappetit.com/recipe/bas-best-molten-chocolate-cake'\n",
    "\n",
    "# movie?\n",
    "url = 'http://www.imdb.com/title/tt3521164/'\n",
    "\n",
    "schemas = get_schemas(url)\n",
    "for schema in schemas:\n",
    "    print schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's looks at the `NewsArticle` type 📰\n",
    "\n",
    "Take a quick peek at the schema documeation before we get started: http://schema.org/NewsArticle\n",
    "\n",
    "How would we go about extracting information about a NewsArticle using the tools we know (requests, BeautifulSoup, etc)?\n",
    "\n",
    "In particular, can we find this information in a [news article]('https://www.nytimes.com/2017/04/02/us/politics/trump-china-jared-kushner.html')?\n",
    "* `headline`\n",
    "* `author`\n",
    "* `description`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.nytimes.com/2017/04/02/us/politics/trump-china-jared-kushner.html'\n",
    "\n",
    "# make the request and run the page through BeautifulSoup\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "for tag in soup.find_all(attrs={'itemtype': 'http://schema.org/NewsArticle'}):\n",
    "\n",
    "    for stuff in tag.find_all(attrs={\"itemprop\":True}):\n",
    "\n",
    "        if 'headline' in stuff['itemprop'] == 'headline':\n",
    "            print 'headline: ' + stuff.get_text()+\"\\n\"\n",
    "\n",
    "        elif 'author' in stuff['itemprop']:\n",
    "            print 'author: ' + stuff.get_text()+\"\\n\"\n",
    "\n",
    "        elif stuff['itemprop'] == 'description':\n",
    "            print 'description: ' + stuff['content']+\"\\n\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ClaimReview\n",
    "\n",
    "Ok, let's finally take a look at the *`ClaimReview`* microdata specification: https://schema.org/ClaimReview\n",
    "\n",
    "As Mark mentioned earlier, `ClaimReview` is a new type addded to the list of supported types (on schema.org) by [Google on October 16](https://blog.google/topics/journalism-news/labeling-fact-check-articles-google-news/).\n",
    "\n",
    "A `ClaimReview` is defined as: _A fact-checking review of claims made (or reported) in some creative work (referenced via itemReviewed)._\n",
    "\n",
    "Let's look at an article from the Washington Post \"Fact Checker\" blog to see if they have a ClaimReview. Use our method `get_schemas()` from above to print out the microdata types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.washingtonpost.com/news/fact-checker/wp/2016/06/17/fact-checking-three-democratic-claims-on-assault-rifles-and-guns/?utm_term=.fdbafa4d21c9'\n",
    "\n",
    "for schema in get_schemas(url):\n",
    "    print schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a closer look at the info in the `ClaimReview`. In this example, we start to print out the item properties for this wonderful piece from snopes. 🐟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# ummm...what?\n",
    "url = 'http://www.snopes.com/bumble-bee-tuna-recall-human/'\n",
    "\n",
    "# make the request and run the page through BeautifulSoup\n",
    "r = requests.get(url)\n",
    "soup = BeautifulSoup(r.text)\n",
    "\n",
    "for tag in soup.find_all(attrs={'itemtype': 'http://schema.org/ClaimReview'}):\n",
    "\n",
    "    for stuff in tag.find_all(attrs={'itemprop':True}):\n",
    "        print \"Property:\", stuff['itemprop']\n",
    "        print \"Text:\", stuff.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare, take a look at what Google's tool finds for this article: https://search.google.com/structured-data/testing-tool/u/0/#url=http%3A%2F%2Fwww.snopes.com%2Fbumble-bee-tuna-recall-human%2F\n",
    "\n",
    "One important piece of data in here is the `reviewRating` --> `alternateName` value. In Snopes case, this is where they tell you if the Claim is `False`, `Mostly False`, or `True`. What can you do with this information? \n",
    "\n",
    "How might you use what we've just done to find how fake news is shared on social networks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P.S. if you were to add most of the various forms of metadata to our \"technology news site\" example...\n",
    "\n",
    "...it might look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "\n",
    "<html>\n",
    "\n",
    "    <head>\n",
    "        <title>My Technology News Site - Events in San Francisco</title>\n",
    "        <meta name=\"description\" content=\"My Technology News Site has the most interesting technology stories and events.\">\n",
    "        <meta name=\"keywords\" content=\"tech, news, super important tech news, technology, technology news, technology events, events, San Francico, Silicon Valley\">\n",
    "        \n",
    "        <!-- OpenGraph for FB -->\n",
    "        <meta property=\"og:title\" content=\"My Technology News Site - Events in San Francisco\" />\n",
    "        <meta properly=\"og:description\" content=\"My Technology News Site has the most interesting technology stories and events.\" />\n",
    "        <meta property=\"og:type\" content=\"website\" />\n",
    "        <meta property=\"og:image\" content=\"http://mysweettechsite.com/logo.png\" />\n",
    "\n",
    "        <!-- TwitterCard for Twitter -->\n",
    "        \n",
    "        <meta name=\"twitter:card\" content=\"summary\" />\n",
    "        <meta name=\"twitter:site\" content=\"@mytwitteraccount\" />\n",
    "        <meta name=\"twitter:title\" content=\"My Technology News Site - Events in San Francisco\" />\n",
    "        <meta name=\"twitter:image\" content=\"http://mysweettechsite.com/logo.png\" />\n",
    "\n",
    "        <script type=\"application/ld+json\">\n",
    "        {\n",
    "            \"@context\": \"http://schema.org\",\n",
    "            \"@type\": \"Event\",\n",
    "            \"location\": {\n",
    "                \"@type\": \"Place\",\n",
    "                \"address\": {\n",
    "                  \"@type\": \"PostalAddress\",\n",
    "                  \"addressLocality\": \"San Francisco\",\n",
    "                  \"addressRegion\": \"CA\",\n",
    "                },\n",
    "                \"name\": \"The Moscone Convention Center\"\n",
    "            },\n",
    "            \"name\": \"Macworld Expo San Francisco\",\n",
    "            \"startDate\": \"2014-01-05T09:00\",\n",
    "            \"endDate\": \"2014-01-09T17:00\"\n",
    "        }\n",
    "        </script>\n",
    "    \n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "        <div class=\"vevent\">\n",
    "            <div class=\"summary\"><strong>Macworld Expo San Francisco</strong></div>\n",
    "            <div>\n",
    "                 <span class=\"dtstart\" title=\"2004-01-05\">January 5</span>-\n",
    "                 <span class=\"dtend\" title=\"2005-01-09\">9, 2004</span>\n",
    "            </div>\n",
    "            <div class=\"location\">Moscone Convention Center, San Francisco, CA</div>\n",
    "        </div>\n",
    "    </body>\n",
    "\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
