{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mongo Basics\n",
    "------------\n",
    "\n",
    "We are going to spend a little time familiarizing you with the basics of how to interact with Mongo. Many of your projects involve Twitter and it is designed to be efficient with tweet-style data. First, as we did last time, let's create a client object to talk to the database. We are going to use the database of 760K tweets that have #SusanRice in them. It's much easier than working with 760K files! They are hosted on our `compute-cuj.org` server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://journalist:secret@compute-cuj.org:27017/tweets\")\n",
    "type(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a connection, we specify a database..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = client[\"tweets\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and a collection. Here the database is `tweets` and the collection is `rice`. Again, it's the collection of tweets we pulled that contain the hashtag #SusanRice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rice = db[\"rice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the numbers are consistent. 760K records in the database, one for each tweet. Here is one. Again, it's just Python's instantiation of a JSON string. It is a dictionary made up of built-in data types, lists and other dictionaries. Or, in Mongo-speak, a document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making simple queries**\n",
    "\n",
    "A database not only regularizes access to data for a team, it also provides us with basic search capabilities. Here we are going to show how to pull targeted subsets of data from a Mongo database. We begin with a simple exact match. Here we are looking for tweets that have a `lang` field that is equal to `und` for undefined. I'm not sure how that happens but let's see how many there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"lang\": \"und\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than an exact match of to a string, below we use a regular expression to find a pattern in the `source` field. Here we find sources that refer to \"periscope\". For this, we make use of an operator to specify the documents of interest.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`{\"source\": {\"$regex\":\"periscope\"}}`\n",
    "\n",
    "Let's see how many there are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"source\": {\"$regex\":\"periscope\"}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `$regexp` expression is called an **operator**. It is one of many that Mongo makes availabe to express constraints on data to form subsets. Given our experience with Pandas, we might look for things like pattern matching in strings, or various inequalities for numerical data.\n",
    "\n",
    "In the expression below, we form a search for all the tweets with a `retweet_count` equal to 0. The numerical operators include `$eq`, `$gt` and `$lt`  -- equality, greater-than and less-than. Here's what the expression would look like.\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`{\"retweet_count\":{\"$gt\":2000}}`\n",
    "\n",
    "And let's form a count..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"retweet_count\":{\"$eq\":0}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other operators include `$exists`, which simply tests if some part of the document (the tweet) is present or not. Why is this useful? Twitter only includes the `retweeted_status` field if the tweet is a retweet. If it is an original post, that field won't be part of the tweet. \n",
    "\n",
    "Here we see how many tweets are not retweets in our collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"retweeted_status\":{\"$exists\":False}}).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"retweeted_status\":{\"$exists\":True}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a [complete list of operators you can use with Mongo](https://docs.mongodb.com/manual/reference/operator/query/)\n",
    "\n",
    "If we want to have several conditions in our match, we can just add more items to our dictionary. Here we take all the tweets that are retweets and keep just the ones that start with \"RT \". \n",
    "\n",
    "The \"documents\" we've been making to perform searches (create subsets) of data are called **filters**. They take on the structure of the original data. Remember? Our tweets have keys like `retweeted_status` or `text` and so our filters! Ah you can't chop down a symmetry!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"retweeted_status\":{\"$exists\":True}, \"text\":{\"$regex\":\"^RT \"}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than just counting, we can iterate through the set to display our results. Here we search for tweets with a retweet count of 0 and we only keep the fields `text` and `user.screen_name` (the \".\" is how we index into an embedded document, `screen_name` being a key to the `user` dictionary of the tweet). \n",
    "\n",
    "The notation in the second dictionary assigns a value of `True` to a key if you want to keep the variable with that name and it assigns a `False` otherwise. (You will also see 1 and 0 instead -- remember `True` reduces to 1 and `False` to 0.) This is called **a projection**. The first two arguments to `find()` are `filter=` and `projection=`.  In the code below, we are leaving out Mongo's `_id` variable as it's an internal Mongo index.\n",
    "\n",
    "Ah and notice that the projection is also a document, just like filter is, matching our data. \n",
    "\n",
    "In the code below we have also added `.limit(10)` to the back of the command so that we only get 10 items from the database. We'll show you how to sort the data first and get the 10 with the largest retweet counts or some other condition shortly. \n",
    "\n",
    "But for now we are printing out the JSON that's returned from the database and then a more formatted printout of the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in rice.find({\"retweet_count\":{\"$eq\":0}},{\"text\":True,\"user.screen_name\":True,\"_id\":False}).limit(10):\n",
    "    # the dictionary from Mongo\n",
    "    print tweet\n",
    "    print \"---\"\n",
    "    # printing out some data from the dictionary\n",
    "    print tweet[\"user\"][\"screen_name\"]\n",
    "    print tweet[\"text\"]\n",
    "    print \"===\"*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most retweeted updates in our database came from Donald Trump Jr. Here's his congratulatory post to Cernovich."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Congrats to <a href=\"https://twitter.com/Cernovich\">@Cernovich</a> for breaking the <a href=\"https://twitter.com/hashtag/SusanRice?src=hash\">#SusanRice</a> story. In a long gone time of unbiased journalism he&#39;d win the Pulitzer, but not today!</p>&mdash; Donald Trump Jr. (@DonaldJTrumpJr) <a href=\"https://twitter.com/DonaldJTrumpJr/status/849240401974308864\">April 4, 2017</a></blockquote>\n",
       "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Congrats to <a href=\"https://twitter.com/Cernovich\">@Cernovich</a> for breaking the <a href=\"https://twitter.com/hashtag/SusanRice?src=hash\">#SusanRice</a> story. In a long gone time of unbiased journalism he&#39;d win the Pulitzer, but not today!</p>&mdash; Donald Trump Jr. (@DonaldJTrumpJr) <a href=\"https://twitter.com/DonaldJTrumpJr/status/849240401974308864\">April 4, 2017</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how often it was a retweet among our collection of tweets. It appears that the most reliable way to decide if a tweet is a retweet is to see if the tweet object contains the `retweeted_status` field.  When it exists, your tweet is a retweet. \n",
    "\n",
    "And if it exists, the field holds the original tweet being retweeted. So, you can look inside `retweeted_status` for the `id_str` (a string version of the tweet id -- why have both a number and a string?) of the original tweet. In our case, we are looking for an `id_str1` with value \"849240401974308864\". We could also use `$eq` with the numerical value of the id. (Why have a string and a numerical version of the id?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.find({\"retweeted_status.id_str\":\"849240401974308864\"}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see who retweeted Trump Jr. We can use the same filter document and won't restrict the output with  projection -- we've left the second argument to `find()` off. Here's a simple printout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in rice.find({\"retweeted_status.id_str\":\"849240401974308864\"},{\"user.screen_name\":True,\"user.followers_count\":True,\"_id\":False}).limit(10):\n",
    "    print tweet[\"user\"][\"screen_name\"], tweet[\"user\"][\"followers_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing we want to do next is simply sort by followers. Who among those that retweeted Trump Jr. has the most followers? We can sort the results of our search for retweeters by `followers_count`, here from largest to smallest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, DESCENDING\n",
    "\n",
    "for tweet in rice.find({\"retweeted_status.id_str\":\"849240401974308864\"}).sort(\"user.followers_count\",DESCENDING).limit(10):\n",
    "        print tweet[\"user\"][\"screen_name\"], tweet[\"user\"][\"followers_count\"]\n",
    "        print tweet[\"user\"][\"description\"]\n",
    "        print \"---\"*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here from smallest to largest, adding the number of friends as well to the output. Notice that many don't have proper descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import ASCENDING, DESCENDING\n",
    "\n",
    "for tweet in rice.find({\"retweeted_status.id_str\":\"849240401974308864\"}).sort(\"user.followers_count\",ASCENDING).limit(10):\n",
    "        print tweet[\"user\"][\"screen_name\"], tweet[\"user\"][\"followers_count\"], tweet[\"user\"][\"friends_count\"]\n",
    "        print tweet[\"user\"][\"description\"]\n",
    "        print \"---\"*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, Python's syntax for `sort()` is different than that used by Mongo. Mongo again deals in a document to specify a key and a direction. But pymongo wants a list of keyname-direction pairs. Alas.\n",
    "\n",
    "Now, let's take the retweet times for these retweets and see what they look like. We will load a data frame from our Mongo search using the `from_records()` method we saw briefly last time, and again use our TimeGrouper. Here we kept just the `created_at` field and you can see why we might want to be a little sparing about the data we bring over from Mongo. We don't need a hundred fields for this task, so we can leave them behind.\n",
    "\n",
    "Remember that we have seen a couple ways to manufacture a dataframe. One involves a dictionary where the keys are column names and the values are lists representing columns of data. We can also have a list of lists, where the inner lists are the data for each row and the outer list forms the table, holding an ordered set of rows. The \"records\" formulation uses a list of dictionaries, where each dictionary has keys that are column names and represents a single row. \n",
    "\n",
    "That's what we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas  import DataFrame, TimeGrouper, to_datetime\n",
    "\n",
    "dj2 = DataFrame.from_records(rice.find({\"retweeted_status.id_str\":'849240401974308864'},{\"created_at\":True,\"_id\":False}))\n",
    "dj2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few lines of code we've seen frequently. We turn the string representation of time into a Python datetime object and then use it as the index for our data frame. We can then apply the `TimeGrouper` (because it wants to group things by a time-based index) and look at counts per 15 minutes. The last printout is our final counts data frame that tells us how often the Trump Jr. tweet was retweeted in each 15 minute epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dj2[\"stamp\"] = to_datetime(dj2[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "dj2.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "counts = dj2.groupby(TimeGrouper(freq='15min')).aggregate({\"created_at\":{\"counts\":\"count\"}})\n",
    "counts.columns = counts.columns.droplevel()\n",
    "counts = counts.reset_index()\n",
    "\n",
    "dj2.reset_index(inplace=True)\n",
    "\n",
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sure, let's plot it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "sign_in(\"cocteautt\",\"9psj3t57ti\")\n",
    "\n",
    "mydata = [go.Scatter(x=counts[\"stamp\"],y=counts[\"counts\"],mode=\"line\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**A processing pipeline**\n",
    "\n",
    "So far we have just pulled subsets of data from Mongo and created a dataframe for further processing. This might be wasteful. The database is a powerful aggregation engine as well, meaning we can do some procesing in an optimized environment before pulling data into Python. The pipeline is accessed via a method called `aggregate()`. \n",
    "\n",
    "In this method you specify some aggregtors, operators if  you will. There are operators to `$match`, limiting our data to a subset, to `$group` the subset by one or more variables so you can perform summaries like counting or summing, and finally to `$project` the data, keeping only those terms we want.  Each stage in the pipeline transforms documents. [Here is a list of the operators you can use at each stage.](https://docs.mongodb.com/manual/reference/operator/aggregation/#aggregation-pipeline-operator-reference) \n",
    "\n",
    "<img src=https://docs.mongodb.com/manual/_images/aggregation-pipeline.bakedsvg.svg width=800>\n",
    "\n",
    "Below we use the `$group` operator to group by the name of a person being retweeted. So we look into the `retweeted_status` field, if it's there, and pull out the id of the tweet that was retweeted. That groups the data. Then, for each group we pull the person's name who  tweeted said tweet and then sum up the number of times it was retweeted. \n",
    "\n",
    "In forming the expression below, we have operators like `$group`. We also have operators that take actions on groups. These include `$sum` and `$first`. The former adds up data in the group and the latter returns the first value in the group. In our case, all the tweets in a group have the same originator and so the first and last and all the screen names should be the same. Consult the operator reference for the other things you can do. \n",
    "\n",
    "Oh and for `$group`, you are first speciying the variable(s) to group by with a dictionary key of `_id`. You then name columns in your new data set as keys in the rest of the document, with dictionaries for how to compute them. When you have a name from your original data (coming from Mongo) you add a `$`. \n",
    "\n",
    "The `aggregate()` method gives us back something we can iterate over (in a loop, say) by using the `.next()` method. We usually don't touch that because a for-loop would call it for us. But here we just want to see one entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.aggregate([{\"$group\":{\"_id\":\"$retweeted_status.id_str\",\"name\":{\"$first\":\"$retweeted_status.user.screen_name\"},\"text\":{\"$first\":\"$retweeted_status.text\"},\"counts\":{\"$sum\":1}}}]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one tweet and its retweet count. Let's  do this for all the tweets in our data set. Instead of using one record, we'll pass the result of `.aggregate()` to the `from_records` method of a data frame and get back a table of all the tweets and their retweet counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame.from_records(\n",
    "    rice.aggregate([{\"$group\":{\"_id\":\"$retweeted_status.id_str\",\n",
    "                     \"name\":{\"$first\":\"$retweeted_status.user.screen_name\"},\"text\":{\"$first\":\"$retweeted_status.text\"},\"counts\":{\"$sum\":1}}}]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, maybe we want to look at the top of the table, the big values, instead. Let's use what we recall from pandas to do that. Once we have `df` we can just sort..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sort_values(\"counts\",ascending=False,inplace=True)\n",
    "df.reset_index(inplace=True,drop=True)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline we fed to `aggregate` is a list. It is a list of things to do to the data in order. Here we add the sorting of our tweets into the pipeline rather than do it in pandas. It means adding the operator `$sort` to the mix. `$group` is the first element in the list and `$sort` is the second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame.from_records(\n",
    "    rice.aggregate([{\"$group\":{\"_id\":\"$retweeted_status.id_str\",\n",
    "                     \"name\":{\"$first\":\"$retweeted_status.user.screen_name\"},\"text\":{\"$first\":\"$retweeted_status.text\"},\"counts\":{\"$sum\":1}}},\n",
    "                   {\"$sort\":{\"counts\":-1}}]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at more of the retweets and see which happened when. We use the data frame we just made and pull out the id's of each popular tweet. We cycle through just as we did above for a single tweet, adding more lines to our plot. Here we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas  import DataFrame, TimeGrouper, to_datetime\n",
    "\n",
    "mydata = []\n",
    "\n",
    "for row in df[0:20].to_records():\n",
    "\n",
    "    tid = row[\"_id\"]\n",
    "    who = row[\"name\"]\n",
    "    \n",
    "    dj2 = DataFrame.from_records(rice.find({\"retweeted_status.id_str\":tid},{\"created_at\":True}))\n",
    "    dj2[\"stamp\"] = to_datetime(dj2[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "    dj2.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "    counts = dj2.groupby(TimeGrouper(freq='15min')).aggregate({\"created_at\":{\"counts\":\"count\"}})\n",
    "    counts.columns = counts.columns.droplevel()\n",
    "    counts = counts.reset_index()\n",
    "    \n",
    "    dj2.reset_index(inplace=True)\n",
    "\n",
    "    mydata.append(go.Scatter(x=counts[\"stamp\"],y=counts[\"counts\"],mode=\"line\",name=who))\n",
    "    \n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same code, but look at frequent tweeters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame.from_records(\n",
    "    rice.aggregate([{\"$group\":{\"_id\":\"$user.screen_name\",\"counts\":{\"$sum\":1}}},\n",
    "                    {\"$sort\":{\"counts\":-1}}\n",
    "                   ]))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas  import DataFrame, TimeGrouper, to_datetime\n",
    "\n",
    "mydata = []\n",
    "\n",
    "for row in df[0:20].to_records():\n",
    "\n",
    "    who = row[\"_id\"]\n",
    "    \n",
    "    dj2 = DataFrame.from_records(rice.find({\"user.screen_name\":who},{\"created_at\":True}))\n",
    "    dj2[\"stamp\"] = to_datetime(dj2[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "    dj2.set_index(\"stamp\",inplace=True)\n",
    "\n",
    "    counts = dj2.groupby(TimeGrouper(freq='15min')).aggregate({\"created_at\":{\"counts\":\"count\"}})\n",
    "    counts.columns = counts.columns.droplevel()\n",
    "    counts = counts.reset_index()\n",
    "    \n",
    "    dj2.reset_index(inplace=True)\n",
    "\n",
    "    mydata.append(go.Scatter(x=counts[\"stamp\"],y=counts[\"counts\"],mode=\"line\",name=who))\n",
    "    \n",
    "mylayout = go.Layout(autosize=False, width=1000,height=500)\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import set_option\n",
    "\n",
    "set_option(\"display.max_colwidth\",140)\n",
    "set_option(\"display.max_rows\",100)\n",
    "\n",
    "tx = DataFrame.from_records(\n",
    "        rice.find({\"user.screen_name\":\"TXCowboysRawk\"},{\"created_at\":True,\"retweeted_status.user.screen_name\":True,\"source\":True}))\n",
    "tx[\"stamp\"] = to_datetime(tx[\"created_at\"],format='%a %b %d %H:%M:%S +0000 %Y')\n",
    "tx.sort_values(\"stamp\").head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we leave this, there is another `aggregate` operator that comes in handy, `$project`. Let's pull all the tweets from people with more than 10000 followers. For each tweet from these people, we keep the tweet id, their screen name and the retweet count of the given tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = DataFrame.from_records(rice.find({\"user.followers_count\":{\"$gt\":10000}},{\"_id\":False,\"user.screen_name\":True,\"id\":True,\"retweet_count\":True}).limit(100))\n",
    "tmp.head()                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that the data frame now holds an embedded document, a dictionary, that represents the part of the `user` data we have decided to keep. We don't want a dictionary, we want a string representing the screen name. \n",
    "\n",
    "To get around this, we use `aggregate()` and `$project` the document, reshaping  it to just include the id of the tweet and the user's screen_name, but getting rid of the extra dictionary. Again, the pipeline is represented as a list of dictionaries where the keys match operations at each stage. Here we use `$match` to form a subset and `$project` to flatten things out.\n",
    "\n",
    "Here's an example and then how you can use it to create a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rice.aggregate([{\"$match\":{\"user.followers_count\":{\"$gt\":10000}}},\n",
    "                {\"$project\":{\"text\":True,\"screen_name\":\"$user.screen_name\",\"retweet_count\":True,\"_id\":False}}]).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in data frame form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = DataFrame.from_records(rice.aggregate([{\"$match\":{\"user.followers_count\":{\"$gt\":10000}}},\n",
    "                {\"$project\":{\"id\":True,\"screen_name\":\"$user.screen_name\",\"retweet_count\":True,\"_id\":False}}]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very fast introduction to a powerful aspect of Mongo. Here is a complete [description of aggregation](https://docs.mongodb.com/manual/meta/aggregation-quick-reference/#aggregation-expressions)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
