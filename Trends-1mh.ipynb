{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Trending Topics </h1>\n",
    "<hr>\n",
    "<img src=\"http://noble66.github.io/Viz/mh370drift_world2.gif\" style=\"width: 65%;\"/>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the first class where we will explore topics that trend on social media platforms, specifically Twitter and Facebook. \n",
    "\n",
    "There are **so** many questions that revolve around this particular feature available to users on most social networks today, that it would be hard to cover everything in a single class. However, we will do our best to discuss the relevant parts and defer the rest of the material via readings outside class. Main points from these reading materials will be explored further in [discussion sessions](#Discussion).\n",
    "\n",
    "Here's the flow for our session on **trending topics**: \n",
    "\n",
    "> We will start with some [introductory](#Introduction) questions that focus on how and where trends come from? Or who decides what's on the trending topic list? It is important to understand these factors before we embark on parsing and finding patterns in data about computed trends from Facebook or Twitter. This is fundamental to any data science analysis - the incentives and procedures through which the data source generates and publishes data can often give us significant knowledge about how to interrogate it. \n",
    "\n",
    ">Following that, we will explore some real [datasets](#Data) of trends collected from Facebook and Twitter. This will give you hands-on experience analyzing trends, assessing their patterns and rhythms. On Thursday, we will flip things around and you will be asked to come up with trending algorithms.\n",
    "\n",
    ">The next section will be [methods](#Methods), where we will study some metrics that help **quantify features in the trend signal**. Example features include how long a trend lasted in some location, or how many geolocations it spread to etc. Note it isn't necessary that these features will reveal something \"interesting\" about the trend. The idea of this exercise is to help you calibrate your thinking about trends as a signal of social attention. In other words, assuming trends were a signal of \"attention\", what metrics can be used to compare to trends? \n",
    "\n",
    ">Finally, we will [discuss](#Discussion) more general readings about trending topics, including the recent controversy around Facebook's Trending Topic, the limitations of algorithmic methods in surfacing trends and the unintended appearance of fake news in trending topics list! \n",
    "\n",
    "[Introduction](#Introduction) | [Data](#Data) | [Methods](#Methods) | [Discussion](#Discussion)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "We will start this session with some web work and a discussion. \n",
    "\n",
    "1. The idea of a trending or popular topic has become a fixture of the web and almost a navigational strategy for many of us. But what does it mean for a topic to be trending? How do these notions relate to other uses of the word, say from fashion? Next, let's find situations where trends are published, and talk about what they mean. What's trending on these sites?\n",
    "\n",
    "2. Next, let's focus just on Twitter and Facebook. What are the differences between their ideas of what's trending? What are your options for exploring trends on each platform? What comparisons can you make and what changes?\n",
    "\n",
    "In a broad sense, the idea behind trending topics is to surface something that signifies what the community is interested in, or paying attention to. Thus, when a group of users on Twitter increasingly RT (Retweet) a message or tweet about some topic, Twitter labels this as a \"trend\". \n",
    "\n",
    "Due to the incredible amounts of user-generated messages that these social platforms see everyday, Trending Topics are usually determined by an \"algorithm\" (a computer program or a set of guidelines for humans to follow... or a mixture). The role of the algorithm is to collect a substantial chunk of data generated on the social media site and strive to find **words/or phrases that occur more frequently than others, or words that are being produced with high \"velocity\"**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Trending topics are determined by an algorithm measuring velocity of Tweets about a topic, not overall popularity: <a href=\"https://t.co/8gJJOT3gCw\">https://t.co/8gJJOT3gCw</a></p>&mdash; Policy (@policy) <a href=\"https://twitter.com/policy/status/742642510862950400\">June 14, 2016</a></blockquote>\n",
       "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Trending topics are determined by an algorithm measuring velocity of Tweets about a topic, not overall popularity: <a href=\"https://t.co/8gJJOT3gCw\">https://t.co/8gJJOT3gCw</a></p>&mdash; Policy (@policy) <a href=\"https://twitter.com/policy/status/742642510862950400\">June 14, 2016</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the term \"velocity\" mean here? \n",
    "\n",
    "In class, we suggested that a trend must  be both popular and timely. That is, it must be talked about by a large number of people, but that this group represents a significant jump in the number of people who have previously mentioned the topic. As an example, the President is discussed often on social media sites, but we only want to flag him as a trending topic if the conversation about him spikes quickly, perhaps due to a press conference or the signing of an executive order.\n",
    "\n",
    "Velocity is a measure of this real time surge in discussion about a topic. A simplistic way to compute velocity is to examine a graph of tweets (or FB messages) on a topic occurring in 5- or 10-minute windows (the window size is a \"parameter\" that needs to be specified). The velocity of a topic is the increase in the number of mentions of a topic from one time period to the next."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, remember when the power went out during the SuperBowl of 2013?\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">All the lights are out!! Itâ€™s pandemonium!! Thank god we have out Beyonce finger lights! <a href=\"http://t.co/JxUKr27i\">pic.twitter.com/JxUKr27i</a></p>&mdash; Neil Patrick Harris (@ActuallyNPH) <a href=\"https://twitter.com/ActuallyNPH/status/298245477042900992\">February 4, 2013</a></blockquote>\n",
    "<script async src=\"//platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "Here is a chart comparing two topics, \"superbowl\" and \"power\" that evening. \n",
    "\n",
    "<img src=\"http://www.socialflow.com/wp-content/uploads/2013/02/power_superbowl.jpg\" style=\"width: 80%;\"/>\n",
    "\n",
    "While both have peaks in this plot, the \"power\" outage clearly spikes once the lights go out in the stadium. Its velocity or jump at this point is enormous and eclipses the superbowl itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to talk about several things to consider when designing a trending algorithm. \n",
    "\n",
    "### 1.1 Sampling\n",
    "\n",
    "Trending algorithms often begin by creating a **sample** of tweets or FB status messages. Why do we want to work with  a subset of these messages, why not the whole thing you ask? Well, for one, the data might simply be too big to analyze quickly. In this case, some form of random sampling would help reduce the size of the data, but hopefully preserve the important patterns. Twitter, for example, offers users a random sample of tweets from their API.\n",
    "\n",
    "Also, depending on your notion of a trend, we might want to identify patterns in certain groups or communities within a social network. This means creating a sample of data from just these members, possibly using statistical sampling again if the number is too large. \n",
    "\n",
    "For example, Twitter computes trending topics for 400 places around the world. Some places are cities, some are entire countries and then there is a category for worldwide trending topics. By forming geography-based samples, we can ask what are the trending topics in Austin? In New York City? In the United States? Facebook also computes trends for geographic regions, but the restrict this to 5 zones -- Canada, the USA, India, Great Britian, and Australia. As we noted in class, this captures a large chunk of the English speaking world. \n",
    "\n",
    "So sampling, being the first phase of the trend algorithm, plays a critical role in specifying what trends you are after. For example, if you sample all Facebook messages originating from India vs. those originating from the USA, then there is bound to be significant difference in the trending topic list, because the status updates from these countries would almost certainly be different. This is true unless there is a global event that captures the attention of both nations simulateneously. \n",
    "\n",
    "### 1.2 Personalization\n",
    "\n",
    "Beyon forming trends from data on broad groups of users, Twitter and Facebook further personalize trends to you and your corner of the network. These personalized trends can be based on \n",
    "1. Your location,\n",
    "2. The people you follow or are friends with, and \n",
    "3. Your interests: Pages you follow or things you LIKE/RT \n",
    "Twitter calls this sort of personalization \"Tailored Trends\" which is \"on\" by default. You can change this defalut and instead receive trending topics from any of their geographic lists. Your Facebook trending list is also personalized by default, but more importantly, it is *not possible* to retrieve a list of trends for the five Facebook zones in Facebook's interface. \n",
    "\n",
    "This means that on Twitter, you can see what's trending in Paris even if you live in Boston. On Facebook, you cannot see what's trending in Australia unless you live there. \n",
    "\n",
    "(Luckily for us, the services that Facebook offers to its developers give us access to the list of Facebook trends for their 5 zones. These will be the subject of our initial data work.)\n",
    "\n",
    "### 1.3 Influencers\n",
    "\n",
    "As discussed in class, trends might also be defined by *who* is talking about a given topic. If people are \"high profile\" -- having a large number of followers or perhaps always earning a large number of LIKEs/RTs -- perhaps their interests should be weighted more heavily.\n",
    "\n",
    "While this framing focuses on the high end, it might also be worth looking at the low profile users, perhaps as an indication of accounts that are \"fake.\" We might consider downweighting messages from these users.\n",
    "\n",
    "### 1.4 Trend Propagation\n",
    "\n",
    "So the next obvious question is: why does a trend start in one place and spread all over the network? To understand this, we must delve a bit deeper. A sequence of activity resembles what we call time series data. Activity in a social network can be tracked in three levels: (1) Micro, (2) Meso and (3) Macro. \n",
    "\n",
    "* Micro: You tweet or RT something\n",
    "* Meso: All the people in Washington DC tweet/RT something\n",
    "* Macro: The entire network activity\n",
    "\n",
    "Meso signals resemble time series data generated from activity of a collection of users. We do not know exactly how such activity correlates with one other, but most previous research hint at information cascades as one reason.\n",
    "\n",
    "**Information cascades** resemble a mathematical system where each node will make a decision of whether to forward the message/information or not based on its previous experience (is this a influential person) and the current signal information (is this tweet good enough to RT). In general, the *n*th agent considers the decisions of the previous *n-1* agents, and his/her own signal. He/she then makes a decision based on some reasoning to determine the most rational choice. The result is a set of activities on information propagating from node to node. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*7988kEm4d2hDZdCpQoMGiQ.png\">\n",
    "\n",
    "Because meso signals are generated from micro signal (individual) activity and individual activity is influenced by network topology (who you follow and who follows you), the trend signal is indirectly caused by information dynamics governed by network topology. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 The Attention Signal\n",
    "\n",
    "Thus, the **trending topic over time is a SIGNAL** - a signal for what has captured the attention of a particular demographic (i.e. in a geo-location or within a community). Plotting such topic signals can often reveal interesting facts about information diffusion. \n",
    "\n",
    "For example, lets look at the trending topic '#Ferguson' in various US cities. \n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/800/1*NXer4xgyr9qFEnUEjuIFJA.gif\">\n",
    "\n",
    "Here, the X-axis represents a fixed duration of time from when the trend was first seen in St. Louis. Y-axis represents the score of the trend in the trending topic list. (A score of 10 represents rank 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Introductory Data Reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Article | Description |\n",
    "| ------ | ----------- |\n",
    "|1. [FB Newsroom Trending Topics Guideline](https://fbnewsroomus.files.wordpress.com/2016/05/full-trending-review-guidelines.pdf)   |  How your news gets to be on the Trending Topic List |\n",
    "|2. [The Digital Flames of Ferguson](https://medium.com/i-data/the-digital-flames-of-ferguson-87c4eb9aaae4#.5cuci5dm0) | Quantifying how news spreads from location to location using Twitter trends. |\n",
    "|3. [#TrumpWon: Trend vs. Reality](https://medium.com/i-data/trumpwon-trend-vs-reality-16cec3badd60#.lspl71ll7)   | Our reality is decided by what we pay attention to. |\n",
    "|4. [Hong Kong, the World and Facebook Trends](https://medium.com/i-data/hong-kong-the-world-and-facebook-trends-28331ee8f2d1#.60t0s8k3j)   | A product's user Interface design can affect what becomes a trend|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Some Helper Scripts before we begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Counters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A Counter is really useful thing, that can count the frequency of things in a list..\n",
    "# it can then order in descending fashion. \n",
    "from collections import Counter\n",
    "x = ['ford','chevy','honda','ford','chevy','lincoln','ford']\n",
    "print Counter(x)\n",
    "print ''\n",
    "print Counter(x).most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = ['ford','chevy','honda','ford','chevy','lincoln','ford']\n",
    "print set(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = ['ford','chevy','aston martin']\n",
    "set(x).intersection(set(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "[Introduction](#Introduction) | [Data](#Data) | [Methods](#Methods) | [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two sources of trends data we will work with: Facebook and Twitter.\n",
    "\n",
    "**Facebook Data Description**: The ingestion script probes Facebook every 15 minutes and logs the trends for five zones: CA, AU, US, IN, GB.  [Download the data](http://compute-cuj.org/fb_trends_mh.csv.gz), uncompress it, and place it in the same folder as this notebook. **The data have been updated from last night, so please download the file again.**\n",
    "\n",
    "**Twitter Data Description**: The ingestion script probes Twitter every 15 minutes and logs the TTL (trending topic list) + underlying trends (users might not see this in the UI) for ~400 geographical locations worldwide. Again, [download the data](http://sumandebroy.com/columbia/twitter_trending_topics_for_us_120to122.csv.gz), uncompressit, and place it in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some basic analysis on the two datasets:\n",
    "  * [Facebook](#tt-fb)\n",
    "  * [Twitter](#tt-tw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Facebook Trends <a id=\"tt-fb\"></a>\n",
    "\n",
    "We will start by reading in the data we have downloaded. Again, we cleaned things up a bit from last night and made the Facebook and Twitter data sets look a little more similar. We will use read_csv() from pandas to do the heavy lifting. We import both read_csv() as well as set_option(). Here we are going to change the way DataFrames are displayed so that we see more rows. This will help us get a better sense of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "\n",
    "set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load fb trends data\n",
    "trends = read_csv(\"fb_trends_mh.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every 15 minutes, Suman queried Facebook for the trends for their five zones. Our \"trends\" DataFrame stores this information in a table, ordered first by zone and then by time  within zone. The earliest trends for a zone come first, which in this case is 7pm on January 18, 2017. The trends for a given 15 minute period are ordered according to their rank, with the top trend coming first. Let's have a look. The first region in the data set is Canada (zone \"CA\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here we see that the first set of trends for Canada (zone is \"CA\") are at 7pm. The run sequentially to about index 44. Then we see a new set of trends that were recorded at 7:15pm and are displayed until row index  86. Then it's the data from 7:30pm and so on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends.tail(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the USA is the last zone in the data set, and we see the last data request at 9:30pm on January 23, 2017. We see the tail end of the topics pulled at this time for the USA. Unlike Canada that had about 40 or so topics per time period, Facebook seems to be calculating about 10 times more trending topics for the USA. \n",
    "\n",
    "To sum, we collected data from 7:00pm on January 18 and stopped at 9:30pm on January 23. This gives us a pretty big window to examine. \n",
    "\n",
    "Now, the columns. For each trending topic, we have the time it was observed (datetime), a representation of that time in seconds since January 1, 1970 (timestamp), the zone (US, Great Britian GB, India IN, Canada CA, and Australia AU), the name of the topic (its entry in the \"open graph\"), a headline (generated presumably by computer now), a derived variable count that is taken from the headline (the headline of \"Chelsea Manning: 280K people talking about this\" gives a count of 280000) and finally the topic name's index to the node in the open graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the method count() to tell us how many non-missing values we have in each column of a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Q]**: Why are there fewer headlines? What about counts? Facebook does not return headlines for very low trending news. And no headline means no count.\n",
    "\n",
    "We can now look at the number of topics recorded in each zone. Again, we saw that the USA returned hundreds of trending topics, while Canada was in the 10s. That difference is noticeable with a call to value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what zones am I looking at? \n",
    "trends[\"zone\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For qualitative data, value_counts() is your friend. Here we look at what topics were popuar, irrespective of region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends['topic_name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is our subsetting in action. We will ask for just the data for the US and then count up the topics we observed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what were the 10 most popular trend in US\n",
    "trends[ trends['zone']=='US' ]['topic_name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do the same for another zone. What do you see?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An aside about columns of strings in a DataFrame**\n",
    "\n",
    "As we mentioned in class, when a column in a DataFrame is made up of strings, you can access all the string methods you learned in your drill using the \".str\" object of the column. So, here we might look at the uppercase versions of the topic_names or ask if any of the topics startswith() the string \"Murder\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends[\"topic_name\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends[\"topic_name\"].str.upper().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends[\"topic_name\"].str.startswith(\"Murder\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the subsetting operator to extract out portions of a string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends[\"datetime\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trends[\"datetime\"].str[:7].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the \"slice\" or the numeric range above to \n",
    "# give you different parts of the datetime field\n",
    "\n",
    "# Put your code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we can pull data from a given date. We can use the \"logical expressions\" we learned about. Here we store the True/False data in a variable called \"mask\". It is True of the dte is January 22nd and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str[:10] == '2017-01-22'\n",
    "\n",
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there are several ways to do this. In this case, we could also use the string method startswith()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str.startswith('2017-01-22')\n",
    "\n",
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have more to say about some of the nice syntax in a DataFrame, but for now, it's enough to know that the material we covered about strings is not lost. \n",
    "\n",
    "Similarly, the work we did with logical expressions apply to DataFrames. Instead of \"and\" and \"or\" we have the symbols \"&\" and \"|\" to combine the results of two or more logical expressions that have been derived from columns in a DataFrame. Here we look for all the trends in India that were in position 1. \n",
    "\n",
    "(We set the display option to 500 because there are 491 15-minute periods between when we started collection trends on the 18th of January and wen we ended on the 23rd. Scan this over and have a look both at the topics as well as the number of people talking about the subject.)\n",
    "\n",
    "When does anything about the US election come in? What do the topics look like? They are sorted in time order. Are there moments during these days that are interesting to look at with respect to trending topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_option('display.max_rows', 500)\n",
    "\n",
    "trends[(trends['zone']=='IN') & (trends['position']==1)]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try the same thing for another zone. Put your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment on what you see and what questions it prompts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at all the trending topics in the US on Inauguration day and see what we get. Keep in mind that there are lots and lots of trends returned for every 15 minute slice. Hundreds. Let's see what they amount to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask =  trends['datetime'].str.startswith('2017-01-20') & (trends['zone']=='US')\n",
    "leaders = trends[mask]\n",
    "\n",
    "leaders[\"topic_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might skinny thing a little and look just at the top-ranking trends. This is done by limiting the position of the trend to be 10 or less (1 being the top, remember). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str.startswith('2017-01-20') & (trends[\"zone\"] == \"US\") & (trends[\"position\"]<=10)\n",
    "\n",
    "leaders = trends[mask]\n",
    "leaders[\"topic_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice here? Among all the top ranking topics, who or what is represented? Can you say something about the character of the topics? \n",
    "\n",
    "As you can see, chaining a number of conditions together gives us a more refined subset, letting us look at trends a bit more closely. \n",
    "\n",
    "So far, we have a broad feel for the trending topics during the inauguration. Let's focus on just the top-ranked trends from January 20th. \n",
    "\n",
    "(We see 96 such rows in the data set, which makes sense as 0.25\\*96 = 24. Or, since data are taken every 15 minutes, a quarter of an hour, we have 96 quarter hours or 24 hours. It all adds up!)\n",
    "\n",
    "So here are the trends appearing in the number 1 slot on Facebook in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask =  trends['datetime'].str.startswith('2017-01-20') & (trends['zone']=='US') & (trends['position']==1)\n",
    "mask.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaders = trends[mask]\n",
    "leaders[\"topic_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice? Or rather, given that this was the day of the Presidential Inauguration, what's missing?\n",
    "\n",
    "Here we look at any trend from the US on January 20th that contains a reference to \"Trump\". We'll look at the actual data, which again is sorted in time order. What do you see? Look at the trend position. Who gets low numbers and who gets high numbers (high ranking v. low ranking). Also look at the numbers of people involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str.startswith('2017-01-20') & (trends[\"zone\"] == \"US\") & trends[\"topic_name\"].str.contains(\"Trump\")\n",
    "\n",
    "trump = trends[mask]\n",
    "trump.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trump[\"topic_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that Donal Trump is trending quite often, but as you can see above, he's rarely \\#1. The next string of conditional expressions move from just any trending topic, but not as far as looking at only the top. We'll consider any trend that is in the top 10. Again, have a look what happens when during the inauguration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str.startswith('2017-01-20') & (trends[\"zone\"] == \"US\") & trends[\"topic_name\"].str.contains(\"Trump\") & (trends[\"position\"]<=10)\n",
    "\n",
    "trump = trends[mask]\n",
    "trump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's have a look: Simple plotting**\n",
    "\n",
    "Next, this seems a little out of left field, but I noticed that in Great Britian, Madonna trended quite often during our observation period. Let's look into that a little. Here's making a new DataFrame with just her trending times. Remember that \"shape\" tells you the number of rows and columns in a DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = (trends['topic_name'] == \"Madonna\") & (trends[\"zone\"]==\"GB\")\n",
    "madonna = trends[mask]\n",
    "madonna.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, 62 rows. Here they are. What do you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "madonna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tables are really tough to see any patterns in. We can think instead about plotting. We will use a simple tool called Plotly. To use this in Python, we will need to \"install\" a new package. We've seen pandas as a package that came with Anaconda. Plotly didn't come with Anaconda and we have to install it. \n",
    "\n",
    "Here's how. We use a command called \"pip\", Python's installation program. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to use it. It will be  a little obscure, but what we are doing is loading two functions, iplot() and sign_in() and then we are loading all the graphing capabilities from the Plotly graph_objs package. You can [read about Plotly here](https://plot.ly/). It is an online plotting platform that plays nice with the notebook. \n",
    "\n",
    "If you go to the Plotly site, you can create your own login and put your credentials in place of mine in the code below. Then, once you sign in to the service you can make a plot!\n",
    "\n",
    "Here we are creating a Scatterplot that has time on the x-axis and the category of the topic_name on the y-axis. This will create what we call a dot-chart. The function Scatter() sets up the plot. We can overlay several sets of data on one plot, and hence the \"[trace]\" entry below. If we had several scatterplots to overlay we might have \"[trace0,trace1]\", say.\n",
    "\n",
    "So, let's see when Madonna trended. Each blue dot is a trending period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly.plotly import iplot, sign_in\n",
    "import plotly.graph_objs as go \n",
    "\n",
    "sign_in(\"cocteautt\",\"9psj3t57ti\")\n",
    "\n",
    "mydata = [go.Scatter(x=madonna[\"datetime\"],y=madonna[\"topic_name\"],mode=\"markers\")]\n",
    "myfigure = go.Figure(data=mydata)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only gets interesting when you have multiple categories (topic_names) for the y-axis. Here we select all the trends in the US that are in the top 10 for a time period, recorded on inauguration day. Have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = trends['datetime'].str.startswith('2017-01-20') & (trends[\"zone\"] == \"US\") & (trends[\"position\"]<=10)\n",
    "\n",
    "trump = trends[mask]\n",
    "\n",
    "mydata = [go.Scatter(x=trump[\"datetime\"],y=trump[\"topic_name\"],mode=\"markers\")]\n",
    "mylayout = go.Layout(autosize=False, width=1000,height=1200,margin=go.Margin(l=150,r=50,b=100,t=100,pad=4))\n",
    "myfigure = go.Figure(data = mydata, layout = mylayout)\n",
    "iplot(myfigure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your turn! Have a look at some of the trends from other places or at times across the five zones. See what you can find about Facebook trends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your work!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Twitter Trends <a id=\"tt-tw\"></a>\n",
    "\n",
    "We are now going to examine the Twitter data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load twitter trends data\n",
    "trends = read_csv('twitter_trending_topics_for_us_120to122.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what this data looks like\n",
    "trends.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# how big is this dataset?\n",
    "trends.count()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Q]**: Why is the count of cities lower than the overall count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Describe topics trended on these days?\n",
    "trends['topic_name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what are the most common trends in this time period\n",
    "trends[\"topic_name\"].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# What trended in LA ? \n",
    "mask = (trends['city'] == 'Los Angeles')\n",
    "trends[mask].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# more concise report on what trended in LA\n",
    "trends[mask]['topic_name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Q]**: How do you find the top trend in other cities? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Limit by date\n",
    "mask = trends['datetime'].str.startswith('2017-01-21')\n",
    "before22 = trends[mask]\n",
    "\n",
    "before22['topic_name'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what was trending in Seattle before 20-21st Jan? \n",
    "before22['topic_name'][ before22[\"city\"]=='Seattle' ].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what trends reached rank 1 in Boston? \n",
    "trends['topic_name'][(trends['position']==1) & (trends['city']=='Boston')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what trend was emerging, but never made it to Boston's TTL\n",
    "trends['topic_name'][(trends['position']>10) & (trends['position']<15) & (trends['city']=='Boston')].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# what were the most common trends in some city ? \n",
    "trends['topic_name'][(trends['city']=='Atlanta')].value_counts().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods\n",
    "[Introduction](#Introduction) | [Data](#Methods) | [Methods](#Results) | [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods are a list of features that trend signals usually contain. While these might not be valuable individually to comprehend the nature of the trend, a combination of all features allows two things:\n",
    "\n",
    "* Uniquely fingerprint a trend in the world\n",
    "* Allow comparison between two trend signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures to capture features in a trend signal\n",
    "  * [Origin](#chapter-1)\n",
    "  * [Persistence](#chapter-2)\n",
    "  * [Recurrence](#chapter-3)\n",
    "  * [Geospan](#chapter-4)\n",
    "  * [Drift](#chapter-5)\n",
    "  * [Volatility](#chapter-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1 Origin<a id=\"chapter-1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The origin of a trend indicates where it was initiated. The main reason origin is a fascinating features includes (1) big trends can originate in small cities and go national (2) sometimes cities have an affinity to initiate certain categories of trends, e.g., many gaming trending topics originate in SF whereas numerous fashion trending topics originate in NY. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Within the time limits of this data, find where \"#WomensMarch\" or \"#USofScience\" originated ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: Can you find a city that did not originate any trend, but always latched on to existing ones? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Persistence of a Trend <a id=\"chapter-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Persistence of a trend is the duration of continuous time units for which it kept trending in some geo-location, signigied by continual presence in the trending topic list. This means during the persistence spell, a trend never fell out of the TTL and was not replaced by any other trend. \n",
    "\n",
    "So what does persistence really signify? Recall that a topic trends because people are tweeting about it. Two conditions are necessary for a trend to persist: \n",
    "* (1) a decent volume of tweets containing the trending word in a short amount of time and \n",
    "* (2) a failure of consolidation - i.e.  other tweets from the user group (either geo-location or follower group) fail to use the same trending word/ hash-tag in a consolidated fashion in enough tweets. This is also [the reason why #OccupyWallStreet **did not** trend in New York](http://www.niemanlab.org/2011/10/why-hasnt-occupywallstreet-trended-in-new-york/). \n",
    "\n",
    "\n",
    "<img src = \"http://www.niemanlab.org/images/socialflow_twittertrending.png\">\n",
    "\n",
    "The first condition assures that the word is trending enough to be above the threshold or cut-off marker that qualifies as a trend. The second condition assures that other trends are not competing hard enough to enter into the TTL. \n",
    "\n",
    "\n",
    "#### Visualizing Persistence:\n",
    "\n",
    "A smart way scientist visualize persistence is through something called dispersion plot. The Y-axis represents geo locations whereas the X-axis represents units of time since origin. You can the place a (dot) for every time the trend was observed at a location, and a blank if it wasn't. The result is continuos lines indicating persistence and gaps indicating lack of it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"drogba.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shown above is a dispersion plot of **Euro2012**, a soccer tournament. Notice how the trend persists/ sticks more in European cities than the American counterparts, indicating more interest or attention in the former locations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate persistence of trend '#USofScience' in Boston. \n",
    "trends[(trends['topic_name'] == '#USofScience') & (trends['city']=='Boston') & (trends['position']<11)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recurrence of a Trend <a id=\"chapter-3\"></a>\n",
    "\n",
    "The recurrence of a trend is the number of times the trend reappears in the TTL (Trending Topic List) after initially dropping out the TTL. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The phenomena causing recurrence is intuitively more challenging to comprehend than persistence. Firstly, it makes sense to assume that if a trend can persist for longer its chances of recurrence are lower, because **sustained attention is hard!** Recurrence indicates disrupted or unsteady attention spans among users in the community. The repetition of the trend reappearing could be due to many factors, including reduction of attention of one trend caused due to a sudden relative increase in attention of the another trend.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's another fascinating tidbit about recurrence: **data shows that the origin location of a trend plays an important role in the recurrence score.** In fact, the recurrence score is higher if the location's population is larger and more diverse. For example, trends will recur more often in New York than Tallahassee. This is because a big city with diverse population tweeting many different things disperses attention more quickly compared to a more homogenous crowd of smaller cities where people might have limited topics to tweet about. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrence is also common after people wake up from sleep. Because you don't tweet in bed (or do you?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*4YreqD2g2mgtnrBlv0RNsw.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Exercise: \n",
    "# Find the recurrence of some trends from the Twitter dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 GeoSpan <a id=\"chapter-4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geospan of a trend signal signifies the various geo-locations at which it was observed. In the case of micro signals, this boils down to individuals from different locations acting upon the media related to the trend. Geospan's are an important measure in identifying if a trend has gone national, in which case it will be visible in most geo locations of the country! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many  cities in the US are we tracking? \n",
    "trends['city'][(trends['country'] == 'United States')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many cities did #TrumpInauguration trend at? \n",
    "trends['city'][(trends['topic_name'] == '#TrumpInauguration')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How many cities did #WomensMarch trend at? \n",
    "trends['city'][(trends['topic_name'] == '#WomensMarch')].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exercise: find the cities where #TrumpInauguration did not trend! \n",
    "noTrendHere = set(trends['city'][(trends['country'] == 'United States')]) - set(trends['city'][(trends['topic_name'] == '#TrumpInauguration')])\n",
    "print noTrendHere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Drift <a id=\"chapter-5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In simple terms, the drift of a trend is the chronological order of geo-locations that it touches on its way to becoming a national trend (sometimes it doesn't go national but only local). The reason we calculate drift is to observe two powerful network effects:\n",
    "\n",
    "* Drift can tell us which cities have low attention grasping capability, i.e. they can quickly catch up to another city's trending topic.\n",
    "* Drift can tell us which cities have similar interests, which is one of the reasons the trend spreads to that city.\n",
    "\n",
    "Shown below is the drift of #JesuisCharlie trend. It begins in Paris and then spreads to the French cities. However after that, it simultaneously drift to both some US cities (like NY, San Diego) and European cities (Madrid, Dusseldoff) within very short time. The final cities to get affected by the trend are South American and Australian cities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/2000/1*nmDuxI2vBA-R5gwIb1xjeg.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drift exercises time permitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Volatility <a id=\"chapter-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# More mathematical, time permitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "[Introduction](#Introduction) | [Data](#Data) | [Methods](#Methods) | [Discussion](#Discussion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias\n",
    "\n",
    "Now letâ€™s think about the bias issue. Bias means certain responses are more probable than others. This might cause a data sensor to detect some changes more promptly than others. Bias is not always social, it can be dependent on sampling. \n",
    "\n",
    "Sometimes, it is caused by the inherent signal generation. A nice example of this is determining which news articles are most read by users. One could pick a signal like â€˜# of RTs the tweets with that news article received in Twitterâ€™. But note Twitter has lots of bots, algorithmâ€™s that could tweet out links based on domains or keywords. Thus, a link that has been RT-ed a lot might be under bots bias. On the other hand, think about an app like Instapaper, which flags a â€˜readâ€™ every time the user scrolls down the page to reach 20% distance from the end. This signal has much less bias, because bots cannot scroll. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithmic Curation\n",
    "\n",
    "* How do we start thinking about ways to have editors work in tandem with algorithms to identify trends. \n",
    "\n",
    "* What could happen if humans are not in the loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some more interesting reads about humans and algorithmic trend capture: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Article | Description |\n",
    "| ------ | ----------- |\n",
    "|1. [Fake news in Trends](https://www.washingtonpost.com/news/the-intersect/wp/2016/10/12/facebook-has-repeatedly-trended-fake-news-since-firing-its-human-editors/?utm_term=.ec1c1e47ca49)   |  Facebook fires editors, algorithm can't detect fake news. |\n",
    "|2. [Is this how the Trending Algorithm works?](https://qz.com/769413/heres-how-facebooks-automated-trending-bar-probably-works/) | And does that make it vulnerable? |\n",
    "|3. [The real problem with facebook and trending](https://stratechery.com/2016/the-real-problem-with-facebook-and-the-news/) | Is there a solution: editorial or algorithmic? |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Next Session:\n",
    "\n",
    "Trends-2:\n",
    ">Build your own trends from raw Twitter data. We will use raw tweets collected from Washington DC and New York to compile the trending topic list in these locations. All the personalization belongs to you.\n",
    "\n",
    "> More visualizations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
