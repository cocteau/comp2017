{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNIX basics and A/B testing\n",
    "---------------------------\n",
    "\n",
    "Today we step back to a simpler time when we interacted with computers through a handful of typed commands. Specifically, we'll deal in some pretty old magic -- UNIX commands. At one level, you can think of these as tools to help you manipulate programmatically the basic **stuff of a computer**. We'll work with files and folders and running jobs. These tools come from a time when computers looked like this.\n",
    "\n",
    "<img align=center src=http://history-computer.com/ModernComputer/Software/images/Dennis-Ritchie-Ken-Thompson-and-PDP11-UNIX-1972.jpg>\n",
    "\n",
    "Pictured above are two of the developers of UNIX, Dennis Ritchie and Ken Thompson. To give their work some context, let's define terms. The start of this notebook is a little chatty, but it will also be one of the most practial we'll have all term.\n",
    "\n",
    "      __\n",
    "    o-''|\\_____/)\n",
    "     \\_/|_)     )\n",
    "        \\  __  /\n",
    "        (_/ (_/    \n",
    "\n",
    "**An operating system** \n",
    "\n",
    "An operating system is a piece of software (code) that organizes and controls hardware and other software so your computer behaves in a flexible but predictable way.\n",
    "\n",
    "Most devices that contain a computer of some kind will have an OS. Operating systems appear when the appliance will have to deal with new applications, complex user input and possibly changing requirements of its function. In addition to a laptop or desktop computer, your DVR, smartphone and even your automobile all have operating systems.\n",
    "\n",
    "The computer you're using to run this notebook probably has a Windows, MacOS or Linux operating system. \n",
    "\n",
    "**Your computer**\n",
    "\n",
    "Let's think about your computer a little more deeply -- it consists of several components. **The Central Processing Unit** (CPU) or microprocessor (a microchip) is a complete computational engine, capable of carrying out a number of basic commands (perform simple arithmetic calculations, store and retrieve information from its memory, and so on). \n",
    "\n",
    "The CPU itself has the capacity to store some amount of information, and when it needs more space, it moves data to another kind of chip known as **Random Access Memory** (RAM) — \"random access\" as opposed to, say, sequential access to memory locations. \n",
    "\n",
    "Your computer also has one or more storage devices that can be used to organize and store data — hard disks or drives store data magnetically, while solid state drives again use special chips. (A solid state drive is a larger, more sophisticated version of your traditional thumb drive.)\n",
    "\n",
    "**Operating systems, again**\n",
    "\n",
    "Your operating system, then, manages all of your computer’s resources, providing layers of abstraction for both you, the user, as well as developers who are writing new programs for your computer.\n",
    "\n",
    "With the emergence of so-called **cloud computing**, we imagine a variety of computing resources \"out there\" on the web that we can execute -- think about the variety of APIs we've encountered that do various smart things for us or to our data. In this model, computations are performed elsewhere, and your own computer might function more as a \"browser\" receiving results -- Google’s Chrome operating system is \"minimalist\" in this sense. \n",
    "\n",
    "But let’s not get ahead of ourselves. The computers you are probably sitting at are running the Mac OS which is built on a Unix platform. Let’s spend some time talking about Unix.\n",
    "\n",
    "\n",
    "                /)-_-(\\        /)-_-(\\\n",
    "                 (o o)          (o o)\n",
    "         .-----__/\\o/            \\o/\\__-----.\n",
    "        /  __      /              \\      __  \\\n",
    "    \\__/\\ /  \\_\\ |/                \\| /_/  \\ /\\__/\n",
    "         \\\\     ||                  ||      \\\\\n",
    "         //     ||                  ||      //\n",
    "         |\\     |\\                  /|     /|\n",
    "         \n",
    "**UNIX history**\n",
    "\n",
    "In 1964, Bell Labs (the research arm of AT&T) partnered with MIT and GE to create Multics (for Multiplexed Information and Computing Service) -- here is the vision they had for computing\n",
    "\n",
    ">“Such systems must run continuously and reliably 7 days a week, 24 hours a day in a\n",
    "way similar to telephone or power systems, and must be capable of meeting wide\n",
    "service demands: from multiple man-machine interaction to the sequential processing\n",
    "of absentee-user jobs; from the use of the system with dedicated languages and\n",
    "subsystems to the programming of the system itself”\n",
    "\n",
    "Bell Labs pulled out of the Multics project in 1969, a group of researchers at Bell Labs started work on Unics (Uniplexed information and computing system) because initially it could only support one user; as the system matured, it was renamed UNIX, which isn’t an acronym for\n",
    "anything. Ritchie simply says that UNIX is a \"somewhat treacherous pun on Multics.\"\n",
    "\n",
    "While this seems like quite a long time ago, consider how Dennis Ritchie described UNIX support for programming.\n",
    "\n",
    ">Ritchie observes: “What we wanted to preserve was not just a\n",
    "good environment in which to do programming, but a system\n",
    "around which a fellowship could form. We knew from\n",
    "experience that the essence of communal computing, as\n",
    "supplied by remote-access, time-shared machines, is not just\n",
    "to type programs into a terminal instead of a keypunch, but to\n",
    "encourage close communication.” The theme of computers\n",
    "being viewed not merely as logical devices by as the nuclei of\n",
    "communities was in the air; 1969 was also the year the\n",
    "ARPANET (the direct ancestor of today’s Internet) was\n",
    "invented. The theme of “fellowship” would resonate all through\n",
    "UNIX’s subsequent history.\n",
    "<br><br>From [\"The Art of Unix Programming\"](http://www.catb.org/esr/writings/taoup/) by Raymond\n",
    "\n",
    "In Multics, we find the first notion of a hierarchical file system -- software for\n",
    "organizing and storing computer files and the data they contain in UNIX, files are\n",
    "arranged in a tree structure that allows separate users to have control of their own\n",
    "areas. Think a system of folders or directories -- one folder can contain files and other folders and so on. A tree! UNIX began (more or less) as a file system and then an interactive shell emerged to let you examine its contents and perform basic operations. And these are what we will focus on today.\n",
    "\n",
    "**The UNIX kernel and shell**\n",
    "\n",
    "The **UNIX kernel** is the part of the operating system that provides other programs\n",
    "access to the system’s resources (the computer’s CPU or central processing unit, its\n",
    "memory and various I/O or input/output devices).\n",
    "\n",
    "The **UNIX shell** is a command-line interface to the kernel — keep in mind that UNIX\n",
    "was designed by computer scientists for computer scientists and the interface is not\n",
    "optimized for novices. (The term \"shell\" is general in that a shell is the outermost\n",
    "interface to the inner workings of the system it surrounds -- where have we seen this idea before?)\n",
    "\n",
    "The UNIX shell is a type of program called an interpreter — in this case, think of it as a\n",
    "text-based interface to the kernel. It operates in a simple loop: It accepts a command, interprets it, executes the command and waits for another. Very obedient. The shell displays a prompt to tell you that it is ready to accept a command. \n",
    "\n",
    "On a Mac, you can open the Terminal application and be greeted with a happy UNIX prompt. \n",
    "\n",
    "              /\\___/\\\n",
    "              `)9 9('\n",
    "              {_:Y:.}_\n",
    "    ----------( )U-'( )----------\n",
    "\n",
    "**Getting started**\n",
    "\n",
    "We are going to explore UNIX with the \"cell magic\" syntax we've been using in our notebooks. All of the commands in the cells below can be copied and pasted into a Terminal window (leaving out the %%sh) and will run \"as is.\"\n",
    "\n",
    "One last comment. There are several versions of a UNIX shell. Why might we want different kinds of interfaces to our computer? Well, it turns out that some shells are good for interactive work (allowing you to hit the Tab key and have a command \"autocomplete\") while others have additional programming support to help you make \"scripts\" (think of the move from single commands to functions in Python). The **sh**, or [the Bourne Shell](https://en.wikipedia.org/wiki/Bourne_shell), is an old standby, whereas **bash**, or [the Bourne Again Shell](https://www.gnu.org/software/bash/), combines many characteristics of different shells together (bashing them together).\n",
    "\n",
    "We'll stick to %%sh for now in our cell magic. So, let's download a file and give you a sense of what UNIX commands are capable of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib import urlretrieve\n",
    "urlretrieve(\"http://compute-cuj.org/columbia.txt\",\"columbia.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've downloaded a file from our course web server. It's called columbia.txt on your computer. We are going to examine it using some simple UNIX commands. \n",
    "\n",
    "A few for exploring your folders: **pwd, ls, cd**<br><br>Making and removing folders (directories): **mkdir, rmdir**<br><br>Copying, renaming and removing files: **cp, mv, rm**<br><br>\n",
    "\n",
    "\n",
    "         |\\_/|                  \n",
    "         | @ @   Woof! \n",
    "         |   <>              _  \n",
    "         |  _/\\------____ ((| |))\n",
    "         |               `--' |   \n",
    "     ____|_       ___|   |___.' \n",
    "    /_/_____/____/_______|\n",
    "    \n",
    "<br><br>First, **pwd** or \"print working directory\" will tell you which folder you're in. For the notebook, this means the folder your data and notebook file are being stored in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command **ls** lists the contents of a folder. Compare this list below to what you  see when you use your finder to examine the same folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unix commands can be modified by adding one or more **options**. In the case of\n",
    "ls, we can add a \"-l\" for the \"long\" form of the output and a \"-a\" for all directories that\n",
    "begin with a “.” Another useful option is \"-h\" for humanly readable output or \"-G\" for\n",
    "color (which will only show up in the Terminal and not the notebook).\n",
    "\n",
    "The long printout below tells us the size of each file and what we can do to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: Why a command line?**\n",
    "\n",
    "While interacting with a computer by typing in commands might seem primitive, it has its advantages (there are reasons why it's hanging around).\n",
    "\n",
    "**Agile** — It is designed tok be very interactive, supporting exploratory\n",
    "analysis; it is also close to the “filesystem” which means the tools are\n",
    "close to the data you’re working with\n",
    "\n",
    "**Scalable** — You are interacting with your computer by typing\n",
    "commands and not through a graphical user interface (GUI) which\n",
    "means your instructions can be combined into a file or script and\n",
    "reused\n",
    "\n",
    "**Extensible** — New tools are being developed for the command line\n",
    "on a daily basis, being written in a variety of languages but all usable\n",
    "in the same way as the original tools that appeared in the 1960’s and\n",
    "1970s\n",
    "\n",
    "**Ubiquitous** — It is hard to find a computer system that you’ll\n",
    "purchase (desktop or laptop) and if you soar into “the cloud” you will\n",
    "likely encounter the various computers you find there through a\n",
    "command line interface\n",
    "\n",
    "       _=,_\n",
    "    o_/6 /#\\\n",
    "    \\__ |##/\n",
    "     ='|--\\\n",
    "       /   #'-.\n",
    "       \\#|_   _'-. /\n",
    "        |/ \\_( # |\" \n",
    "       C/ ,--___/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to the drill**\n",
    "\n",
    "The command **man** will provide you with help on any Unix command. You simply\n",
    "supply the name of the command you are interested in as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "man ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the **man** command above, the string \"ls\" is passed as an **argument** that tells UNIX which \"data\" to work with. Here's another example of an argument. \n",
    "\n",
    "The command **head** does what you might expect given our exposure to Pandas. It prints out the first 10 lines of a file, the name of which you pass as an argument. Here we look at the first 10 lines of \"columbia.txt\". How do you get the last 10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "head columbia.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "man head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A UNIX command  will often involve both arguments and options. Here we tell **head** to only print out the first three lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "head -3 columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Web access logs**\n",
    "\n",
    "OK what kind of data do we have? This is the so-called [combined log format](https://httpd.apache.org/docs/1.3/logs.html) from an Apache web server. Whenever you browse a web site (in this case, [www.journalism.columbia.edu](http://www.journalism.columbia.edu)), there is a program responding to your requests. Want the home page? Want information about the Dual Degree? You request the HTML page and that request is recorded as a single line in the log file. Then, to render the page, your browser might need some CSS files or JavaScript files or just some simple images. The subsequent requests for these objects are also recorded, one line each, in the log file. \n",
    "\n",
    "So the log file is growing with each user's visit. Requests are logged to the bottom of the file in time, so the oldest entries are at the top of the file and the newest at the bottom. If many people are looking at the site at the same time, their requests are interleaved in the file, as it records requests in time order. \n",
    "\n",
    "Each line in the log file hold these values\n",
    "\n",
    ">IP address<br>\n",
    "Identity<br>\n",
    "Userid<br>\n",
    "date<br>\n",
    "Request<br>\n",
    "Status<br>\n",
    "Bytes<br>\n",
    "Referrer<br>\n",
    "Agent\n",
    "\n",
    "Let's compare this information with the first line (oldest request) in our file. (Notice that these log lines are really long and so \"wrap around\" the cell and can look like two or more lines.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "head -1 columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the visit was from someone using the address 128.59.40.117 at 17/Apr/2016:06:27:25. The request was for a file called \"robots.txt\" which describes where automated programs are allowed to scrape on the site. [The 200 means](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes) that the transmission was completed and that 469 bytes were sent. The user agent is not a browser but a \"crawler\" which means an automated scraper that is sucking up our content, presumably because it's feeding a search engine.\n",
    "\n",
    "Finally, a UNIX command can help us figure out the IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "whois 128.59.40.117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newest entries in the file are obtained from the bottom of the file. The last few lines are displayed with **tail**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "tail columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last request has a timestamp of \"17/Apr/2016:09:12:53\". That means we have captured about 3 hours worth of activity on our site. How many requests is that? The command **wc** tells us how many lines, words and characters are in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "wc columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in our three hours we have 4,000 or so requests. What other questions might we ask of the data? We might want to know how many different IP addresses appear in the data set. Or maybe how many different status codes. \n",
    "\n",
    "We can use the command **cut** to select specific items from the file. Here we pass options that include \"-d\" (a character to be used as a delimiter defining separate fields in the file) and \"-f\" (to specify which fields to cut from the file). \n",
    "\n",
    "Below we define individual fields as being separated by a blank space character and then ask for just the first field, the IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1 columbia.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f10 columbia.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at one of the log lines above and make sure you understand that the 10th field (as defined by spaces) is the number of bytes transferred. \n",
    "\n",
    "Below, use another delimiter to pull out the month the request was made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "# your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The options for the fields to keep include lists separated by commas and ranges defined by a hyphen. The next two are fields 1 and 10 and then fields 1 through 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1,10 columbia.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1-3 columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're getting tired of seeing 4000 lines of output scroll by. We can catch the output and \"pipe\" it into the command that restricts us to 10 lines, **head**. The vertical bar \"|\" is known as a pipe and it takes the output of one command (cut, below) and pipes it as input to the next command (head, below). \n",
    "\n",
    "The net result is printing just 10 lines of fields 1 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1,10 columbia.txt | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As its name suggests, the command **sort** will order the rows in our file. By default it\n",
    "uses alphabetical order but the option \"-n\" lets you sort numerically instead. Below we **cut** out just the IP's and then \"redirect the output\" to a file called \"ips.txt\". We then sort the IP addresses and put the sorted result in a filed called \"ips_sorted.txt\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1 columbia.txt > ips.txt\n",
    "sort ips.txt > ips_sorted.txt\n",
    "head -100 ips_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With UNIX pipes, we can avoid the extra files and just get the sorted data directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1 columbia.txt | sort | head -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(You will end the display with a red box saying that the **head** command only allowed 100 lines to be printed and not all of the output from **sort**. It's OK.)\n",
    "\n",
    "Next, the command **uniq** will remove repeated adjacent lines in a file, so if your file is sorted, it will return just the unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "uniq ips_sorted.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in one line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f1 columbia.txt | sort | uniq | head -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command **uniq** has an option \"-c\" that returns the counts of each row in the file. If we apply it to \"ips_sorted.txt\", we'll get two columns -- one is how many requests were made in our 3 hour window by the IP address and the second is the IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "uniq -c ips_sorted.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, preferably, in one line..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "cut -d\" \" -f1 columbia.txt | sort | uniq -c | head -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can add a second sort to this pipeline to sort in reverse numerical order (using options -r and -n) the **uniq**'d file, giving us the most frequently seen IPs first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh \n",
    "\n",
    "cut -d\" \" -f1 columbia.txt | sort | uniq -c | sort -rn | head -25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 207.46.13.69 was seen 139 times. What is this address?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "whois 207.46.13.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's owned by Microsoft. We can use a filtering command known as **egrep** to pull just the lines that match a regular expression pattern (in quotes). So we might do the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "egrep \"207\\.46\\.13\\.69\" columbia.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could save these lines in a new file if we wanted to do more work. But for now, we see that they are all running \"bingbot\" which is the spider (scraper) for the Bing search engine. Let's see how many times \"bingbot\" is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "egrep \"bingbot\" columbia.txt | wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 481 out of our 4000 or so requests were from Bing. \n",
    "\n",
    "The referrer field is number 11. It records the link someone clicked on to get to the page they're requesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f11 columbia.txt | head -100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we look at just referrers that are Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "cut -d\" \" -f11 columbia.txt | grep \"google\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can clean up a little. Let's remove our two files of IP addresses. First, find them..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "ls -l ips*.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then use **rm** to remove them, with a follow up **ls** to make sure they're gone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "\n",
    "rm ips.txt\n",
    "rm ips_sorted.txt\n",
    "ls -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn**\n",
    "\n",
    "Come up with three questions about the visitors to the site and answer them using simple UNIX commands. Recall we've seen \n",
    "\n",
    ">**pwd, ls, rm, mv, cp<br><br> head, tail, wc, <br><br> cut, sort, uniq,<br><br> grep**\n",
    "\n",
    "This is a pretty powerful pipeline!\n",
    "<br><br>\n",
    "\n",
    "    _     /)---(\\          /~~~\\\n",
    "    \\\\   (/ . . \\)        /  .. \\\n",
    "     \\\\__)-\\(*)/         (_,\\  |_)\n",
    "      \\_       (_         /   \\@/    /^^^\\\n",
    "      (___/-(____) _     /      \\   / . . \\\n",
    "                   \\\\   /  `    |   V\\ Y /V\n",
    "                    \\\\/  \\   | _\\    / - \\\n",
    "                     \\   /__'|| \\\\_  |    \\\n",
    "                      \\_____)|_).\\_).||(__V\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remote Access**\n",
    "\n",
    "We are now going to create a remote machine and access data from it. The advantage is that we can strat to locate our work \"in the cloud\". There are [plenty of services that attempt to make this kind of thing easy for you,](https://ifttt.com) but now that you have some UNIX skills, we can try things out on our own. First, we are going to want to create a computer that we will rent for a little while. We will use [Amazon's EC2 (Elastic Compute Cloud) service.](https://aws.amazon.com/ec2/) \n",
    "\n",
    "```\n",
    "                .--~~,__\n",
    "   :-....,-------`~~'._.'\n",
    "    `-,,,  ,_      ;'~U'\n",
    "     _,-' ,'`-__; '--.\n",
    "    (_/'~~      ''''(;\n",
    "```\n",
    "\n",
    "Let's start by setting up a small computer. It will be so small that Amazon gives it away for free. In the upper righthand corner of the EC2 site, click on the yellow \"Sign In to the Console\" button and use your Amazon account. (If you do not have one, let me know and I can give you a temporary account.) After a short (5 minutes, say) period, we should all be up and running. \n",
    "\n",
    "We will want to sign in to the console and select EC2 services. This will take us to a screen that should look a lot like this.\n",
    "\n",
    "<img src=http://compute-cuj.org/screen.jpg width=500>\n",
    "\n",
    "From here, we can \"launch an instance\", or, rather, startup a computer for our personal use. This computer will remain awake and operational until we decide to take it down. Click on the blue \"Launch Instance\" button in the middle of the page. \n",
    "\n",
    "1. Use the blue \"Select\" button to choose the first kind of computer you are offered on the page, \"Amazon Linux AMI 2017.03.0 (HVM), SSD Volume Type\". Don't sweat all the lingo, just know that this is a Linux computer, and the operating system was configured by Amazon. \n",
    "2. After you select the type of computer, you will be asked for the size specifications. You will select from the \"General purpose\" family, a t2.micro computer. This baby is free! OK you have about 8Gb for of storage and not all of your jobs will work with free this free choice. But, for now, it gets the point across. With the \"t2.micro\" selected, scroll to the bottom of the page and click the blue \"Review and Launch\" button.\n",
    "3. Scroll to the bottom of the page and select \"Launch\". You will be immediately prompted to create so-called key pair. From the menu, choose to create a new key pair and give it a name. This will cause a file (ending in .pem) to be downloaded to your computer. We'll do more with that in a second. For now, hit \"Launch Instance\" and away we go!\n",
    "4. Finally, on the landing page, enter \"View Instance\" to trot over and have a look at your new arrival.\n",
    "5. Let's connect! At the top of the console, you'll see a grey button asking you to \"Connect\". It will pop up a small window that tells you what to do with your key file. The command `chmod` is a UNIX command you type into the terminal window that changes the \"permissions\" on the key file. I usually make a folder called Credentials and put the file in there. The 400 says that only you can look at this file and that the other users of your laptop (guests, say) can't see it. Security! Then, use the `ssh` command they provide, again in the terminal window, with the right path to your key file. It should look something like\n",
    "\n",
    "`ssh -i (yourkey.pem) ec2-user@(your machine).amazonaws.com`\n",
    "\n",
    "\n",
    "The command `ssh` stands for secure shell and is your window to the new computer. To get there you have to provide your key (which is why you want to keep it safe) and the address of the machine. You should be greeted with something like this...<br><br>\n",
    "\n",
    "```\n",
    "\n",
    "       __|  __|_  )\n",
    "       _|  (     /   Amazon Linux AMI\n",
    "      ___|\\___|___|\n",
    "\n",
    "https://aws.amazon.com/amazon-linux-ami/2017.03-release-notes/\n",
    "2 package(s) needed for security, out of 2 available\n",
    "Run \"sudo yum update\" to apply all updates.\n",
    "[ec2-user@ip-172-31-46-101 ~]$ \n",
    "```\n",
    "<br><br>\n",
    "With the dollar sign being your very own UNIX prompt out in the cloud! Ha! Try out one of your UNIX commands to see what's there. \n",
    "\n",
    "```\n",
    "         __\n",
    "        /  \\\n",
    "       / ..|\\\n",
    "      (_\\  |_)\n",
    "      /  \\@'\n",
    "     /     \\\n",
    " _  /  `   |\n",
    "\\\\/  \\  | _\\\n",
    " \\   /_ || \\\\_\n",
    "  \\____)|_) \\_)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Twitter in the Cloud**\n",
    "\n",
    "To monitor Twitter remotely, we can use an application called twarc. It is a command line tool for archiving tweets. It handles all the rate limits and lets you worry about what you're going to do with the data once it's puddledup. First, using your terminal window that is logged into the EC2 t2.micro computer, install twarc. It's a Python application so...\n",
    "\n",
    "`sudo pip install twarc`\n",
    "\n",
    "Ah, `sudo`. That's a command that basically promotes you to administrator while you install twarc. Think about your laptop. When you install software, you have to type in a password because you need to have super powers to put files on certain parts of the computer. Your guests, for example, probably don't have this ability. \n",
    "\n",
    "Once you have installed tward, you should configure it with your keys. Have them ready from Twitter ([go to apps.twitter.com](https://apps.twitter.com/)) and type\n",
    "\n",
    "`twarc configure`\n",
    "\n",
    "OK that done, we can now start monitoring Twitter! Here's a simple \n",
    "\n",
    "`twarc timeline cernovich`\n",
    "\n",
    "OK that had a lot of stuff streaming by. Essentially, you received all of Cernovich's tweets, up to the rate limit. We didn't ask to do anything with them so they just printed out. twarc has a lot of great features that let you do things like follow people and watch their tweets in real time. Cernovich as a twitter id of 358545917. Here's how we follow him.\n",
    "\n",
    "`twarc filter --follow  358545917`\n",
    "\n",
    "And now the printout is slower, but it is meant to be printing both Cernovich's tweets and his retweets. Busy boy! You end this parade by entering Cntl-C to kill the twarc job.\n",
    "\n",
    "twarc was brought to you by Pri and Nic and seems quite sensible. Here is [detailed documentation](https://github.com/DocNow/twarc). I'd advise using it where you can.\n",
    "\n",
    "**Storage**\n",
    "\n",
    "Now, rather than have the data stream by, we could capture it in a file. Recall our \"redirect\" that dumps output into a file. Here we store Cernovich's timeline in a file called `cern.json`. \n",
    "\n",
    "`twarc timeline cernovich > cern.json`\n",
    "\n",
    "To make use of it, let's copy it from our cloud computer back to our desktop. So type \n",
    "\n",
    "`exit`\n",
    "\n",
    "and you should end up with a prompt that looks more like your laptop where you started. Now, hit the \"up arrow\" key on your keyboard while you are in the terminal window. This will recall your last command. You can then alter it to the following (keeping `yourkey` and `yourmachine` as they are in your terminal window. \n",
    "\n",
    "`scp -i (yourkey.pem) ec2-user@(your machine).amazonaws.com:cern.json  .`\n",
    "\n",
    "This command is \"secure copy\" -- it uses your credentials or key to move the file `cern.json` from your amazon computer to your laptop. If you want to copy some other file `abc.txt` to the cloud machine you would do this.\n",
    "\n",
    "`scp -i (yourkey.pem) abc.txt ec2-user@(your machine).amazonaws.com:`\n",
    "\n",
    "So the syntax is \n",
    "\n",
    "`scp -i (yourkey.pem) from_file to_file`\n",
    "\n",
    "... make sure you see this by comparing the two lines above. Now, we can read that file in (maybe you have to put `cern.json` into the folder where your notebook is located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from json import loads\n",
    "\n",
    "# read in the tweets as strings from the file - one line per tweet\n",
    "tweetstrings = open('cern.json').readlines()\n",
    "\n",
    "# for the first 10 strings, load them into python objects (dictionaries)\n",
    "# and printout the text of the tweet\n",
    "\n",
    "for t in tweetstrings[:10]:\n",
    "    tweet = loads(t)\n",
    "    print tweet[\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "            ,/A\\,\n",
    "          .//`_`\\\\,\n",
    "        ,//`____-`\\\\,\n",
    "      ,//`[_ROVER_]`\\\\,\n",
    "    ,//`=  ==  __-  _`\\\\,\n",
    "   //|__=  __- == _  __|\\\\\n",
    "   ` |  __ .-----.  _  | `\n",
    "     | - _/       \\-   |\n",
    "     |__  | .-\"-. | __=|\n",
    "     |  _=|/)   (\\|    |\n",
    "     |-__ (/ a a \\) -__|\n",
    "jgs  |___ /`\\_Y_/`\\____|\n",
    "          \\)8===8(/\n",
    "```\n",
    "\n",
    "**Mongo**\n",
    "\n",
    "That's cool but we can do way way better. Let's go back to your computer in the Amazon cloud and install a data base. We will use something called MongoDB (Mongo from hu*mongo*us.). You can [read about the project here.](https://www.mongodb.com/). It is an example of a new breed of data bases that have emerged. They are called NoSQL (for non-SQL or \"not only\" SQL) and signal a break from the relational model (which, weirdly, we will come back to). According to the Mongo site, some examples of this new breed include\n",
    "\n",
    "* **Document databases** pair each key with a complex data structure known as a document. Documents can contain many different key-value pairs, or key-array pairs, or even nested documents.\n",
    "* **Graph stores** are used to store information about networks of data, such as social connections. Graph stores include Neo4J and Giraph.\n",
    "* **Key-value stores** are the simplest NoSQL databases. Every single item in the database is stored as an attribute name (or 'key'), together with its value. Examples of key-value stores are Riak and Berkeley DB. Some key-value stores, such as Redis, allow each value to have a type, such as 'integer', which adds functionality.\n",
    "* **Wide-column stores** such as Cassandra and HBase are optimized for queries over large datasets, and store columns of data together, instead of rows.\n",
    "\n",
    "Mongo is a document database, where the documents are represented by JSON strings. This kind of flexibility is perfect for our Twitter data. To install Mongo on our cloud machine, `ssh` over there and let'sdo the following. Oh we have [taken these instructions mainly from here.](https://github.com/SIB-Colombia/dataportal-explorer/wiki/How-to-install-node-and-mongodb-on-Amazon-EC2)\n",
    "\n",
    "1. Secure shell over to your Amazon machine.\n",
    "2. The version of `pip` for Linux (or a version) is something called `yum`. Our first command will be to update `yum` itself. First, making sure all its packages are current.\n",
    "<br><br>\n",
    "`sudo yum check-update`<br>\n",
    "`sudo yum update`\n",
    "<br><br> Then, `yum` needs a database of projects to look through and our next commands will be to update that list. Don't worry too much about this, it's just adding a \"repo\" to the places where `yum` looks  for code to install.  \n",
    "<br>\n",
    "`echo \"[mongodb-org-3.2]\n",
    "name=MongoDB Repository\n",
    "baseurl=https://repo.mongodb.org/yum/amazon/2013.03/mongodb-org/3.2/x86_64/\n",
    "gpgcheck=1\n",
    "enabled=1\n",
    "gpgkey=https://www.mongodb.org/static/pgp/server-3.2.asc\" |\n",
    "  sudo tee -a /etc/yum.repos.d/mongodb-org-3.2.repo`\n",
    "<br><br>\n",
    "3. Next, install MongoDB. It's just like using `pip` except that we have to `sudo` for administrator powers and then use `yum` for a Linux app. \n",
    "<br><br>\n",
    "`sudo yum -y install mongo-10gen-server mongodb-org-shell mongodb-org-tools`\n",
    "<br><br>\n",
    "4. We are using the /var/lib/mongo folder to save our database data, a log file and so on. These defaults are fine.\n",
    "<br><br>\n",
    "`sudo mkdir /var/lib/mongo/data\n",
    "sudo mkdir /var/lib/mongo/log\n",
    "sudo mkdir /var/lib/mongo/journal`\n",
    "<br><br>\n",
    "5. Set the storage items (data, log, journal) to be owned by the user (mongod) and group (mongod) that MongoDB will be starting under:\n",
    "<br><br>\n",
    "`sudo chown mongod:mongod /var/lib/mongo/data\n",
    "sudo chown mongod:mongod /var/lib/mongo/log\n",
    "sudo chown mongod:mongod /var/lib/mongo/journal`\n",
    "<br><br>\n",
    "6. Set the MongoDB service to start at \"boot\" (if you ever have to reboot your machine) and activate Mongo!\n",
    "<br><br>\n",
    "`sudo chkconfig mongod on\n",
    "sudo /etc/init.d/mongod start`\n",
    "<br><br>\n",
    "7. Have a look around! MongoDB has a shell (everything does!) that you can use to look at data, etc. There's not much to do now except maybe create a new database and a user who can read and write into the database.\n",
    "<br><br>\n",
    "`mongo`\n",
    "<br><br>\n",
    "Not much to do just yet. I mean you can ask for help, and maybe `show databases`. So let's add some data. <br><br>\n",
    "`quit()` \n",
    "<br><br>\n",
    "out of here. \n",
    "\n",
    "```\n",
    " __/ / \\\n",
    "|    |/\\\n",
    "|_--\\   \\              /-\n",
    "     \\   \\-___________/ /\n",
    "      \\                :\n",
    "      |                :\n",
    "      |       ___ \\    )\n",
    "       \\|  __/     \\  )\n",
    "        | /         \\  \\\n",
    "        |l           ( l\n",
    "        |l            ll\n",
    "        |l            |l\n",
    "       / l           / l\n",
    "       --/           --\n",
    "```\n",
    "\n",
    "**Storing Data**\n",
    "\n",
    "Now, let's store data. We'll take Cernovich's timeline and dump it into a database. The instructions [are given here](https://gist.github.com/edsu/ac57715ac0a2fec3bc64). Hold on, this will be shocking.\n",
    "<br><br>\n",
    "`twarc timeline cernovich | mongoimport --db tweets --collection cernovich` \n",
    "<br><br>\n",
    "This command uses twarc, asks for Cernovich's timeline and then pipes the output (pipes!) into  a command `mongoimport` to bring the data into our database. The database is called `tweets` and the particular collection of documents is called `cernovich`. \n",
    "\n",
    "Think of this structure as having one database per project and then multiple collections of documents (JSON data) in each database. We might also collect tweets from the Gateway Pundit too.\n",
    "<br><br>\n",
    "`twarc timeline gatewaypundit | mongoimport --db tweets --collection gatewaypundit` \n",
    "<br><br>\n",
    "To see what we've done, let's get into Mongo \n",
    "<br><br>\n",
    "`mongo`\n",
    "<br><br>\n",
    "and then look at the databases\n",
    "<br><br>\n",
    "`show databases`\n",
    "<br><br>\n",
    "to see your `tweets` and then \n",
    "<br><br>\n",
    "`use tweets`\n",
    "<br><br>\n",
    "to switch to that database. We can then see what collections are available in this database.\n",
    "<br><br>\n",
    "`show collections`\n",
    "<br><br>\n",
    "And we can see what's there. Maybe we count the tweets we've recorded in each collection.\n",
    "<br><br>\n",
    "`db.cernovich.count()`\n",
    "<br>\n",
    "`db.gatewaypundit.count()`\n",
    "<br><br>\n",
    "The structure of this command in the Mongo shell is `db.collectionname.action`. We can do things like find all the tweets from the Gateway Pundit that were retweeted over 80,000 times and look just at the retweet_count, and the text of the tweet (as opposed to the whole thing). Here is the code. We'll talk it through.\n",
    "<br><br>\n",
    "`db.gatewaypundit.find({retweet_count:{$gt:80000}},{retweet_count:1,text:1})`\n",
    "<br><br>\n",
    "In general, the `find()` command searches for JSON documents and uses a dictionary syntax to find them. Here we searched for the `retweet_count` field, looking for those well retweeted tweets. $gt and $lt are ways to specify ranges. The second argument of `find()` gives a dictionary that tells you what data to keep. The value 1 means keep.\n",
    "\n",
    "The Mongo shell is really powerful. The Mongo site [has great documentation on `find()` and other commands](https://docs.mongodb.com/manual/reference/method/db.collection.find/). Now, we are often going to access a database from the comfort of some other computing environment. In this case, Python. \n",
    "\n",
    "1. To prepare our database for remote access, we'll set up a user (with a password). In mongo you can copy the following.\n",
    "<br><br>\n",
    "`db.createUser({\n",
    "    user: 'journalist',\n",
    "    pwd: 'secret',\n",
    "    roles: [{ role: 'readWrite', db:'tweets'}]\n",
    "})`\n",
    "<br><br>\n",
    "and then get out\n",
    "<br><br>\n",
    "quit()\n",
    "<br><br>\n",
    "2. Next, we want to open up Mongo to talk to the outside world. This means changing its configuration file. Here we comment out one command and remove the comment from another. We are using an old old UNIX command called Sed for the Stream Editor.\n",
    "<br><br>\n",
    "`sudo sed -i 's/bindIp/#bindIp/' /etc/mongod.conf `\n",
    "<br>\n",
    "`sudo sed -i 's/^#security/security/' /etc/mongod.conf `\n",
    "<br>\n",
    "`sudo sed -i \"/^security/a  \\ \\ \\ authorization: 'enabled'\" /etc/mongod.conf`\n",
    "<br><br>\n",
    "3. Return to your EC2 Console and click on the instance in the upper pane of the console. Below you will see details about your computer and scroll down to \"Security Groups\". It should probably be \"launch-wizard-1\". Click on it and look at its security rules. Click on the \"Inbound\" tab. You see port 22 on the machine is open for `ssh` communication (that includes the secure shell and secure copy). Click \"Edit\" and then \"Add Rule\". You will want to select \"Custom TCP Rule\" (the default) and then Port 27017 and the access IP of 0.0.0.0/0, meaning every computer can connect. If there was just one IP address that needed your data, you could put it there instead. Hit \"Save\" and go back to your Terminal logged into the Amazon computer.\n",
    "4. On the Amazon computer restart Mongo with its new user and new network aware self.\n",
    "<br><br>\n",
    "`sudo service mongod restart`\n",
    "<br><br>\n",
    "And there we are. Mongo is up and running and we can now talk to it. Let's! To do this in Python, we need to install PyMongo. Yay!\n",
    "\n",
    "```\n",
    "            __\n",
    "(\\,--------'()'--o\n",
    " (_    ___    /~\"\n",
    "  (_)_)  (_)_)\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Python and Mongo - PyMongo, of course!**\n",
    "\n",
    "PyMongo lets us access a database from the comfort of our notebook. \n",
    "http://api.mongodb.com/python/current/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "client = MongoClient(\"mongodb://journalist:secret@ec2-34-207-224-214.compute-1.amazonaws.com:27017/tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = client[\"tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db[\"cernovich\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db[\"gatewaypundit\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cern = db[\"cernovich\"]\n",
    "cern.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tweet in cern.find({\"retweet_count\":{\"$gt\":20000}},{\"text\":1,\"retweet_count\":1,\"screen_name\":1,\"_id\":0}):\n",
    "    print tweet\n",
    "    print \"---\"*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "df = DataFrame.from_records(cern.find({\"retweet_count\":{\"$gt\":20000}},{\"text\":1,\"retweet_count\":1,\"_id\":0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
